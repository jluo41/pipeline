{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import logging\n",
    "import datasets\n",
    "import pandas as pd \n",
    "from datasets import disable_caching\n",
    "from pprint import pprint \n",
    "from datetime import datetime \n",
    "\n",
    "def process_inference_SPACE(SPACE, MODEL_ENDPOINT):\n",
    "\n",
    "    assert 'MODEL_ROOT' in SPACE, \"Invalid SPACE: missing MODEL_ROOT\"   \n",
    "    \n",
    "    # pipeline from ModelVersion/pipeline\n",
    "    SPACE['CODE_FN'] = os.path.join(SPACE['MODEL_ROOT'], MODEL_ENDPOINT, 'pipeline')\n",
    "    assert os.path.exists(SPACE['CODE_FN']), f\"Invalid CODE_FN: {SPACE['CODE_FN']}\"\n",
    "    # external from ModelVersion/external\n",
    "    SPACE['DATA_EXTERNAL'] = os.path.join(SPACE['MODEL_ROOT'], MODEL_ENDPOINT, 'external')\n",
    "    assert os.path.exists(SPACE['DATA_EXTERNAL']), f\"Invalid DATA_EXTERNAL: {SPACE['DATA_EXTERNAL']}\"\n",
    "\n",
    "    SPACE['DATA_RAW'] = os.path.join(SPACE['MODEL_ROOT'], MODEL_ENDPOINT)\n",
    "    assert os.path.exists(SPACE['DATA_RAW']), f\"Invalid DATA_EXTERNAL: {SPACE['DATA_RAW']}\"\n",
    "\n",
    "    SPACE['DATA_INFERENCE'] = os.path.join(SPACE['MODEL_ROOT'], MODEL_ENDPOINT, 'inference')\n",
    "    assert os.path.exists(SPACE['DATA_INFERENCE']), f\"Invalid DATA_EXTERNAL: {SPACE['DATA_INFERENCE']}\"\n",
    "\n",
    "    SPACE['MODEL_ENDPOINT'] = MODEL_ENDPOINT\n",
    "    return SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- environment for Estimator.deploy() -----------\n",
    "\n",
    "\n",
    "############################\n",
    "MODEL_ROOT          = '../../../_Model'           # '/opt/ml/model' in sagemaker\n",
    "MODEL_ENDPOINT      = 'vTestCGMFull' # 'vTestWeight' # \n",
    "INF_CohortName      = '20241013_InferencePttSampleV0'\n",
    "INF_OneCohortArgs   = {'CohortLabel': 9,\n",
    "                       'CohortName': '20241013_InferencePttSampleV0',\n",
    "                       'FolderPath': '$DATA_RAW$/inference/',\n",
    "                       'SourcePath': 'patient_sample',\n",
    "                       'Source2CohortName': 'InferencePttSampleV0'}\n",
    "INF_CFArgs          = ['cf.TargetCGM_Bf24H'] \n",
    "INF_Args            = {'GEN_Args': {\n",
    "                            'num_first_tokens_for_gen': 289,\n",
    "                            'max_new_tokens': 24,\n",
    "                            'do_sample': False,\n",
    "                            'items_list': ['hist', 'pred', 'logit_scores']}\n",
    "                      } \n",
    "MetaFnName = 'MetaFn_None'\n",
    "TrigFnName = 'TriggerFn_CGM5MinEntry_v1211' \n",
    "PostFnName = \"PostFn_WithCGMPred_v1210\" # \"EngagementPredToLabel\"\n",
    "POST_PROCESS_SCRIPT = None # 'pipeline/inference/post_process.py' # by default, use this script\n",
    "LoggerLevel         = \"INFO\"\n",
    "############################\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "\n",
    "############################# # image your are in the sagemaker container\n",
    "MODEL_ROOT        = os.environ.get('MODEL_ROOT', MODEL_ROOT)\n",
    "MODEL_ENDPOINT    = os.environ.get('MODEL_ENDPOINT', MODEL_ENDPOINT)\n",
    "INF_CohortName    = os.environ.get('INF_COHORT_NAME', INF_CohortName)\n",
    "INF_CohortArgs    = os.environ.get('INF_COHORT_ARGS', INF_OneCohortArgs)\n",
    "InputCFArgs_ForInference = os.environ.get('INF_CFArgs', INF_CFArgs)\n",
    "InferenceArgs     = os.environ.get('INF_Args', INF_Args)   \n",
    "\n",
    "PostFnName = os.environ.get('PostFnName', PostFnName)\n",
    "TrigFnName = os.environ.get('TrigFnName', TrigFnName)\n",
    "MetaFnName = os.environ.get('MetaFnName', MetaFnName)\n",
    "\n",
    "LoggerLevel       = os.environ.get('LOGGER_LEVEL', LoggerLevel)\n",
    "#############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE = {'MODEL_ROOT': MODEL_ROOT}  \n",
    "SPACE = process_inference_SPACE(SPACE, MODEL_ENDPOINT)\n",
    "# TODO: update POST_PROCESS_SCRIPT is it is a s3 path\n",
    "\n",
    "pprint(SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPACE['CODE_FN'] not in sys.path:\n",
    "    sys.path.append(SPACE['CODE_FN'])\n",
    "    sys.path = list(set(sys.path))\n",
    "\n",
    "\n",
    "# from config.config_record.Cohort import CohortName_to_OneCohortArgs\n",
    "from recfldtkn.record_base.cohort import CohortFn, Cohort\n",
    "from recfldtkn.case_base.caseutils import get_ROCOGammePhiInfo_from_CFList\n",
    "from recfldtkn.aidata_base.aidata_base import AIData_Base \n",
    "from recfldtkn.record_base.record_base import Record_Base\n",
    "from recfldtkn.case_base.case_base import Case_Base\n",
    "from recfldtkn.model_base.model_base import Model_Base\n",
    "from recfldtkn.base import fill_missing_keys\n",
    "\n",
    "from nn import load_model_instance_from_nn\n",
    "\n",
    "from inference.utils_inference import (\n",
    "    load_AIData_Model_InfoSettings,\n",
    "    load_Inference_Entry_Example,\n",
    "    pipeline_inference_for_modelbase,\n",
    "    Record_Proc_Config,\n",
    "    Case_Proc_Config,\n",
    "    OneEntryArgs_items_for_inference,\n",
    ")\n",
    "\n",
    "from inference.post_process import NAME_TO_FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelEndpoint_Path = os.path.join(SPACE['MODEL_ROOT'], SPACE['MODEL_ENDPOINT'])\n",
    "assert os.path.exists(ModelEndpoint_Path), f\"Invalid ModelEndpoint_Path: {ModelEndpoint_Path}\"\n",
    "\n",
    "print(ModelEndpoint_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CohortName_to_OneCohortArgs = {INF_CohortName: INF_OneCohortArgs}\n",
    "\n",
    "Package_Settings = {\n",
    "    'INF_CohortName': INF_CohortName,\n",
    "    'INF_OneCohortArgs': INF_OneCohortArgs,\n",
    "    'Record_Proc_Config': Record_Proc_Config,\n",
    "    'Case_Proc_Config': Case_Proc_Config,\n",
    "    'OneEntryArgs_items_for_inference': OneEntryArgs_items_for_inference,\n",
    "    'get_ROCOGammePhiInfo_from_CFList': get_ROCOGammePhiInfo_from_CFList,\n",
    "    'load_model_instance_from_nn': load_model_instance_from_nn,\n",
    "    'Model_Base': Model_Base,\n",
    "    'AIData_Base': AIData_Base,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Context = load_AIData_Model_InfoSettings(\n",
    "    ModelEndpoint_Path = ModelEndpoint_Path,\n",
    "    InputCFArgs_ForInference = InputCFArgs_ForInference, \n",
    "    InferenceArgs = InferenceArgs, \n",
    "    SPACE = SPACE,\n",
    "    **Package_Settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = Context['model_base']\n",
    "aidata_base = Context['aidata_base']\n",
    "InfoSettings = Context['InfoSettings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaFn = NAME_TO_FUNCTION[MetaFnName]\n",
    "\n",
    "meta_results = MetaFn(SPACE)\n",
    "pprint(meta_results, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "Inference_Entry_Example = load_Inference_Entry_Example(INF_CohortName, \n",
    "                                                        CohortName_to_OneCohortArgs,\n",
    "                                                        Cohort,\n",
    "                                                        CohortFn,\n",
    "                                                        SPACE)\n",
    "print([i for i in Inference_Entry_Example.keys()])  \n",
    "########################\n",
    "\n",
    "########################\n",
    "inference_form_name = [i for i in Inference_Entry_Example if 'inference_form' in i][0]\n",
    "inference_form = Inference_Entry_Example[inference_form_name]\n",
    "\n",
    "pprint([i for i in inference_form.keys()])\n",
    "########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_return_metadata = inference_form.get('requestType') == 'metadata'\n",
    "indicator_return_metadata = True \n",
    "\n",
    "if indicator_return_metadata:\n",
    "    metadata_response = meta_results.get('metadata_response', {})\n",
    "    pprint(metadata_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelArtifacts to Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArtifacts_external_to_call = inference_form.get('models')\n",
    "# ModelArtifacts_external_to_call\n",
    "\n",
    "if ModelArtifacts_external_to_call is not None:\n",
    "    ModelArtifacts_to_call = [meta_results['External_to_Local_ModelArtifacts'][i] for i in ModelArtifacts_external_to_call]\n",
    "else:\n",
    "    ModelArtifacts_to_call = None \n",
    "\n",
    "ModelArtifacts_to_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TriggerName_to_CaseTriggerList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in NAME_TO_FUNCTION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "TriggerName_to_CaseTriggerList = None\n",
    "######################################\n",
    "\n",
    "TrigFn = NAME_TO_FUNCTION.get(TrigFnName)\n",
    "\n",
    "if TriggerName_to_CaseTriggerList is None: \n",
    "    TriggerName_to_CaseTriggerList = TrigFn(inference_form)\n",
    "\n",
    "\n",
    "TriggerName_to_dfCaseTrigger = {k: pd.DataFrame(v) for k, v in TriggerName_to_CaseTriggerList.items()}\n",
    "TriggerName_to_dfCaseTrigger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infernece Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inference_Entry = {}\n",
    "Inference_Entry['inference_form'] = Inference_Entry_Example[inference_form_name]\n",
    "Inference_Entry['template_form']  = Inference_Entry_Example['template_form']\n",
    "Inference_Entry['TriggerName_to_dfCaseTrigger'] = TriggerName_to_dfCaseTrigger\n",
    "Inference_Entry['ModelArtifacts_to_call'] = ModelArtifacts_to_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i for i in Inference_Entry])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_results = pipeline_inference_for_modelbase(\n",
    "                        Inference_Entry = Inference_Entry,\n",
    "                        Record_Base = Record_Base, \n",
    "                        Case_Base = Case_Base,\n",
    "                        aidata_base = aidata_base, \n",
    "                        model_base = model_base,\n",
    "                        InfoSettings = InfoSettings, \n",
    "                        SPACE = SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in inference_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArtifactName_to_Inference = inference_results['ModelArtifactName_to_Inference']\n",
    "pprint(ModelArtifactName_to_Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArtifactName_to_Inference = inference_results['ModelArtifactName_to_Inference']\n",
    "\n",
    "PostFn = NAME_TO_FUNCTION[PostFnName]\n",
    "results = PostFn(ModelArtifactName_to_Inference, SPACE)\n",
    "    \n",
    "print('PostFnName', PostFnName)\n",
    "pprint(results, sort_dicts=False, compact=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_base = inference_results['record_base']\n",
    "onecohort_recordbase = record_base.CohortName_to_OneCohortRecordBase[INF_CohortName]\n",
    "onecohort_recordbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onecohort_recordbase.TriggerName_to_dfCaseTrigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = onecohort_recordbase.Name_to_HRF[('P', 'CGM5Min')]\n",
    "record.df_RecAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_base = inference_results['case_base']\n",
    "\n",
    "\n",
    "TriggerCaseBaseName_to_CaseSetNameToCaseset = case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset\n",
    "TriggerCaseBaseName = [i for i in TriggerCaseBaseName_to_CaseSetNameToCaseset][0]\n",
    "# TriggerCaseBaseName\n",
    "\n",
    "CaseSetName_to_Caseset = TriggerCaseBaseName_to_CaseSetNameToCaseset[TriggerCaseBaseName]   \n",
    "# CaseSetName_to_Caseset\n",
    "\n",
    "\n",
    "CaseSetName = [i for i in CaseSetName_to_Caseset][0]\n",
    "caseset = CaseSetName_to_Caseset[CaseSetName]\n",
    "caseset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseset.df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseset.ds_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}