{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af9e5f6-12ce-4ac4-95d8-aa091997589e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Space Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "753d321c-8789-48cb-ad8e-cf23f78f8d8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This is the file that implements a flask server to do inferences. It's the file that you will modify to\n",
    "# implement the scoring for your own algorithm.\n",
    "\n",
    "from __future__ import print_function\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "# import flask\n",
    "import logging\n",
    "import datasets\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from datetime import datetime \n",
    "# from flask import Flask, request, jsonify, Response\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e485a37-59c4-4326-afdd-fa3f5c9a187f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# parent_directory = '/dbfs/FileStore/Sid_Files/Deployment-v1119'\n",
    "parent_directory = '.'\n",
    "\n",
    "os.chdir(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b9c96ac-16ab-492f-bbe5-419884775c7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_inference_SPACE(SPACE, MODEL_ENDPOINT):\n",
    "\n",
    "    assert 'MODEL_ROOT' in SPACE, \"Invalid SPACE: missing MODEL_ROOT\"   \n",
    "    \n",
    "    # pipeline from ModelVersion/pipeline\n",
    "    SPACE['CODE_FN'] = os.path.join(SPACE['MODEL_ROOT'], MODEL_ENDPOINT, 'pipeline')\n",
    "    assert os.path.exists(SPACE['CODE_FN']), f\"Invalid CODE_FN: {SPACE['CODE_FN']}\"\n",
    "    # external from ModelVersion/external\n",
    "    SPACE['DATA_EXTERNAL'] = os.path.join(SPACE['MODEL_ROOT'], MODEL_ENDPOINT, 'external')\n",
    "    assert os.path.exists(SPACE['DATA_EXTERNAL']), f\"Invalid DATA_EXTERNAL: {SPACE['DATA_EXTERNAL']}\"\n",
    "\n",
    "    SPACE['DATA_RAW'] = os.path.join(SPACE['MODEL_ROOT'], MODEL_ENDPOINT)\n",
    "    assert os.path.exists(SPACE['DATA_RAW']), f\"Invalid DATA_EXTERNAL: {SPACE['DATA_RAW']}\"\n",
    "\n",
    "    SPACE['DATA_INFERENCE'] = os.path.join(SPACE['MODEL_ROOT'], MODEL_ENDPOINT, 'inference')\n",
    "    assert os.path.exists(SPACE['DATA_INFERENCE']), f\"Invalid DATA_EXTERNAL: {SPACE['DATA_INFERENCE']}\"\n",
    "\n",
    "    SPACE['MODEL_ENDPOINT'] = MODEL_ENDPOINT\n",
    "    return SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "279949ba-10ba-4e52-882f-4f38b761b6fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #####################\n",
    "# # Save the model with artifacts\n",
    "# MODEL_NAME = 'weight_af1m_prediction'\n",
    "# json_payload_path = 'data_weight.json'\n",
    "# #####################\n",
    "\n",
    "\n",
    "\n",
    "# ############################\n",
    "# # ----------- environment for Estimator.deploy() -----------\n",
    "# MODEL_ROOT          = 'model'           # '/opt/ml/model' in sagemaker\n",
    "# MODEL_ENDPOINT      = 'vTestWeight' # 'vTestCGMFull'\n",
    "# INF_CohortName      = '20241013_InferencePttSampleV0'\n",
    "# INF_OneCohortArgs   = {'CohortLabel': 9,\n",
    "#                        'CohortName': '20241013_InferencePttSampleV0',\n",
    "#                        'FolderPath': '$DATA_RAW$/inference/',\n",
    "#                        'SourcePath': 'patient_sample',\n",
    "#                        'Source2CohortName': 'InferencePttSampleV0'}\n",
    "# INF_CFArgs          = None \n",
    "# INF_Args            = None \n",
    "\n",
    "# PostFnName = \"PostFn_NaiveForUniLabelPred\" # \"EngagementPredToLabel\"\n",
    "# TrigFnName = 'TriggerFn_WeightEntry_v1211' \n",
    "# MetaFnName = 'MetaFn_None'\n",
    "\n",
    "# POST_PROCESS_SCRIPT = None # 'pipeline/inference/post_process.py' # by default, use this script\n",
    "# LoggerLevel         = \"INFO\"\n",
    "# ############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Save the model with artifacts\n",
    "MODEL_NAME = 'cgmlsm_naive_2h_predict'\n",
    "\n",
    "json_payload_path = 'data_cgm.json'\n",
    "#####################\n",
    "\n",
    "###########################\n",
    "MODEL_ROOT          = 'model' # '../../../_Model'           # '/opt/ml/model' in sagemaker\n",
    "MODEL_ENDPOINT      = 'vTestCGMFull' # 'vTestWeight' # \n",
    "INF_CohortName      = '20241013_InferencePttSampleV0'\n",
    "INF_OneCohortArgs   = {'CohortLabel': 9,\n",
    "                       'CohortName': '20241013_InferencePttSampleV0',\n",
    "                       'FolderPath': '$DATA_RAW$/inference/',\n",
    "                       'SourcePath': 'patient_sample',\n",
    "                       'Source2CohortName': 'InferencePttSampleV0'}\n",
    "INF_CFArgs          = ['cf.TargetCGM_Bf24H'] \n",
    "INF_Args            = {'GEN_Args': {\n",
    "                            'num_first_tokens_for_gen': 289,\n",
    "                            'max_new_tokens': 24,\n",
    "                            'do_sample': False,\n",
    "                            'items_list': ['hist', 'pred', 'logit_scores']}\n",
    "                      } \n",
    "MetaFnName = 'MetaFn_None'\n",
    "TrigFnName = 'TriggerFn_CGM5MinEntry_v1211' \n",
    "PostFnName = \"PostFn_WithCGMPred_v1210\" # \"EngagementPredToLabel\"\n",
    "POST_PROCESS_SCRIPT = None # 'pipeline/inference/post_process.py' # by default, use this script\n",
    "LoggerLevel         = \"INFO\"\n",
    "###########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# # image your are in the sagemaker container\n",
    "MODEL_ROOT        = os.environ.get('MODEL_ROOT', MODEL_ROOT)\n",
    "MODEL_ENDPOINT    = os.environ.get('MODEL_ENDPOINT', MODEL_ENDPOINT)\n",
    "INF_CohortName    = os.environ.get('INF_COHORT_NAME', INF_CohortName)\n",
    "INF_CohortArgs    = os.environ.get('INF_COHORT_ARGS', INF_OneCohortArgs)\n",
    "InputCFArgs_ForInference = os.environ.get('INF_CFArgs', INF_CFArgs)\n",
    "InferenceArgs     = os.environ.get('INF_Args', INF_Args)   \n",
    "\n",
    "PostFnName = os.environ.get('PostFnName', PostFnName)\n",
    "TrigFnName = os.environ.get('TrigFnName', TrigFnName)\n",
    "MetaFnName = os.environ.get('MetaFnName', MetaFnName)\n",
    "\n",
    "LoggerLevel       = os.environ.get('LOGGER_LEVEL', LoggerLevel)\n",
    "#############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE = {'MODEL_ROOT': MODEL_ROOT}  \n",
    "SPACE = process_inference_SPACE(SPACE, MODEL_ENDPOINT)\n",
    "# TODO: update POST_PROCESS_SCRIPT is it is a s3 path\n",
    "\n",
    "pprint(SPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92851f08-7316-406c-8d71-fe4d5831480d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MlFlow Databrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49e7c26c-51fc-4990-8c15-ca7c13ee379e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edfe3448-926b-4c13-aff0-53cacbbcbe76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class PredictionModel(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    MLflow PythonModel for weight prediction with complete model context.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.MODEL_ENDPOINT = MODEL_ENDPOINT\n",
    "        self.pipeline_inference_for_modelbase = None\n",
    "        self.aidata_base = None\n",
    "        self.model_base = None\n",
    "        self.info_settings = None\n",
    "        self.Inference_Entry = None \n",
    "        self.SPACE = None\n",
    "        self.InputCFArgs_ForInference = InputCFArgs_ForInference\n",
    "        self.InferenceArgs = InferenceArgs\n",
    "\n",
    "    def load_context(self, context):\n",
    "        \"\"\"\n",
    "        Load model context including external features, inference examples,\n",
    "        models, and pipeline code.\n",
    "        \n",
    "        Context structure:\n",
    "        - external/: External features\n",
    "        - Inference/: Inference examples\n",
    "        - models/: Model files\n",
    "        - pipeline/: Python package\n",
    "        \"\"\"\n",
    "\n",
    "        for key, path in context.artifacts.items():\n",
    "            print(f\"{key}: {path}\")\n",
    "\n",
    "        # Setup logging\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "        # SPACE['MODEL_ENDPOINT']\n",
    "\n",
    "        MODEL_ENDPOINT = self.MODEL_ENDPOINT\n",
    "\n",
    "        MODEL_ENDPOINT_FOLDER = context.artifacts[MODEL_ENDPOINT]\n",
    "        MODEL_ROOT = os.path.dirname(MODEL_ENDPOINT_FOLDER)\n",
    "\n",
    "        SPACE = {\n",
    "            'MODEL_ROOT': MODEL_ROOT,\n",
    "        }\n",
    "\n",
    "        SPACE = process_inference_SPACE(SPACE, MODEL_ENDPOINT)\n",
    "\n",
    "\n",
    "        logger.info(f\"SPACE information: {SPACE}\")  \n",
    "\n",
    "        if SPACE['CODE_FN'] not in sys.path:\n",
    "            sys.path.append(SPACE['CODE_FN'])\n",
    "            sys.path = list(set(sys.path))\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        from recfldtkn.record_base.cohort import CohortFn, Cohort\n",
    "        from recfldtkn.case_base.caseutils import get_ROCOGammePhiInfo_from_CFList\n",
    "        from recfldtkn.aidata_base.aidata_base import AIData_Base \n",
    "        from recfldtkn.record_base.record_base import Record_Base\n",
    "        from recfldtkn.case_base.case_base import Case_Base\n",
    "        from recfldtkn.model_base.model_base import Model_Base\n",
    "        from recfldtkn.base import fill_missing_keys\n",
    "        from nn import load_model_instance_from_nn\n",
    "        from inference.utils_inference import (\n",
    "            load_AIData_Model_InfoSettings,\n",
    "            load_Inference_Entry_Example,\n",
    "            pipeline_inference_for_modelbase,\n",
    "            Record_Proc_Config,\n",
    "            Case_Proc_Config,\n",
    "            OneEntryArgs_items_for_inference,\n",
    "        )\n",
    "        from inference.post_process import NAME_TO_FUNCTION\n",
    "        # ----------------------------------------------------\n",
    "\n",
    "\n",
    "        try:\n",
    "            self.pipeline_inference_for_modelbase = pipeline_inference_for_modelbase\n",
    "\n",
    "            self.MetaFn = NAME_TO_FUNCTION[MetaFnName]\n",
    "            self.TrigFn = NAME_TO_FUNCTION[TrigFnName]\n",
    "            self.PostFn = NAME_TO_FUNCTION[PostFnName]\n",
    "\n",
    "            InputCFArgs_ForInference = self.InputCFArgs_ForInference\n",
    "            InferenceArgs = self.InferenceArgs\n",
    "            CohortName_to_OneCohortArgs = {INF_CohortName: INF_OneCohortArgs}\n",
    "\n",
    "            ModelEndpoint_Path = os.path.join(SPACE['MODEL_ROOT'], SPACE['MODEL_ENDPOINT'])\n",
    "            assert os.path.exists(ModelEndpoint_Path), f\"Invalid ModelEndpoint_Path: {ModelEndpoint_Path}\"\n",
    "\n",
    "            Package_Settings = {\n",
    "                'INF_CohortName': INF_CohortName,\n",
    "                'INF_OneCohortArgs': INF_OneCohortArgs,\n",
    "                'Record_Proc_Config': Record_Proc_Config,\n",
    "                'Case_Proc_Config': Case_Proc_Config,\n",
    "                'OneEntryArgs_items_for_inference': OneEntryArgs_items_for_inference,\n",
    "                'get_ROCOGammePhiInfo_from_CFList': get_ROCOGammePhiInfo_from_CFList,\n",
    "                'load_model_instance_from_nn': load_model_instance_from_nn,\n",
    "                'Model_Base': Model_Base,\n",
    "                'AIData_Base': AIData_Base,\n",
    "            }\n",
    "\n",
    "            Context = load_AIData_Model_InfoSettings(\n",
    "                ModelEndpoint_Path = ModelEndpoint_Path,\n",
    "                InputCFArgs_ForInference = InputCFArgs_ForInference, \n",
    "                InferenceArgs = InferenceArgs, \n",
    "                SPACE = SPACE,\n",
    "                **Package_Settings,\n",
    "            )\n",
    "            \n",
    "            self.model_base = Context['model_base']\n",
    "            self.aidata_base = Context['aidata_base']\n",
    "            self.InfoSettings = Context['InfoSettings']\n",
    "            self.SPACE = SPACE\n",
    "\n",
    "            Inference_Entry_Example = load_Inference_Entry_Example(INF_CohortName, \n",
    "                                                                    CohortName_to_OneCohortArgs,\n",
    "                                                                    Cohort,\n",
    "                                                                    CohortFn,\n",
    "                                                                    SPACE)\n",
    "            self.Inference_Entry_Example = Inference_Entry_Example\n",
    "\n",
    "\n",
    "            self.Record_Base = Record_Base\n",
    "            self.Case_Base = Case_Base\n",
    "\n",
    "            \n",
    "            # Import pipeline components\n",
    "            self.logger.info(\"Successfully loaded model context and components\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to load model context: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"Run prediction using loaded context.\"\"\"\n",
    "        try:\n",
    "            # #{dataframe_record: [ {input: {k1:v1, k2:v2}}]}\n",
    "            # # df: column `input`\n",
    "            # #           | {k1:v1, k2:v2}|\n",
    "            # self.logger.info(model_input) # json_payload = {'xxx': model_input}\n",
    "\n",
    "            # # model_input: df\n",
    "            # # model_input = model_input['inputs'] # follow databrick's requirements \n",
    "            # # model_input: series # one-row series\n",
    "\n",
    "            # model_input = model_input.iloc[0]\n",
    "\n",
    "\n",
    "            # # model_input: {k1:v1, k2:v2}\n",
    "            # TriggerName_to_CaseTriggerList = model_input['TriggerName_to_CaseTriggerList']\n",
    "\n",
    "\n",
    "            df_model_input = model_input\n",
    "            #{dataframe_record: [ {k1:v1, k2:v2}]}\n",
    "            # df: column `k1`, k2\n",
    "            #           | v1,|.v2|\n",
    "            self.logger.warning(model_input) # json_payload = {'xxx': model_input}\n",
    "            self.logger.warning(type(model_input))\n",
    "            # model_input: df\n",
    "\n",
    "\n",
    "            model_input = df_model_input.iloc[0].to_dict()\n",
    "            # model_input: series: {k1:v1, k2:v2}\n",
    "\n",
    "\n",
    "            # model_input: {k1:v1, k2:v2}\n",
    "            # assert type(model_input) == dict, f'get type of {type(model_input)}'\n",
    "\n",
    "            self.logger.warning(type(model_input))\n",
    "            \n",
    "\n",
    "            # ------------- TriggerName_to_dfCaseTrigger -------------\n",
    "            if 'TriggerName_to_CaseTriggerList' not in model_input:\n",
    "                inference_form = model_input['inference_form']\n",
    "                TriggerName_to_CaseTriggerList = self.TrigFn(inference_form)\n",
    "            else:\n",
    "                TriggerName_to_CaseTriggerList = model_input['TriggerName_to_CaseTriggerList']          \n",
    "            \n",
    "            TriggerName_to_dfCaseTrigger = {k: pd.DataFrame(v) for k, v in TriggerName_to_CaseTriggerList.items()}\n",
    "\n",
    "            for TriggerName, df in TriggerName_to_dfCaseTrigger.items():\n",
    "                if 'ObsDT' not in df.columns:\n",
    "                    df['ObsDT'] = pd.to_datetime(df['ObsDT_UTC']) + pd.to_timedelta(df['TimezoneOffset'], 'm')\n",
    "                TriggerName_to_dfCaseTrigger[TriggerName] = df\n",
    "\n",
    "\n",
    "            Inference_Entry = {}\n",
    "            Inference_Entry['TriggerName_to_dfCaseTrigger'] = TriggerName_to_dfCaseTrigger\n",
    "            Inference_Entry['inference_form'] = model_input['inference_form']\n",
    "            Inference_Entry['template_form'] = self.Inference_Entry_Example['template_form']\n",
    "            Inference_Entry['ModelArtifacts_to_call'] = None \n",
    "\n",
    "            pipeline_inference_for_modelbase = self.pipeline_inference_for_modelbase\n",
    "\n",
    "            inference_results = pipeline_inference_for_modelbase(\n",
    "                Inference_Entry = Inference_Entry,\n",
    "                Record_Base = self.Record_Base, \n",
    "                Case_Base = self.Case_Base,\n",
    "                aidata_base = self.aidata_base, \n",
    "                model_base = self.model_base,\n",
    "                InfoSettings = self.InfoSettings, \n",
    "                SPACE = self.SPACE\n",
    "            )\n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            du1 = inference_results['du1']\n",
    "            du2 = inference_results['du2']\n",
    "            du3 = inference_results['du3']\n",
    "            du4 = inference_results['du4']\n",
    "            total_time = inference_results['total_time']\n",
    "\n",
    "            self.logger.info(f\"record_base: {du1}\")\n",
    "            self.logger.info(f\"case_base: {du2}\")\n",
    "            self.logger.info(f\"aidata_base and model_base update: {du3}\")\n",
    "            self.logger.info(f\"model_infernece: {du4}\")\n",
    "            self.logger.info(f\"total_time: {total_time}\")\n",
    "\n",
    "            print(inference_results)\n",
    "            \n",
    "            ModelArtifactName_to_Inference = inference_results['ModelArtifactName_to_Inference']\n",
    "            results = self.PostFn(ModelArtifactName_to_Inference, self.SPACE)\n",
    "            \n",
    "            self.logger.info(\"Successfully ran prediction\")\n",
    "            return results\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Prediction failed: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1209f917-f322-4fc7-b610-33eb5b1e8dd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "artifacts = {\n",
    "    SPACE['MODEL_ENDPOINT']: os.path.join(SPACE['MODEL_ROOT'], SPACE['MODEL_ENDPOINT']),\n",
    "}\n",
    "\n",
    "artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2828388-24c8-40f4-bd1b-b98dffc87a1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conda_env = {\n",
    "    \"channels\": [\n",
    "        \"pytorch\",\n",
    "        \"nvidia\", \n",
    "        \"defaults\", \n",
    "        \"conda-forge\", \n",
    "        ],\n",
    "    \"dependencies\": [\n",
    "        f\"python={sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n",
    "        \"pip\", \n",
    "\n",
    "        # pay attention to this pytorch part. \n",
    "        \"cudatoolkit\", \n",
    "        \"pytorch\", \n",
    "        \"torchvision\", \n",
    "        \"torchaudio\",\n",
    "        \"cudatoolkit\",\n",
    "\n",
    "        \"ipykernel\", \n",
    "\n",
    "        \"datasets\",\n",
    "        \"pandas==2.2.0\",\n",
    "        \"requests==2.31.0\",\n",
    "        \"scikit-learn==1.4.0\",\n",
    "        \"scipy==1.12.0\",\n",
    "        \"tokenizers==0.15.1\",\n",
    "        \"xgboost==2.0.3\",\n",
    "        \"Werkzeug==2.0.2\",\n",
    "        \"Pympler==1.1\",\n",
    "\n",
    "        \"numpy\",\n",
    "        \"gunicorn\",\n",
    "        \"matplotlib\",#\n",
    "    ],\n",
    "    \"name\": \"weight_prediction_env\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8889612d-a585-45c3-852d-dbe9ab2edba4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def underscore_to_hyphen(parent_dir):\n",
    "    os.chdir(f'{parent_dir}/ds_case')\n",
    "    print(os.getcwd())\n",
    "    files = os.listdir()\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        if file.split('.')[-1] == 'arrow':\n",
    "            new_file = file.replace('_', '-')\n",
    "            os.rename(file, new_file)\n",
    "    os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d37efdc-d894-4420-9df7-4ca9d888d1f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce8d3452-99a9-4df7-a6f3-211dff3e18f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# model_folder_path = 'weight_prediction_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register in Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cd7f5bc-ff30-4320-8156-951a49bd6727",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_NAME):\n",
    "    shutil.rmtree(MODEL_NAME)\n",
    "\n",
    "mlflow.pyfunc.save_model(\n",
    "    path = MODEL_NAME,\n",
    "    python_model=PredictionModel(),\n",
    "    artifacts=artifacts,\n",
    "    conda_env=conda_env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "919d6262-5725-4b1c-9719-2295b9a375d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register in Databrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c815c9e-8c98-4b86-a98d-a83e48afddfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ################\n",
    "# MODEL_NAME = MODEL_NAME\n",
    "# #Update this peice of code before\n",
    "# i = 0\n",
    "# ################\n",
    "\n",
    "\n",
    "# with mlflow.start_run() as run:\n",
    "#     mlflow.pyfunc.log_model(\n",
    "#         MODEL_NAME,\n",
    "#         python_model=WeightPredictionModel(),\n",
    "#         signature=None,\n",
    "#         artifacts=artifacts,\n",
    "#         conda_env = conda_env\n",
    "#     )\n",
    "#     run_id = run.info.run_id\n",
    "\n",
    "#     # Register the model\n",
    "#     model_uri = f\"runs:/{run_id}/{MODEL_NAME}\"\n",
    "#     mlflow.register_model(model_uri=model_uri, name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_ENDPOINT = i + 1\n",
    "# model_uri = f\"models:/{MODEL_NAME}/{MODEL_ENDPOINT}\"\n",
    "# loaded_model = mlflow.pyfunc.load_model(model_uri = model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "506a72ea-bb42-43aa-9e15-b74ff08eb370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_payload_path, 'r') as f:\n",
    "    json_payload = json.load(f)\n",
    "\n",
    "model_input = pd.DataFrame(json_payload['dataframe_records'])\n",
    "display(model_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loaded_model.predict(model_input)\n",
    "print(\"Prediction result:\", result)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "def remove_unwanted_files(folder_path):\n",
    "    \"\"\"Remove macOS trash files and Python rubbish files from the specified folder.\"\"\"\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Remove specific files\n",
    "        for name in files:\n",
    "            if name in [\".DS_Store\"] or name.endswith((\".pyc\", \".pyo\", \"~\")):\n",
    "                file_path = os.path.join(root, name)\n",
    "                print(f\"Removing {file_path}\")\n",
    "                os.remove(file_path)\n",
    "        \n",
    "        # Remove specific directories\n",
    "        for name in dirs:\n",
    "            if name in [\"__MACOSX\", \"__pycache__\"]:\n",
    "                dir_path = os.path.join(root, name)\n",
    "                print(f\"Removing {dir_path}\")\n",
    "                shutil.rmtree(dir_path, ignore_errors=True)\n",
    "\n",
    "def compress_to_zip(folder_path, output_file):\n",
    "    \"\"\"Compress the folder into a zip file after cleaning.\"\"\"\n",
    "    remove_unwanted_files(folder_path)  # Clean up trash files\n",
    "    with zipfile.ZipFile(output_file, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, folder_path)  # Maintain folder structure\n",
    "                zipf.write(file_path, arcname)\n",
    "    print(f\"Compressed {folder_path} to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_NAME):\n",
    "    shutil.rmtree(MODEL_NAME)\n",
    "\n",
    "RUN = './mlruns'\n",
    "if os.path.exists(RUN):\n",
    "    shutil.rmtree(RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage example\n",
    "folder_to_compress = os.getcwd()\n",
    "output_tar_gz = f\"{folder_to_compress}.zip\"\n",
    "print(output_tar_gz)\n",
    "\n",
    "if os.path.exists(output_tar_gz):\n",
    "    os.remove(output_tar_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_to_zip(folder_to_compress, output_tar_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Final_Databrick-Inference_final_V1sb_v1107_15Days",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}