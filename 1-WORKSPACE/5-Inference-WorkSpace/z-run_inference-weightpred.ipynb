{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "\n",
    "from datasets import disable_caching\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'; WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY; os.chdir(WORKSPACE_PATH)\n",
    "\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN']); SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "\n",
    "disable_caching()\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.record_base.cohort import CohortFn, Cohort\n",
    "from config.config_record.Cohort import CohortName_to_OneCohortArgs\n",
    "\n",
    "\n",
    "CohortName = '20241013_InferencePttSampleV0'\n",
    "CohortName_list = [CohortName]\n",
    "CohortName_list_for_inference = CohortName_list\n",
    "OneEntryArgs_items_for_inference = ['Input_Part']\n",
    "\n",
    "Record_Proc_Config = {\n",
    "    'save_data': False, \n",
    "    'load_data':False, \n",
    "    'via_method': 'df'\n",
    "}\n",
    "\n",
    "Case_Proc_Config = {\n",
    "    'max_trigger_case_num': None, \n",
    "    'use_task_cache': True, \n",
    "    'caseset_chunk_size': 50000,\n",
    "    'save_data': False, \n",
    "    'load_data': False, \n",
    "    'load_casecollection': False,\n",
    "    'via_method': 'df',\n",
    "    'n_cpus': 1, \n",
    "    'batch_size': None,  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an Inference_Entry\n",
    "################\n",
    "# replace this part with the API input. \n",
    "OneCohort_Args = CohortName_to_OneCohortArgs[CohortName]\n",
    "\n",
    "\n",
    "Source2CohortName = OneCohort_Args['Source2CohortName']\n",
    "cohort_fn = CohortFn(Source2CohortName, SPACE)\n",
    "cohort = Cohort(OneCohort_Args, SPACE, cohort_fn)\n",
    "cohort.setup_fn(cohort_fn)\n",
    "cohort.initialize_cohort()\n",
    "\n",
    "# Get Inference_Entry\n",
    "SourceFile_List = cohort.SourceFile_List\n",
    "OneCohort_Args = cohort.OneCohort_Args\n",
    "get_RawName_from_SourceFile = cohort.get_RawName_from_SourceFile\n",
    "get_InferenceEntry = cohort.cohort_fn.get_InferenceEntry\n",
    "Inference_Entry = get_InferenceEntry(OneCohort_Args, \n",
    "                                     SourceFile_List, \n",
    "                                     get_RawName_from_SourceFile)\n",
    "\n",
    "pprint(Inference_Entry['template_form'], sort_dicts=False, compact=True)\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i for i in Inference_Entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TriggerFn_WeightEntry_v1211(inference_form):\n",
    "\n",
    "    ########### ------ build the df_case and save to the Inference_Entry ------ ###########\n",
    "    TriggerName = 'WeightEntry'\n",
    "    DBTableName = 'ElogWeightEntry'\n",
    "    df_weight = pd.DataFrame(inference_form[DBTableName])\n",
    "    case = df_weight.iloc[-1]\n",
    "    PatientID = case['PatientID']\n",
    "    ObsDT = case['ObservationEntryDateTime']\n",
    "    Weight = case['Weight']\n",
    "    case = {\n",
    "        'PatientID': PatientID,\n",
    "        'ObsDT': ObsDT,\n",
    "        # 'Weight': Weight\n",
    "    }\n",
    "\n",
    "    CaseTriggerList = [case]\n",
    "    TriggerName_to_CaseTriggerList = {\n",
    "        TriggerName: CaseTriggerList,\n",
    "    }\n",
    "    return TriggerName_to_CaseTriggerList\n",
    "\n",
    "\n",
    "inferece_form_name = [i for i in Inference_Entry if 'inference_form' in i][0]\n",
    "inference_form = Inference_Entry[inferece_form_name]\n",
    "TriggerName_to_CaseTriggerList = TriggerFn_WeightEntry_v1211(inference_form)\n",
    "TriggerName_to_dfCaseTrigger = {TriggerName: pd.DataFrame(CaseTriggerList) for TriggerName, CaseTriggerList in TriggerName_to_CaseTriggerList.items()}\n",
    "Inference_Entry['TriggerName_to_dfCaseTrigger'] = TriggerName_to_dfCaseTrigger\n",
    "TriggerName_to_dfCaseTrigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ENDPOINT = 'vTestWeight'\n",
    "SPACE['MODEL_ENDPOINT'] = MODEL_ENDPOINT\n",
    "pprint(SPACE, sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Model_Base from a Model Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.model_base.model_base import Model_Base\n",
    "from nn import load_model_instance_from_nn\n",
    "\n",
    "ModelEndpoint_Path = os.path.join(SPACE['MODEL_ROOT'], SPACE['MODEL_ENDPOINT'])\n",
    "model_base = Model_Base(\n",
    "    ModelEndpoint_Path = ModelEndpoint_Path,\n",
    "    load_model_instance_from_nn = load_model_instance_from_nn,\n",
    "    SPACE = SPACE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(model_base.ModelArtifactName_to_ModelInfo, sort_dicts=False, compact=True)\n",
    "\n",
    "for model_artifact_name, ModelInfo in model_base.ModelArtifactName_to_ModelInfo.items():\n",
    "    # model_instance \n",
    "    print(model_artifact_name)\n",
    "    model_artifact = ModelInfo['model_artifact']\n",
    "    print({k: len(v['input_ids']['tid2tkn']) for k, v in model_artifact.aidata.CF_to_CFvocab.items()})\n",
    "    # pprint(model_instance.aidata.EntryArgs['Input_FullArgs'])\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: InfoSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.utils_inference import get_complete_InfoSettings\n",
    "\n",
    "###################\n",
    "# CFArgs_ForInference = None\n",
    "InputCFArgs_ForInference = None # ['cf.TargetCGM_Bf24H'] # to remove in the future\n",
    "###################\n",
    "\n",
    "InfoSettings = get_complete_InfoSettings(model_base, CohortName_list, InputCFArgs_ForInference)\n",
    "\n",
    "print([i for i in InfoSettings])\n",
    "pprint(InfoSettings['TriggerCaseBaseName_to_TriggerCaseBaseArgs'], sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. AIData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.aidata_base import AIData_Base   \n",
    "\n",
    "OneAIDataName_to_OneAIDataArgs = InfoSettings['OneAIDataName_to_OneAIDataArgs']\n",
    "pprint({k:v['OneEntryArgs'] for k, v in OneAIDataName_to_OneAIDataArgs.items()}, sort_dicts=False, compact=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneAIDataName = [i for i in OneAIDataName_to_OneAIDataArgs][0]\n",
    "OneAIDataArgs = OneAIDataName_to_OneAIDataArgs[OneAIDataName]\n",
    "[i for i in OneAIDataArgs['OneEntryArgs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in OneAIDataName_to_OneAIDataArgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata_base = AIData_Base(\n",
    "    OneAIDataName_to_OneAIDataArgs = OneAIDataName_to_OneAIDataArgs,\n",
    "    OneEntryArgs_items_for_inference = OneEntryArgs_items_for_inference,\n",
    "    CohortName_list_for_inference = CohortName_list_for_inference, \n",
    "    SPACE = SPACE, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(aidata_base.AIDataHashName_to_AIDataArgs, sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneAIDataName = aidata_base.get_AIDataName_list()[0]\n",
    "OneAIDataArgs = aidata_base.get_OneAIDataArgs_from_OneAIDataName(OneAIDataName)\n",
    "\n",
    "OneEntryArgs = OneAIDataArgs['OneEntryArgs']\n",
    "pprint(OneEntryArgs, sort_dicts=False, compact=True)\n",
    "aidata = aidata_base.get_aidata_from_OneAIDataName(OneAIDataName)\n",
    "aidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata_base.get_AIDataHashName_list()\n",
    "Name_to_Data = aidata.Name_to_Data\n",
    "[i for i in Name_to_Data]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: CF, HRF, TriggerCaseBaseName_to_CohortNameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneAIDataArgs['OneEntryArgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from recfldtkn.case_base.caseutils import get_ROCOGammePhiInfo_from_CFList\n",
    "\n",
    "\n",
    "Case_Args_Settings = InfoSettings['Case_Args_Settings']\n",
    "CF_to_CFArgs = Case_Args_Settings['CF_to_CFArgs']\n",
    "TagCF_to_TagCFArgs = Case_Args_Settings.get('TagCF_to_TagCFArgs', {})\n",
    "\n",
    "CF_list_ForInference = InfoSettings['CF_list_ForInference'] # (aidata_base, CF_to_CFArgs, TagCF_to_TagCFArgs)\n",
    "pprint(CF_list_ForInference, sort_dicts=False)\n",
    "\n",
    "ROCOGammaPhiInfo = get_ROCOGammePhiInfo_from_CFList(CF_list_ForInference, CF_to_CFArgs)\n",
    "HumanRecordRecfeat_Args = ROCOGammaPhiInfo['HumanRecordRecfeat_Args']\n",
    "pprint(HumanRecordRecfeat_Args, sort_dicts=False)\n",
    "\n",
    "\n",
    "TriggerCaseBaseName_List = list(set([v['TriggerCaseBaseName'] for k, v in OneAIDataName_to_OneAIDataArgs.items()]))\n",
    "TriggerCaseBaseName_to_CohortNameList = {}\n",
    "for TriggerCaseBaseName in TriggerCaseBaseName_List:\n",
    "    TriggerCaseBaseName_to_CohortNameList[TriggerCaseBaseName] = CohortName_list\n",
    "\n",
    "pprint(TriggerCaseBaseName_to_CohortNameList, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: load AIData Model InfoSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelEndpoint_Path = ModelEndpoint_Path\n",
    "print(ModelEndpoint_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputCFArgs_ForInference = InputCFArgs_ForInference\n",
    "print(InputCFArgs_ForInference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InferenceArgs = None\n",
    "print(InferenceArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INF_CohortName = CohortName \n",
    "print(INF_CohortName)\n",
    "INF_OneCohortArgs = CohortName_to_OneCohortArgs[INF_CohortName]\n",
    "print(INF_OneCohortArgs)\n",
    "\n",
    "Package_Settings = {\n",
    "    'INF_CohortName': INF_CohortName,\n",
    "    'INF_OneCohortArgs': INF_OneCohortArgs,\n",
    "    'Record_Proc_Config': Record_Proc_Config,\n",
    "    'Case_Proc_Config': Case_Proc_Config,\n",
    "    'OneEntryArgs_items_for_inference': OneEntryArgs_items_for_inference,\n",
    "    'get_ROCOGammePhiInfo_from_CFList': get_ROCOGammePhiInfo_from_CFList,\n",
    "    'load_model_instance_from_nn': load_model_instance_from_nn,\n",
    "    'Model_Base': Model_Base,\n",
    "    'AIData_Base': AIData_Base,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.utils_inference import load_AIData_Model_InfoSettings\n",
    "\n",
    "\n",
    "results = load_AIData_Model_InfoSettings(\n",
    "    ModelEndpoint_Path = ModelEndpoint_Path, \n",
    "    InputCFArgs_ForInference = InputCFArgs_ForInference,\n",
    "    InferenceArgs = InferenceArgs,\n",
    "    SPACE = SPACE, \n",
    "    **Package_Settings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = results['model_base']\n",
    "aidata_base = results['aidata_base']\n",
    "InfoSettings = results['InfoSettings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: record_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i for i in Inference_Entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "from recfldtkn.record_base import Record_Base\n",
    "from config.config_record.Cohort import CohortName_to_OneCohortArgs\n",
    "\n",
    "\n",
    "TriggerCaseBaseName_to_TriggerCaseBaseArgs = InfoSettings['TriggerCaseBaseName_to_TriggerCaseBaseArgs']\n",
    "\n",
    "s = datetime.now()\n",
    "record_base = Record_Base(CohortName_list, \n",
    "                            HumanRecordRecfeat_Args,\n",
    "                            CohortName_to_OneCohortArgs,\n",
    "                            SPACE = SPACE, \n",
    "                            Inference_Entry = Inference_Entry,\n",
    "                            Record_Proc_Config = Record_Proc_Config,\n",
    "                            )\n",
    "e = datetime.now()\n",
    "du1 = e-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_base.CohortName_to_OneCohortRecordBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_cohort_recordbase = record_base.CohortName_to_OneCohortRecordBase[CohortName]\n",
    "one_cohort_recordbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_cohort_recordbase.TriggerName_to_dfCaseTrigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: case_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.case_base import Case_Base\n",
    "\n",
    "\n",
    "s = datetime.now()\n",
    "case_base = Case_Base(\n",
    "    record_base = record_base, \n",
    "    TriggerCaseBaseName_to_CohortNameList = TriggerCaseBaseName_to_CohortNameList, \n",
    "    TriggerCaseBaseName_to_TriggerCaseBaseArgs = TriggerCaseBaseName_to_TriggerCaseBaseArgs,\n",
    "    Case_Proc_Config = Case_Proc_Config,\n",
    "    Case_Args_Settings = Case_Args_Settings, \n",
    ")\n",
    "e = datetime.now()\n",
    "du2 = e-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_base.TriggerCaseBaseName_to_CFtoCFvocab\n",
    "\n",
    "for TriggerCaseBaseName, CF_to_CFVocab in case_base.TriggerCaseBaseName_to_CFtoCFvocab.items():\n",
    "    print(TriggerCaseBaseName)\n",
    "    print({k: len(v['input_ids']['tid2tkn']) for k, v in CF_to_CFVocab.items()})\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "case_base.TriggerCaseBaseName_to_CFtoCFvocab\n",
    "\n",
    "for TriggerCaseBaseName, CaseSetName_to_CaseSet in case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset.items():\n",
    "    print(TriggerCaseBaseName)\n",
    "    for CaseSetName, caseset in CaseSetName_to_CaseSet.items():\n",
    "        print(CaseSetName)\n",
    "        display(caseset.df_case)\n",
    "        display(caseset.ds_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: aidata_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "aidata_base.update_CaseBase(case_base)\n",
    "e = datetime.now()\n",
    "du3 = e-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIDataName_list = aidata_base.get_AIDataName_list()\n",
    "AIDataName_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneAIDataName = AIDataName_list[0]\n",
    "OneAIDataName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata = aidata_base.get_aidata_from_OneAIDataName(OneAIDataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata.INPUT_CFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata_base.get_AIDataName_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for OneAIDataHash, aidata in aidata_base.OneAIDataHash_to_AIData.items():\n",
    "    print(OneAIDataHash)\n",
    "    for Name, Data in aidata.Name_to_Data.items():\n",
    "        ds_tfm = Data['ds_tfm']\n",
    "        print(Name)\n",
    "        print(ds_tfm)\n",
    "        print()\n",
    "\n",
    "\n",
    "# (0, 0)\t1.0305\n",
    "# (0, 1)\t1.8262\n",
    "# (0, 2)\t11.2388\n",
    "# (0, 3)\t1.878\n",
    "# (0, 4)\t5.3921\n",
    "# (0, 5)\t116.3415\n",
    "# (0, 6)\t5.7057\n",
    "# (0, 7)\t194.8415\n",
    "# (0, 8)\t1.5461\n",
    "# (0, 9)\t0.4845\n",
    "# (0, 10)\t0.9927\n",
    "# (0, 11)\t0.0609\n",
    "# (0, 12)\t15.4268\n",
    "# (0, 13)\t119.5366\n",
    "# (0, 14)\t3.0037\n",
    "# (0, 33)\t230.7333\n",
    "# (0, 36)\t1.0\n",
    "# (0, 37)\t0.7\n",
    "# (0, 38)\t1.0\n",
    "# (0, 39)\t0.5615\n",
    "# (0, 40)\t1.0\n",
    "# (0, 41)\t0.6357\n",
    "# (0, 46)\t1.0\n",
    "# (0, 47)\t0.25\n",
    "# (0, 58)\t1.0\n",
    "# :\t:\n",
    "# (0, 1023)\t0.4787\n",
    "# (0, 1024)\t0.9807\n",
    "# (0, 1025)\t0.0602\n",
    "# (0, 1026)\t15.3012\n",
    "# (0, 1027)\t118.0964\n",
    "# (0, 1028)\t3.1\n",
    "# (0, 1047)\t230.7333\n",
    "# (0, 1050)\t1.0\n",
    "# (0, 1051)\t0.7\n",
    "# (0, 1052)\t1.0\n",
    "# (0, 1053)\t0.5615\n",
    "# (0, 1054)\t1.0\n",
    "# (0, 1055)\t0.5625\n",
    "# (0, 1060)\t1.0\n",
    "# (0, 1061)\t0.25\n",
    "# (0, 1072)\t1.0\n",
    "# (0, 1076)\t2.0515\n",
    "# (0, 1078)\t1053.4574\n",
    "# (0, 1080)\t1.0\n",
    "# (0, 1081)\t1.0\n",
    "# (0, 1083)\t0.5866\n",
    "# (0, 1086)\t2625.72\n",
    "# (0, 1101)\t1.0\n",
    "# (0, 1107)\t1.0\n",
    "# (0, 1114)\t1.0\n",
    "\n",
    "print(ds_tfm['X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InferenceArgs = InfoSettings['InferenceArgs']\n",
    "\n",
    "pprint(InferenceArgs, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "# model_base.update_AIDataBase(aidata_base, update_df_modelinstance = False)\n",
    "######## update te aidata_base to model_base ########\n",
    "model_base.aidata_base = aidata_base\n",
    "ModelArtifactName_to_ModelInfo = model_base.ModelArtifactName_to_ModelInfo\n",
    "ModelArtifactName_to_Inference = {}\n",
    "for model_artifact_name, ModelInfo in ModelArtifactName_to_ModelInfo.items():\n",
    "    model_artifact = ModelInfo['model_artifact']\n",
    "    OneAIDataName = model_artifact.aidata.OneAIDataName\n",
    "    aidata = aidata_base.get_aidata_from_OneAIDataName(OneAIDataName)\n",
    "    Name = [i for i in aidata.Name_to_Data][0]\n",
    "    Data = aidata.Name_to_Data[Name]\n",
    "    inference = model_artifact.inference(Data, InferenceArgs)\n",
    "    # model_instance.model_checkpoint_name\n",
    "    ModelArtifactName_to_Inference[model_artifact.model_artifact_name] = inference\n",
    "e = datetime.now()\n",
    "du4 = e-s\n",
    "\n",
    "total_time = du1 + du2 + du3 + du4\n",
    "print('record_base:', du1)\n",
    "print('case_base:', du2)\n",
    "print('aidata_base and model_base update:', du3)\n",
    "print('model_infernece:', du4)\n",
    "print('total_time:', total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata.EntryArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ModelArtifactName_to_Inference)\n",
    "# {'weightpred/UniLabelPred-weightpred.Af1w-WeightPred.Af1M.WeightLossPctLarge2-XGBClassifierV0.6-2024.10.15-556770446746a3d1': {'y_pred_score': array([0.00042053], dtype=float32)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: pipeline_inference_for_modelbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.utils_inference import pipeline_inference_for_modelbase\n",
    "\n",
    "inference_results = pipeline_inference_for_modelbase(Inference_Entry,\n",
    "                                                    Record_Base,\n",
    "                                                    Case_Base,\n",
    "                                                    aidata_base, \n",
    "                                                    model_base,\n",
    "                                                    InfoSettings, \n",
    "                                                    SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(inference_results, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: PostFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timezone\n",
    "\n",
    "# def PostFn_WithActionDict_v1121(ModelArtifactName_to_Inference, SPACE):\n",
    "#     output = {\"models\": [], \"status\": {\"code\": 200, \"message\": \"Success\"}}\n",
    "\n",
    "#     for model_artifact_name, data in ModelArtifactName_to_Inference.items():\n",
    "#         parts = model_artifact_name.split('__')\n",
    "\n",
    "#         OneAIDataName, OneModelJobName, FingerPrint = parts[0], parts[1], parts[2]\n",
    "\n",
    "\n",
    "#         OneDataName, OneDataVarientName = OneAIDataName.split('/')\n",
    "#         # Extract model details\n",
    "#         # model_name = '-'.join(parts[:2])  # e.g., Jardiance/UniLabelPred-Jardiance.RxAf1w\n",
    "#         # model_name = model_name.split('/')[0].lower()\n",
    "#         name = OneDataVarientName\n",
    "#         # date = parts[4]  # e.g., 2024.11.03\n",
    "#         # date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#         date = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "#         # version = parts[3]  # e.g., XGBClassifierV0.6\n",
    "        \n",
    "#         version = SPACE['MODEL_ENDPOINT']\n",
    "#         prediction_name = parts[2].replace(\"Rx.\", \"\")  # e.g., Rx.Learn\n",
    "#         # score = data['y_pred_score_percentile'][0]\n",
    "#         score = data['y_pred_score'][0]\n",
    "\n",
    "#         # Find or create model entry\n",
    "#         model_entry = next((model for model in output[\"models\"] if model[\"name\"] == name), None)\n",
    "#         if not model_entry:\n",
    "#             model_entry = {\"name\": name, \"date\": date, \"version\": version, \"predictions\": [], \"action\": \"\"}\n",
    "#             output[\"models\"].append(model_entry)\n",
    "\n",
    "#         # Append prediction details\n",
    "#         model_entry[\"predictions\"].append({\"name\": prediction_name, \"score\": score})\n",
    "\n",
    "#     # Set the label as the name of the prediction with the highest score for each model\n",
    "#     for model in output[\"models\"]:\n",
    "#         if model[\"predictions\"]:\n",
    "#             max_prediction = max(model[\"predictions\"], key=lambda x: x[\"score\"])\n",
    "#             model[\"action\"] = {'name': max_prediction[\"name\"], 'score': max_prediction[\"score\"]}\n",
    "\n",
    "#     return output\n",
    "\n",
    "\n",
    "# PostFn = PostFn_WithActionDict_v1121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timezone\n",
    "\n",
    "def PostFn_None(ModelArtifactName_to_Inference, SPACE):\n",
    "\n",
    "    return ModelArtifactName_to_Inference\n",
    "\n",
    "PostFn = PostFn_None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = PostFn(ModelArtifactName_to_Inference, SPACE)\n",
    "\n",
    "pprint(output, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}