{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "\n",
    "from datasets import disable_caching, disable_progress_bars\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'; WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY; os.chdir(WORKSPACE_PATH)\n",
    "\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN']); SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "\n",
    "disable_caching()\n",
    "disable_progress_bars()\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.record_base.cohort import CohortFn, Cohort\n",
    "from config.config_record.Cohort import CohortName_to_OneCohortArgs\n",
    "\n",
    "\n",
    "CohortName = '20241013_InferencePttSampleV0'\n",
    "CohortName_list = [CohortName]\n",
    "CohortName_list_for_inference = CohortName_list\n",
    "OneEntryArgs_items_for_inference = ['Input_Part']\n",
    "\n",
    "Record_Proc_Config = {\n",
    "    'save_data': False, \n",
    "    'load_data':False, \n",
    "    'via_method': 'df'\n",
    "}\n",
    "\n",
    "Case_Proc_Config = {\n",
    "    'max_trigger_case_num': None, \n",
    "    'use_task_cache': True, \n",
    "    'caseset_chunk_size': 50000,\n",
    "    'save_data': False, \n",
    "    'load_data': False, \n",
    "    'load_casecollection': False,\n",
    "    'via_method': 'df',\n",
    "    'n_cpus': 1, \n",
    "    'batch_size': None,  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an Inference_Entry\n",
    "################\n",
    "# replace this part with the API input. \n",
    "OneCohort_Args = CohortName_to_OneCohortArgs[CohortName]\n",
    "\n",
    "\n",
    "Source2CohortName = OneCohort_Args['Source2CohortName']\n",
    "cohort_fn = CohortFn(Source2CohortName, SPACE)\n",
    "cohort = Cohort(OneCohort_Args, SPACE, cohort_fn)\n",
    "cohort.setup_fn(cohort_fn)\n",
    "cohort.initialize_cohort()\n",
    "\n",
    "# Get Inference_Entry\n",
    "SourceFile_List = cohort.SourceFile_List\n",
    "OneCohort_Args = cohort.OneCohort_Args\n",
    "get_RawName_from_SourceFile = cohort.get_RawName_from_SourceFile\n",
    "get_InferenceEntry = cohort.cohort_fn.get_InferenceEntry\n",
    "Inference_Entry = get_InferenceEntry(OneCohort_Args, \n",
    "                                     SourceFile_List, \n",
    "                                     get_RawName_from_SourceFile)\n",
    "\n",
    "pprint(Inference_Entry['template_form'], sort_dicts=False, compact=True)\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i for i in Inference_Entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.record_base.record import Record, RecordFn\n",
    "\n",
    "TriggerRecordName = 'CGM5Min'\n",
    "Rec_Fn = RecordFn(TriggerRecordName, SPACE)\n",
    "\n",
    "pprint(Rec_Fn.RawName_to_RawConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TriggerFn_CGM5MinEntry_v1211(inference_form):\n",
    "    ########### ------ build the df_case and save to the Inference_Entry ------ ###########\n",
    "    TriggerName = 'CGM5MinEntry'\n",
    "\n",
    "    DBTableName = 'ElogBGEntry'\n",
    "    df_recraw = pd.DataFrame(inference_form[DBTableName])\n",
    "    case = df_recraw.iloc[-1]\n",
    "    PatientID = case['PatientID']\n",
    "    TimezoneOffset = case['TimezoneOffset']\n",
    "    ObsDT = case['ObservationDateTime'] #### this time should be adjusted with \n",
    "    ObsDTLocal = pd.to_datetime(ObsDT) + pd.Timedelta(TimezoneOffset, unit='m')\n",
    "    case = {\n",
    "        'PatientID': PatientID,\n",
    "        'ObsDT': ObsDTLocal, # must be local, because the processed data to model is local as well.\n",
    "    }\n",
    "\n",
    "    CaseTriggerList = [case]\n",
    "    TriggerName_to_CaseTriggerList = {\n",
    "        TriggerName: CaseTriggerList,\n",
    "    }\n",
    "    return TriggerName_to_CaseTriggerList\n",
    "\n",
    "inferece_form_name = [i for i in Inference_Entry if 'inference_form' in i][0]\n",
    "inference_form = Inference_Entry[inferece_form_name]\n",
    "TriggerName_to_CaseTriggerList = TriggerFn_CGM5MinEntry_v1211(inference_form)\n",
    "TriggerName_to_dfCaseTrigger = {TriggerName: pd.DataFrame(CaseTriggerList) for TriggerName, CaseTriggerList in TriggerName_to_CaseTriggerList.items()}\n",
    "Inference_Entry['TriggerName_to_dfCaseTrigger'] = TriggerName_to_dfCaseTrigger\n",
    "TriggerName_to_dfCaseTrigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ENDPOINT = 'vTestCGMFull'\n",
    "SPACE['MODEL_ENDPOINT'] = MODEL_ENDPOINT\n",
    "pprint(SPACE, sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Model_Base from a Model Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.model_base.model_base import Model_Base\n",
    "from nn import load_model_instance_from_nn\n",
    "\n",
    "ModelEndpoint_Path = os.path.join(SPACE['MODEL_ROOT'], SPACE['MODEL_ENDPOINT'])\n",
    "model_base = Model_Base(\n",
    "    ModelEndpoint_Path = ModelEndpoint_Path,\n",
    "    load_model_instance_from_nn = load_model_instance_from_nn,\n",
    "    SPACE = SPACE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(model_base.ModelArtifactName_to_ModelInfo, sort_dicts=False, compact=True)\n",
    "\n",
    "for model_artifact_name, ModelInfo in model_base.ModelArtifactName_to_ModelInfo.items():\n",
    "    # model_instance \n",
    "    print(model_artifact_name)\n",
    "    model_artifact = ModelInfo['model_artifact']\n",
    "    print({k: len(v['input_ids']['tid2tkn']) for k, v in model_artifact.aidata.CF_to_CFvocab.items()})\n",
    "    # pprint(model_instance.aidata.EntryArgs['Input_FullArgs'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. InfoSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.utils_inference import get_complete_InfoSettings\n",
    "\n",
    "################### The things you need to provide in advance. \n",
    "# InputCFArgs_ForInference = None\n",
    "InputCFArgs_ForInference = ['cf.TargetCGM_Bf24H'] # to remove in the future\n",
    "###################\n",
    "\n",
    "InfoSettings = get_complete_InfoSettings(model_base, CohortName_list, InputCFArgs_ForInference)\n",
    "\n",
    "print([i for i in InfoSettings])\n",
    "pprint(InfoSettings['TriggerCaseBaseName_to_TriggerCaseBaseArgs'], sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. AIData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.aidata_base import AIData_Base   \n",
    "\n",
    "OneAIDataName_to_OneAIDataArgs = InfoSettings['OneAIDataName_to_OneAIDataArgs']\n",
    "pprint({k:v['OneEntryArgs'] for k, v in OneAIDataName_to_OneAIDataArgs.items()}, sort_dicts=False, compact=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneAIDataName = [i for i in OneAIDataName_to_OneAIDataArgs][0]\n",
    "OneAIDataArgs = OneAIDataName_to_OneAIDataArgs[OneAIDataName]\n",
    "[i for i in OneAIDataArgs['OneEntryArgs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in OneAIDataName_to_OneAIDataArgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata_base = AIData_Base(\n",
    "    OneAIDataName_to_OneAIDataArgs = OneAIDataName_to_OneAIDataArgs,\n",
    "    OneEntryArgs_items_for_inference = OneEntryArgs_items_for_inference,\n",
    "    CohortName_list_for_inference = CohortName_list_for_inference, \n",
    "    SPACE = SPACE, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneAIDataName = aidata_base.get_AIDataName_list()[0]\n",
    "OneAIDataArgs = aidata_base.get_OneAIDataArgs_from_OneAIDataName(OneAIDataName)\n",
    "\n",
    "OneEntryArgs = OneAIDataArgs['OneEntryArgs']\n",
    "pprint(OneEntryArgs, sort_dicts=False, compact=True)\n",
    "aidata = aidata_base.get_aidata_from_OneAIDataName(OneAIDataName)\n",
    "aidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata_base.get_AIDataHashName_list()\n",
    "Name_to_Data = aidata.Name_to_Data\n",
    "[i for i in Name_to_Data]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: CF, HRF, TriggerCaseBaseName_to_CohortNameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneAIDataArgs['OneEntryArgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.case_base.caseutils import get_ROCOGammePhiInfo_from_CFList\n",
    "\n",
    "Case_Args_Settings = InfoSettings['Case_Args_Settings']\n",
    "CF_to_CFArgs = Case_Args_Settings['CF_to_CFArgs']\n",
    "TagCF_to_TagCFArgs = Case_Args_Settings.get('TagCF_to_TagCFArgs', {})\n",
    "\n",
    "CF_list_ForInference = InfoSettings['CF_list_ForInference'] # (aidata_base, CF_to_CFArgs, TagCF_to_TagCFArgs)\n",
    "pprint(CF_list_ForInference, sort_dicts=False)\n",
    "\n",
    "ROCOGammaPhiInfo = get_ROCOGammePhiInfo_from_CFList(CF_list_ForInference, CF_to_CFArgs)\n",
    "HumanRecordRecfeat_Args = ROCOGammaPhiInfo['HumanRecordRecfeat_Args']\n",
    "pprint(HumanRecordRecfeat_Args, sort_dicts=False)\n",
    "\n",
    "\n",
    "TriggerCaseBaseName_List = list(set([v['TriggerCaseBaseName'] for k, v in OneAIDataName_to_OneAIDataArgs.items()]))\n",
    "TriggerCaseBaseName_to_CohortNameList = {}\n",
    "for TriggerCaseBaseName in TriggerCaseBaseName_List:\n",
    "    TriggerCaseBaseName_to_CohortNameList[TriggerCaseBaseName] = CohortName_list\n",
    "\n",
    "pprint(TriggerCaseBaseName_to_CohortNameList, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: load AIData Model InfoSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelEndpoint_Path = ModelEndpoint_Path\n",
    "print(ModelEndpoint_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputCFArgs_ForInference = InputCFArgs_ForInference\n",
    "print(InputCFArgs_ForInference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InferenceArgs = {\n",
    "    'GEN_Args': {\n",
    "        'num_first_tokens_for_gen': 289,\n",
    "        'max_new_tokens': 24,\n",
    "        'do_sample': False,\n",
    "        'items_list': ['hist', 'pred', 'logit_scores']}\n",
    "    }\n",
    "\n",
    "print(InferenceArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INF_CohortName = CohortName \n",
    "print(INF_CohortName)\n",
    "INF_OneCohortArgs = CohortName_to_OneCohortArgs[INF_CohortName]\n",
    "print(INF_OneCohortArgs)\n",
    "\n",
    "Package_Settings = {\n",
    "    'INF_CohortName': INF_CohortName,\n",
    "    'INF_OneCohortArgs': INF_OneCohortArgs,\n",
    "    'Record_Proc_Config': Record_Proc_Config,\n",
    "    'Case_Proc_Config': Case_Proc_Config,\n",
    "    'OneEntryArgs_items_for_inference': OneEntryArgs_items_for_inference,\n",
    "    'get_ROCOGammePhiInfo_from_CFList': get_ROCOGammePhiInfo_from_CFList,\n",
    "    'load_model_instance_from_nn': load_model_instance_from_nn,\n",
    "    'Model_Base': Model_Base,\n",
    "    'AIData_Base': AIData_Base,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.utils_inference import load_AIData_Model_InfoSettings\n",
    "\n",
    "Context = load_AIData_Model_InfoSettings(\n",
    "    ModelEndpoint_Path = ModelEndpoint_Path, \n",
    "    InputCFArgs_ForInference = InputCFArgs_ForInference,\n",
    "    InferenceArgs = InferenceArgs,\n",
    "    SPACE = SPACE, \n",
    "    **Package_Settings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = Context['model_base']\n",
    "aidata_base = Context['aidata_base']\n",
    "InfoSettings = Context['InfoSettings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: record_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i for i in Inference_Entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "from recfldtkn.record_base import Record_Base\n",
    "from config.config_record.Cohort import CohortName_to_OneCohortArgs\n",
    "\n",
    "\n",
    "TriggerCaseBaseName_to_TriggerCaseBaseArgs = InfoSettings['TriggerCaseBaseName_to_TriggerCaseBaseArgs']\n",
    "\n",
    "s = datetime.now()\n",
    "record_base = Record_Base(CohortName_list, \n",
    "                            HumanRecordRecfeat_Args,\n",
    "                            CohortName_to_OneCohortArgs,\n",
    "                            SPACE = SPACE, \n",
    "                            Inference_Entry = Inference_Entry,\n",
    "                            Record_Proc_Config = Record_Proc_Config,\n",
    "                            )\n",
    "e = datetime.now()\n",
    "du1 = e-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_base.CohortName_to_OneCohortRecordBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_cohort_recordbase = record_base.CohortName_to_OneCohortRecordBase[CohortName]\n",
    "one_cohort_recordbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_cohort_recordbase.TriggerName_to_dfCaseTrigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: case_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.case_base import Case_Base\n",
    "\n",
    "# there is no P-Demo. \n",
    "s = datetime.now()\n",
    "case_base = Case_Base(\n",
    "    record_base = record_base, \n",
    "    TriggerCaseBaseName_to_CohortNameList = TriggerCaseBaseName_to_CohortNameList, \n",
    "    TriggerCaseBaseName_to_TriggerCaseBaseArgs = TriggerCaseBaseName_to_TriggerCaseBaseArgs,\n",
    "    Case_Proc_Config = Case_Proc_Config,\n",
    "    Case_Args_Settings = Case_Args_Settings, \n",
    ")\n",
    "e = datetime.now()\n",
    "du2 = e-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_base.TriggerCaseBaseName_to_CFtoCFvocab\n",
    "\n",
    "\n",
    "for TriggerCaseBaseName, CF_to_CFVocab in case_base.TriggerCaseBaseName_to_CFtoCFvocab.items():\n",
    "    print(TriggerCaseBaseName)\n",
    "    print({k: len(v['input_ids']['tid2tkn']) for k, v in CF_to_CFVocab.items()})\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "case_base.TriggerCaseBaseName_to_CFtoCFvocab\n",
    "\n",
    "for TriggerCaseBaseName, CaseSetName_to_CaseSet in case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset.items():\n",
    "    print(TriggerCaseBaseName)\n",
    "    for CaseSetName, caseset in CaseSetName_to_CaseSet.items():\n",
    "        print(CaseSetName)\n",
    "        display(caseset.df_case)\n",
    "        display(caseset.ds_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(caseset.ds_case.iloc[0]['cf.TargetCGM_Bf24H--input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: aidata_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "aidata_base.update_CaseBase(case_base)\n",
    "e = datetime.now()\n",
    "du3 = e-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIDataName_list = aidata_base.get_AIDataName_list()\n",
    "AIDataName_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneAIDataName = AIDataName_list[0]\n",
    "OneAIDataName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata_base.case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata = aidata_base.get_aidata_from_OneAIDataName(OneAIDataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata.INPUT_CFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata_base.get_AIDataName_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for OneAIDataHash, aidata in aidata_base.OneAIDataHash_to_AIData.items():\n",
    "    print(OneAIDataHash)\n",
    "    for Name, Data in aidata.Name_to_Data.items():\n",
    "        ds_tfm = Data['ds_tfm']\n",
    "        print(Name)\n",
    "        print(ds_tfm)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "InferenceArgs = {\n",
    "    'GEN_Args': {\n",
    "        'num_first_tokens_for_gen': 289,\n",
    "        'max_new_tokens': 24,\n",
    "        'do_sample': False,\n",
    "        'items_list': ['hist', 'pred', 'logit_scores']}\n",
    "    }\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in model_base.ModelArtifactName_to_ModelInfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "# model_base.update_AIDataBase(aidata_base, update_df_modelinstance = False)\n",
    "\n",
    "######## update te aidata_base to model_base ########\n",
    "model_base.aidata_base = aidata_base\n",
    "\n",
    "\n",
    "ModelArtifactName_to_ModelInfo = model_base.ModelArtifactName_to_ModelInfo\n",
    "ModelArtifactName_to_Inference = {}\n",
    "for model_artifact_name, ModelInfo in ModelArtifactName_to_ModelInfo.items():\n",
    "    # OneAIDataName = modelinstanceinfo['OneAIDataName']\n",
    "    # model_instance = modelinstanceinfo['model_instance']\n",
    "    model_artifact = ModelInfo['model_artifact']\n",
    "\n",
    "    OneAIDataName = model_artifact.aidata.OneAIDataName\n",
    "    aidata = aidata_base.get_aidata_from_OneAIDataName(OneAIDataName)\n",
    "    Name = [i for i in aidata.Name_to_Data][0]\n",
    "    Data = aidata.Name_to_Data[Name]\n",
    "    logger.info('Start inference process....')\n",
    "    inference = model_artifact.inference(Data, InferenceArgs)\n",
    "    # model_instance.model_checkpoint_name\n",
    "    ModelArtifactName_to_Inference[model_artifact.model_artifact_name] = inference\n",
    "e = datetime.now()\n",
    "du4 = e-s\n",
    "\n",
    "total_time = du1 + du2 + du3 + du4\n",
    "print('record_base:', du1)\n",
    "print('case_base:', du2)\n",
    "print('aidata_base and model_base update:', du3)\n",
    "print('model_infernece:', du4)\n",
    "print('total_time:', total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ModelArtifactName_to_Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact_name = [i for i in ModelArtifactName_to_Inference][0]\n",
    "\n",
    "InferenceInfo = ModelArtifactName_to_Inference[model_artifact_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InferenceInfo['df_case_eval'].iloc[0]['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InferenceInfo['df_case_eval'].iloc[0]['pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: pipeline_inference_for_modelbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.utils_inference import pipeline_inference_for_modelbase\n",
    "\n",
    "inference_results = pipeline_inference_for_modelbase(Inference_Entry,\n",
    "                                                    Record_Base,\n",
    "                                                    Case_Base,\n",
    "                                                    aidata_base, \n",
    "                                                    model_base,\n",
    "                                                    InfoSettings, \n",
    "                                                    SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(inference_results, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArtifactName_to_Inference = inference_results['ModelArtifactName_to_Inference']\n",
    "ModelArtifactName_to_Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArtifactName = [i for i in ModelArtifactName_to_Inference][0]\n",
    "InferenceInfo = ModelArtifactName_to_Inference[ModelArtifactName]\n",
    "InferenceInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = InferenceInfo['df_case_eval']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: PostFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timezone\n",
    "\n",
    "def PostFn_WithCGMPred_v1210(ModelArtifactName_to_Inference, SPACE):\n",
    "    # output = {\"models\": [], \"status\": {\"code\": 200, \"message\": \"Success\"}}\n",
    "    assert len(ModelArtifactName_to_Inference) == 1, \"Only one model is supported for now\"\n",
    "\n",
    "    ModelArtifactName = [i for i in ModelArtifactName_to_Inference][0]\n",
    "    InferenceInfo = ModelArtifactName_to_Inference[ModelArtifactName]\n",
    "    df = InferenceInfo['df_case_eval']\n",
    "\n",
    "    hist = df.iloc[0]['hist']\n",
    "    pred = df.iloc[0]['pred']\n",
    "    output = {\"hist\": hist, \"pred\": pred}\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "PostFn = PostFn_WithCGMPred_v1210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = PostFn(ModelArtifactName_to_Inference, SPACE)\n",
    "\n",
    "pprint(output, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}