{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881d73c8-f12f-4a9b-a485-996a76289767",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b19d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "SPACE['MODEL_ENDPOINT'] = 'vTest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57492949",
   "metadata": {},
   "source": [
    "# Part 1: AIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Oneday: 288, 24pd. 1/12\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "# 24 / 288\n",
    "\n",
    "# AIDataName = 'CGM_32h_24pd_WellDoc_v2_v0323' # CGM, 32h, 24 data per day. \n",
    "AIDataName = 'CGM_32h_24pd_WellDoc_v2_sample' # CGM, 32h, 24 data per day. \n",
    "\n",
    "\n",
    "path = os.path.join(SPACE['DATA_AIDATA'], AIDataName)\n",
    "print(path)\n",
    "dataset = load_from_disk(path)\n",
    "# dataset\n",
    "\n",
    "config = dataset.info.__dict__['config_name']# .features['cf'].feature.vocab\n",
    "print([i for i in config])\n",
    "CF_to_CFvocab = config['CF_to_CFvocab']\n",
    "print([i for i in CF_to_CFvocab])\n",
    "\n",
    "CF_to_CFArgs = config['CaseSettingInfo']['Case_Args_Settings']['CF_to_CFArgs']\n",
    "print([i for i in CF_to_CFArgs])\n",
    "\n",
    "\n",
    "TriggerCaseBaseName = config['TriggerCaseBaseName']\n",
    "TriggerCaseBaseArgs = config['TriggerCaseBaseName_to_TriggerCaseBaseArgs'][TriggerCaseBaseName]\n",
    "TriggerName = TriggerCaseBaseArgs['Trigger']['TriggerName']\n",
    "TriggerName\n",
    "# print(TriggerCaseBaseArgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tag.columns\n",
    "\n",
    "from recfldtkn.base import assign_caseSplitTag_to_dsCase\n",
    "from recfldtkn.base import apply_multiple_conditions\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "columns = dataset.column_names\n",
    "columns_tag = [i for i in columns if '--' not in i]\n",
    "df_tag = dataset.select_columns(columns_tag).to_pandas()\n",
    "\n",
    "def map_age_to_agegroup(age):\n",
    "    if age < 18:\n",
    "        return '0-17'\n",
    "    elif 18<= age < 40:\n",
    "        return '18-39'\n",
    "    elif 40<= age < 65:\n",
    "        return '40-64'\n",
    "    else:\n",
    "        return '65+'\n",
    "    \n",
    "###### additional tagging columns \n",
    "df_tag['Year'] = df_tag['ObsDT'].dt.year\n",
    "df_tag['Cohort'] = df_tag['PID'].astype(str).str[0]\n",
    "df_tag['Age'] = df_tag['Year'] - df_tag['YearOfBirth']  # .dt.year\n",
    "df_tag['AgeGroup'] = df_tag['Age'].apply(map_age_to_agegroup)\n",
    "##########################\n",
    "\n",
    "\n",
    "dataset = dataset.add_column('Age', df_tag['Age'].values)\n",
    "dataset = dataset.add_column('Cohort', df_tag['Cohort'].values)\n",
    "dataset = dataset.add_column('Year', df_tag['Year'].values)\n",
    "dataset = dataset.add_column('AgeGroup', df_tag['AgeGroup'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a274280",
   "metadata": {},
   "outputs": [],
   "source": [
    "Split_to_Selection = {\n",
    "    'Train': {\n",
    "        'Rules': [\n",
    "            ['Age', '>=', 40],\n",
    "            ['Cohort', 'in', ['1', '2', '3']], # <--- add Cohort column\n",
    "            ['Year', 'in', [2020, 2021, 2022, 2023]], # <--- add Year column\n",
    "            ['GenderGroup', 'in', ['Gender.1', 'Gender.2']], \n",
    "            ['ObsDT', '<', '2022-07-01'], \n",
    "            ['ObsDT', '>=', '2021-01-01'],\n",
    "        ], \n",
    "        'Op': 'and',\n",
    "    },\n",
    "    'Val': {\n",
    "        'Rules': [\n",
    "            ['Age', '>=', 40],\n",
    "            ['Cohort', 'in', ['1', '2', '3']], # <--- add Cohort column\n",
    "            ['Year', 'in', [2020, 2021, 2022, 2023]], # <--- add Year column\n",
    "            ['ObsDT', '<', '2023-01-01'], \n",
    "            ['ObsDT', '>=', '2022-07-01'],\n",
    "            ['GenderGroup', 'in', ['Gender.1', 'Gender.2']], \n",
    "        ], \n",
    "        'Op': 'and',\n",
    "    },\n",
    "    'Test': {\n",
    "        'Rules': [\n",
    "            ['Age', '>=', 40],\n",
    "            ['Cohort', 'in', ['1', '2', '3']], # <--- add Cohort column\n",
    "            ['Year', 'in', [2020, 2021, 2022, 2023]], # <--- add Year column\n",
    "            ['ObsDT', '>=', '2023-01-01'], \n",
    "            ['ObsDT', '<', '2024-01-01'],\n",
    "            ['GenderGroup', 'in', ['Gender.1', 'Gender.2']], \n",
    "        ], \n",
    "        'Op': 'and',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b755061",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_to_dataset = {}\n",
    "for split_name, Selection in Split_to_Selection.items():\n",
    "    # split_to_dataset[split_name] = dataset.filter(lambda x: apply_multiple_conditions(x, split_config['Rules'], split_config['Op']))\n",
    "    Rules = Selection['Rules']\n",
    "    Op = Selection['Op']\n",
    "\n",
    "    index = apply_multiple_conditions(df_tag, Rules, Op)\n",
    "    indices = np.where(index == 1)[0]\n",
    "    # len(indices)\n",
    "    dataset_selected = dataset.select(indices)\n",
    "    split_to_dataset[split_name] = dataset_selected\n",
    "\n",
    "split_to_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edaad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name_to_Data = {}\n",
    "for split, dataset in split_to_dataset.items():\n",
    "    Name_to_Data[split] = {'ds_case': dataset}\n",
    "Name_to_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc298692",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs = {\n",
    "     # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStepNoWgt',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "            # 'cf.TargetCGM_Af2Hto8H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'CausalLM',\n",
    "        'set_transform': True,\n",
    "        'num_proc': 4, \n",
    "    },\n",
    "\n",
    "    # 'Output_Part': {\n",
    "    #     'EntryOutputMethod': 'MaskedLM',\n",
    "    #     'MaskingRate': 0.15,\n",
    "    #     'set_transform': True,\n",
    "    #     'num_proc': 4, \n",
    "    # },\n",
    "\n",
    "    # 'Output_Part': {\n",
    "    #     'EntryOutputMethod': 'SupervisedFT',\n",
    "    #     'AfStepNum': 24, # 12, # assert AfterPeriods Af2H,so 12 * 2 = 24\n",
    "    #     'set_transform': True,\n",
    "    #     'num_proc': 4, \n",
    "    # },\n",
    "}\n",
    "\n",
    "from recfldtkn.aidata_base.entry import EntryAIData_Builder\n",
    "\n",
    "entry = EntryAIData_Builder(TriggerName = TriggerName, \n",
    "                            OneEntryArgs = OneEntryArgs, \n",
    "                            SPACE = SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03140aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name_to_Data = entry.setup_EntryFn_to_NameToData(Name_to_Data, CF_to_CFvocab, OneEntryArgs)\n",
    "# Name_to_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fcd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Name_to_Data['Train']\n",
    "\n",
    "# Data\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "batch = ds_tfm[:batch_size]\n",
    "batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1be4a",
   "metadata": {},
   "source": [
    "# Part 2: Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e151e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "[CF for CF in CF_to_CFvocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPart = OneEntryArgs['Input_Part']\n",
    "TargetField = InputPart['TargetField']\n",
    "# TimeField = InputPart['TimeField']\n",
    "# EventFields = InputPart['EventFields']\n",
    "\n",
    "\n",
    "CF_list = InputPart['CF_list']  \n",
    "# FieldList = [TimeField] + EventFields\n",
    "# FieldList\n",
    "\n",
    "# Field_to_CFs = {Field: [CF for CF in CF_list if Field in CF] for Field in FieldList}\n",
    "# Field_to_CFs\n",
    "\n",
    "\n",
    "CF_to_CFvocab = CF_to_CFvocab\n",
    "# Field_to_CFvocab = {Field: CF_to_CFvocab[CFs[0]] for Field, CFs in Field_to_CFs.items()}\n",
    "# Field_to_CFvocab\n",
    "\n",
    "\n",
    "# field_to_vocabsize = {Field: len(Field_to_CFvocab[Field]['input_ids']['tkn2tid']) for Field in FieldList}\n",
    "# field_to_vocabsize\n",
    "\n",
    "\n",
    "TargetField\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749664f4",
   "metadata": {},
   "source": [
    "### CgmLhmConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nn.cgmlhm.configuration_cgmlhm import CgmLhmConfig\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Any, List, Mapping, Optional\n",
    "\n",
    "from transformers import PreTrainedTokenizer, TensorType, is_torch_available\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "from transformers.onnx import OnnxConfigWithPast, PatchingSpec\n",
    "from transformers.utils import logging\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "class CgmLhmConfig(PretrainedConfig):\n",
    "    model_type = \"cgmlhm\"\n",
    "    keys_to_ignore_at_inference = [\"past_key_values\"]\n",
    "    attribute_map = {\n",
    "        'n_layer': 'tf_n_layer',\n",
    "        \"hidden_size\": \"n_embd\",\n",
    "        \"max_position_embeddings\": \"n_positions\",\n",
    "        \"num_attention_heads\": \"n_head\",\n",
    "        \"num_hidden_layers\": \"n_layer\",\n",
    "        \"layer_norm_epsilon\": \"layer_norm_eps\",\n",
    "        \"hidden_act\": \"activation_function\",\n",
    "        # \"hidden_dropout_prob\": \n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_embd=768,\n",
    "        initializer_range=0.02,\n",
    "        use_cache=True,\n",
    "\n",
    "        time_field = 'Time',\n",
    "\n",
    "        # lsm_config\n",
    "        lsm_n_positions=1024,\n",
    "        lsm_n_layer=12,\n",
    "        lsm_n_head=12,\n",
    "        lsm_n_inner=None,\n",
    "        lsm_activation_function=\"gelu_new\",\n",
    "        lsm_resid_pdrop=0.1,\n",
    "        lsm_embd_pdrop=0.1,\n",
    "        lsm_attn_pdrop=0.1,\n",
    "        lsm_layer_norm_epsilon=1e-5,\n",
    "        # lsm_initializer_range=0.02,\n",
    "        lsm_summary_type=\"cls_index\",\n",
    "        lsm_summary_use_proj=True,\n",
    "        lsm_summary_activation=None,\n",
    "        lsm_summary_proj_to_labels=True,\n",
    "        lsm_summary_first_dropout=0.1,\n",
    "        lsm_scale_attn_weights=True,\n",
    "        lsm_scale_attn_by_inverse_layer_idx=False,\n",
    "        lsm_reorder_and_upcast_attn=False,\n",
    "\n",
    "\n",
    "        # fieldeconder_settings.\n",
    "        fe_num_hidden_layers=6,\n",
    "        fe_timestep_lookback = 600,\n",
    "        fe_timestep_lookahead = 300,\n",
    "        fe_embd_pdrop = 0.1,\n",
    "        fe_use_field_type_embedding = True,\n",
    "        fe_num_attention_heads=12,\n",
    "        fe_intermediate_size=3072,\n",
    "        fe_hidden_act=\"gelu\",\n",
    "        fe_hidden_dropout_prob=0.1,\n",
    "        fe_attention_probs_dropout_prob=0.1,\n",
    "        fe_max_position_embeddings=512,\n",
    "        # fe_initializer_range=0.02,\n",
    "        fe_layer_norm_eps=1e-12,\n",
    "        fe_position_embedding_type=\"absolute\",\n",
    "        # fe_use_cache=True,\n",
    "        fe_classifier_dropout=None,\n",
    "\n",
    "\n",
    "        # step connector \n",
    "        sc_num_hidden_layers=2,\n",
    "        sc_num_attention_heads=12,\n",
    "        sc_intermediate_size=3072,\n",
    "        sc_hidden_act=\"gelu\",\n",
    "        sc_hidden_dropout_prob=0.1,\n",
    "        sc_attention_probs_dropout_prob=0.1,\n",
    "        sc_max_position_embeddings=512,\n",
    "        # sc_initializer_range=0.02,\n",
    "        sc_layer_norm_eps=1e-12,\n",
    "        sc_position_embedding_type=\"absolute\",\n",
    "        # sc_use_cache=True,\n",
    "        sc_classifier_dropout=None,\n",
    "        \n",
    "        # temporal fusor \n",
    "        tf_n_layer=4,\n",
    "        tf_n_head=12,\n",
    "        tf_n_inner=None,\n",
    "        tf_activation_function=\"gelu_new\",\n",
    "        tf_resid_pdrop=0.1,\n",
    "        tf_embd_pdrop=0.1,\n",
    "        tf_attn_pdrop=0.1,\n",
    "        tf_layer_norm_epsilon=1e-5,\n",
    "        # tf_initializer_range=0.02,\n",
    "        tf_summary_type=\"cls_index\",\n",
    "        tf_summary_use_proj=True,\n",
    "        tf_summary_activation=None,\n",
    "        tf_summary_proj_to_labels=True,\n",
    "        tf_summary_first_dropout=0.1,\n",
    "        tf_scale_attn_weights=True,\n",
    "        # tf_use_cache=True,\n",
    "        tf_scale_attn_by_inverse_layer_idx=False,\n",
    "        tf_reorder_and_upcast_attn=False,\n",
    "        \n",
    "        # entry_args = None, # Add this line\n",
    "        CF_to_CFvocab = None, # Add this line\n",
    "        OneEntryArgs = None, # Add this line\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_embd = n_embd\n",
    "        self.initializer_range = initializer_range\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "        self.time_field = time_field\n",
    "\n",
    "        self.lsm_n_embd = n_embd\n",
    "        self.lsm_n_positions = lsm_n_positions\n",
    "        self.lsm_n_layer = lsm_n_layer\n",
    "        self.lsm_n_head = lsm_n_head\n",
    "        self.lsm_n_inner = lsm_n_inner\n",
    "        self.lsm_activation_function = lsm_activation_function\n",
    "        self.lsm_resid_pdrop = lsm_resid_pdrop\n",
    "        self.lsm_embd_pdrop = lsm_embd_pdrop\n",
    "        self.lsm_attn_pdrop = lsm_attn_pdrop\n",
    "        self.lsm_layer_norm_epsilon = lsm_layer_norm_epsilon\n",
    "        self.lsm_initializer_range = initializer_range\n",
    "        self.lsm_summary_type = lsm_summary_type\n",
    "        self.lsm_summary_use_proj = lsm_summary_use_proj\n",
    "        self.lsm_summary_activation = lsm_summary_activation\n",
    "        self.lsm_summary_proj_to_labels = lsm_summary_proj_to_labels\n",
    "        self.lsm_summary_first_dropout = lsm_summary_first_dropout\n",
    "        self.lsm_scale_attn_weights = lsm_scale_attn_weights\n",
    "        self.lsm_use_cache = use_cache\n",
    "        self.lsm_scale_attn_by_inverse_layer_idx = lsm_scale_attn_by_inverse_layer_idx\n",
    "        self.lsm_reorder_and_upcast_attn = lsm_reorder_and_upcast_attn\n",
    "\n",
    "\n",
    "        self.fe_hidden_size = n_embd\n",
    "        self.fe_timestep_lookback = fe_timestep_lookback\n",
    "        self.fe_timestep_lookahead = fe_timestep_lookahead\n",
    "        self.fe_embd_pdrop = fe_embd_pdrop\n",
    "        self.fe_use_field_type_embedding = fe_use_field_type_embedding\n",
    "        self.fe_num_hidden_layers = fe_num_hidden_layers\n",
    "        self.fe_num_attention_heads = fe_num_attention_heads\n",
    "        self.fe_intermediate_size = fe_intermediate_size\n",
    "        self.fe_hidden_act = fe_hidden_act\n",
    "        self.fe_hidden_dropout_prob = fe_hidden_dropout_prob\n",
    "        self.fe_attention_probs_dropout_prob = fe_attention_probs_dropout_prob\n",
    "        self.fe_max_position_embeddings = fe_max_position_embeddings\n",
    "        self.fe_initializer_range = initializer_range\n",
    "        self.fe_layer_norm_eps = fe_layer_norm_eps\n",
    "        self.fe_position_embedding_type = fe_position_embedding_type\n",
    "        self.fe_use_cache = use_cache\n",
    "        self.fe_classifier_dropout = fe_classifier_dropout\n",
    "\n",
    "\n",
    "        self.sc_hidden_size = n_embd\n",
    "        self.sc_num_hidden_layers = sc_num_hidden_layers\n",
    "        self.sc_num_attention_heads = sc_num_attention_heads\n",
    "        self.sc_intermediate_size = sc_intermediate_size\n",
    "        self.sc_hidden_act = sc_hidden_act\n",
    "        self.sc_hidden_dropout_prob = sc_hidden_dropout_prob\n",
    "        self.sc_attention_probs_dropout_prob = sc_attention_probs_dropout_prob\n",
    "        self.sc_max_position_embeddings = sc_max_position_embeddings\n",
    "        self.sc_initializer_range = initializer_range\n",
    "        self.sc_layer_norm_eps = sc_layer_norm_eps\n",
    "        self.sc_position_embedding_type = sc_position_embedding_type\n",
    "        self.sc_use_cache = use_cache\n",
    "        self.sc_classifier_dropout = sc_classifier_dropout\n",
    "\n",
    "\n",
    "        self.n_layer = tf_n_layer\n",
    "        self.tf_n_embd = n_embd\n",
    "        self.tf_n_layer = tf_n_layer\n",
    "        self.tf_n_head = tf_n_head\n",
    "        self.tf_n_inner = tf_n_inner\n",
    "        self.tf_activation_function = tf_activation_function\n",
    "        self.tf_resid_pdrop = tf_resid_pdrop\n",
    "        self.tf_embd_pdrop = tf_embd_pdrop\n",
    "        self.tf_attn_pdrop = tf_attn_pdrop\n",
    "        self.tf_layer_norm_epsilon = tf_layer_norm_epsilon\n",
    "        self.tf_initializer_range = initializer_range\n",
    "        self.tf_summary_type = tf_summary_type\n",
    "        self.tf_summary_use_proj = tf_summary_use_proj\n",
    "        self.tf_summary_activation = tf_summary_activation\n",
    "        self.tf_summary_proj_to_labels = tf_summary_proj_to_labels\n",
    "        self.tf_summary_first_dropout = tf_summary_first_dropout\n",
    "        self.tf_scale_attn_weights = tf_scale_attn_weights\n",
    "        self.tf_use_cache = use_cache\n",
    "        self.tf_scale_attn_by_inverse_layer_idx = tf_scale_attn_by_inverse_layer_idx\n",
    "        self.tf_reorder_and_upcast_attn = tf_reorder_and_upcast_attn\n",
    "\n",
    "        self.OneEntryArgs = OneEntryArgs\n",
    "        self.CF_to_CFvocab = CF_to_CFvocab\n",
    "        if OneEntryArgs is not None and CF_to_CFvocab is not None:\n",
    "            self.initalize_field_info()\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def initalize_field_info(self):\n",
    "        if not hasattr(self, 'OneEntryArgs') or not hasattr(self, 'CF_to_CFvocab'):\n",
    "            return None \n",
    "        \n",
    "        # self.CF_to_CFvocab = CF_to_CFvocab\n",
    "        # self.Field_to_CFvocab = None\n",
    "\n",
    "        # self.set_field_info_with_OneEntryArgs(OneEntryArgs, CF_to_CFvocab)  \n",
    "        # self.entry_args = entry_args # Add this line\n",
    "\n",
    "        # self.OneEntryArgs = OneEntryArgs\n",
    "        # self.CF_to_CFvocab = CF_to_CFvocab\n",
    "        # print('in set_field_info_with_OneEntryArgs')\n",
    "        # print(OneEntryArgs)\n",
    "        # print(CF_to_CFvocab)\n",
    "\n",
    "        OneEntryArgs = self.OneEntryArgs\n",
    "        CF_to_CFvocab = self.CF_to_CFvocab\n",
    "        InputPart = OneEntryArgs['Input_Part']\n",
    "        TargetField = InputPart['TargetField']\n",
    "        TimeField = InputPart.get('TimeField', None)\n",
    "        EventFields = InputPart.get('EventFields', [])\n",
    "\n",
    "\n",
    "        CF_list = InputPart['CF_list']  \n",
    "\n",
    "        if TimeField is not None:\n",
    "            FieldList = [TimeField] + EventFields\n",
    "        else:\n",
    "            FieldList = EventFields\n",
    "        # FieldList\n",
    "\n",
    "        Field_to_CFs = {Field: [CF for CF in CF_list if Field in CF] for Field in FieldList}\n",
    "        # Field_to_CFs\n",
    "\n",
    "        Field_to_CFvocab = {Field: CF_to_CFvocab[CFs[0]] for Field, CFs in Field_to_CFs.items()}\n",
    "        # Field_to_CFvocab\n",
    "\n",
    "        # self.Field_to_CFvocab = Field_to_CFvocab  \n",
    "        field_to_fieldinfo = {}\n",
    "\n",
    "        for field in FieldList:\n",
    "            tkn2tid = Field_to_CFvocab[field]['input_ids']['tkn2tid']\n",
    "            # field_to_vocabsize = {field: len(tkn2tid)}\n",
    "            vocab_size = len(tkn2tid) \n",
    "            bos_token_id = tkn2tid['[BOS]']\n",
    "            eos_token_id = tkn2tid['[EOS]']\n",
    "            pad_token_id = 0\n",
    "            field_to_fieldinfo[field] = {\n",
    "                'vocab_size': vocab_size,\n",
    "                'bos_token_id': bos_token_id,\n",
    "                'eos_token_id': eos_token_id,\n",
    "                'pad_token_id': pad_token_id,\n",
    "            }\n",
    "\n",
    "        self.field_to_fieldinfo = field_to_fieldinfo\n",
    "\n",
    "\n",
    "        TargetField_CFs = [CF for CF in CF_list if TargetField in CF] \n",
    "        target_field_vocab = CF_to_CFvocab[TargetField_CFs[0]]\n",
    "        self.target_field_vocab = target_field_vocab\n",
    "        tkn2tid = target_field_vocab['input_ids']['tkn2tid']   \n",
    "        self.lsm_vocab_size = len(tkn2tid)\n",
    "        self.lsm_bos_token_id = tkn2tid['[BOS]']\n",
    "        self.lsm_eos_token_id = tkn2tid['[EOS]']\n",
    "        self.lsm_pad_token_id = 0\n",
    "\n",
    "        \n",
    "    def to_dict(self):\n",
    "        output = super().to_dict()\n",
    "        \n",
    "        # List of fields to exclude\n",
    "        fields_to_exclude = ['CF_to_CFvocab', 'target_field_vocab', 'OneEntryArgs']\n",
    "        \n",
    "        # Remove excluded fields if they exist\n",
    "        for field in fields_to_exclude:\n",
    "            if field in output:\n",
    "                del output[field]\n",
    "                \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArgs = {\n",
    "    'model_type': 'cgmlhm',\n",
    "    'OneEntryArgs': OneEntryArgs,\n",
    "    'CF_to_CFvocab': CF_to_CFvocab,\n",
    "}\n",
    "\n",
    "config = CgmLhmConfig(**ModelArgs)\n",
    "# print(config)\n",
    "config.field_to_fieldinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ca73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3069de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.configuration_cgmlsm import CgmLsmConfig\n",
    "\n",
    "lsm_kwargs = {k.split('lsm_')[1]: v for k, v in config.to_dict().items() if 'lsm_' in k}\n",
    "lsm_kwargs\n",
    "\n",
    "lsm_config = CgmLsmConfig(**lsm_kwargs)\n",
    "lsm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ff95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_kwargs = {k.split('fe_')[1]: v for k, v in config.to_dict().items() if 'fe_' in k}\n",
    "# fe_kwargs['n_embd'] = config.n_embd\n",
    "\n",
    "from nn.cgmlhm.configuration_fieldencoder import FieldEncoderConfig\n",
    "\n",
    "field_to_feconfig = {}\n",
    "for field, fieldinfo in config.field_to_fieldinfo.items():\n",
    "    fe_config = FieldEncoderConfig(**{'field': field, 'fieldinfo': fieldinfo}, **fieldinfo, **fe_kwargs)\n",
    "    field_to_feconfig[field] = fe_config\n",
    "\n",
    "pprint(field_to_feconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bf50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_kwargs = {k.split('sc_')[1]: v for k, v in config.to_dict().items() if 'sc_' in k}\n",
    "pprint(sc_kwargs, compact=True, sort_dicts=True)\n",
    "\n",
    "\n",
    "from nn.cgmlhm.configuration_fieldencoder import FieldEncoderConfig\n",
    "\n",
    "sc_config = FieldEncoderConfig(**sc_kwargs)\n",
    "sc_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_kwargs = {k.split('tf_')[1]: v for k, v in config.to_dict().items() if 'tf_' in k}\n",
    "\n",
    "from nn.cgmlhm.configuration_cgmlsm import CgmLsmConfig\n",
    "\n",
    "\n",
    "tf_config = CgmLsmConfig(**tf_kwargs)\n",
    "tf_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c75762",
   "metadata": {},
   "source": [
    "# CGMLSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac011e37",
   "metadata": {},
   "source": [
    "## Step 1: model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a285a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e8813",
   "metadata": {},
   "source": [
    "## Step 2: model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8aa8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f81ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_cgmlsm import CgmLsmModel\n",
    "\n",
    "lsm_model = CgmLsmModel(lsm_config)\n",
    "lsm_model\n",
    "\n",
    "# vocab size: 409  \n",
    "# input_length is independent of embedding parameters and MLP size or attention parameters size. \n",
    "# hidden_size (embedding size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batch['input_ids'][:1, :]# .shape\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07faf127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc\n",
    "embeddings = lsm_model.wte\n",
    "\n",
    "output = embeddings(input_ids)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_layer = lsm_model.h\n",
    "repr_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d8b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = output\n",
    "\n",
    "for idx, one_layer in enumerate(repr_layer):# .h:\n",
    "    print('\\n\\nlayer', idx)\n",
    "    print('input_tensor:', input_tensor.shape)\n",
    "    output_tensor = one_layer.forward(input_tensor)\n",
    "    # print(output_tensor)\n",
    "    print(one_layer)\n",
    "    output_tensor = output_tensor[0]\n",
    "    print('output_tensor:', output_tensor.shape)\n",
    "\n",
    "    # prepare for the next layer\n",
    "    input_tensor = output_tensor\n",
    "\n",
    "output_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349135f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_output = output_tensor\n",
    "repr_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_layer = lsm_model.pred\n",
    "lsm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2037e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f012bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = lsm_model(input_ids)\n",
    "last_hidden_state = output.last_hidden_state\n",
    "repr_output = last_hidden_state\n",
    "repr_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ef1f6",
   "metadata": {},
   "source": [
    "## Step 3: forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df471ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsm_model_inputs = {k: v for k, v in batch.items() if '--' not in k}\n",
    "# lsm_model_inputs\n",
    "\n",
    "lsm_model_inputs = {\n",
    "    'input_ids': batch['input_ids'],\n",
    "}\n",
    "\n",
    "print(batch['input_ids'].shape)\n",
    "lsm_outputs = lsm_model(**lsm_model_inputs)\n",
    "repr_output = lsm_outputs.last_hidden_state# .shape\n",
    "print(repr_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc9aea",
   "metadata": {},
   "source": [
    "\n",
    "# FieldEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c3c02",
   "metadata": {},
   "source": [
    "## Step 1:model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ec6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_feconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a5067",
   "metadata": {},
   "source": [
    "## Step 2: model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_fieldencoder import FieldEncoderModel\n",
    "import torch \n",
    "\n",
    "\n",
    "field_encoders = torch.nn.ModuleDict()\n",
    "\n",
    "\n",
    "for field, fe_config in field_to_feconfig.items():\n",
    "    field_encoder = FieldEncoderModel(fe_config)\n",
    "    field_encoders[field] = field_encoder\n",
    "\n",
    "field_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf99b2",
   "metadata": {},
   "source": [
    "## step 3: forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_encoder_outputs = {}\n",
    "\n",
    "for field, fe_config in field_to_feconfig.items():\n",
    "\n",
    "    print('\\n===================')\n",
    "    print(field)\n",
    "    field_encoder = field_encoders[field]   \n",
    "\n",
    "\n",
    "    batch_field_inputs = {k.split('--')[1]: v for k, v in batch.items() if field + '--' in k}\n",
    "\n",
    "\n",
    "    for value_name, values in batch_field_inputs.items():\n",
    "        print(value_name, values.shape)\n",
    "\n",
    "\n",
    "    print('reshape')\n",
    "    for value_name, values in batch_field_inputs.items():\n",
    "        # print('before', value_name, values.shape)\n",
    "        a, b = values.size(0), values.size(1)\n",
    "        values = values.view(a * b, -1)\n",
    "        batch_field_inputs[value_name] = values\n",
    "        print(value_name, values.shape)\n",
    "\n",
    "    use_event_indictors = False\n",
    "    if 'event_indicators' in batch_field_inputs:\n",
    "        use_event_indictors = True\n",
    "        event_indicators = batch_field_inputs['event_indicators'] \n",
    "        mask = event_indicators.bool().squeeze() \n",
    "        batch_field_inputs_filtered = {}\n",
    "        for k, v in batch_field_inputs.items():\n",
    "            if k == 'event_indicators': continue\n",
    "            batch_field_inputs_filtered[k] = v[mask]\n",
    "        batch_field_inputs = batch_field_inputs_filtered\n",
    "\n",
    "    input_ids_field = batch_field_inputs['input_ids']\n",
    "    attention_mask_field = input_ids_field.ne(fe_config.pad_token_id)\n",
    "    batch_field_inputs['attention_mask'] = attention_mask_field\n",
    "\n",
    "\n",
    "    print('\\nfinal batch_field_inputs')\n",
    "    for k, v in batch_field_inputs.items(): print(k, v.shape)\n",
    "\n",
    "\n",
    "    ###### test the field_embeddings\n",
    "    # # field_encoder(**batch_field_inputs)\n",
    "    # field_embeddings = field_encoder.embeddings\n",
    "    # # print(field_embeddings)\n",
    "    # embed_results = field_embeddings(**batch_field_inputs)\n",
    "    # # print(results)\n",
    "    # print('field_embeddings', embed_results.shape)\n",
    "\n",
    "    print('\\nfield_encoder')\n",
    "    field_outputs = field_encoder(**batch_field_inputs)\n",
    "    hidden_state = field_outputs.last_hidden_state#.shape\n",
    "    print('field_outputs.hidden_state', hidden_state.shape)\n",
    "\n",
    "    pooler_output =field_outputs.pooler_output# .shape\n",
    "    print('field_outputs.pooler_output', pooler_output.shape)\n",
    "\n",
    "\n",
    "    # hidden_state\n",
    "    if use_event_indictors:\n",
    "        hidden_state_origin = torch.zeros([len(mask),] + list(hidden_state.shape[1:]))\n",
    "        hidden_state_origin[mask] = hidden_state\n",
    "    \n",
    "        pooler_output_origin = torch.zeros([len(mask),] + list(pooler_output.shape[1:]))\n",
    "        pooler_output_origin[mask] = pooler_output\n",
    "\n",
    "\n",
    "    else:\n",
    "        hidden_state_origin  = hidden_state\n",
    "        pooler_output_origin = pooler_output\n",
    "\n",
    "\n",
    "    new_shape = [a, b] + list(hidden_state.shape[1:])\n",
    "    # new_shape\n",
    "    hidden_state_origin = hidden_state_origin.reshape(new_shape)\n",
    "    print('field_outputs.hidden_state_origin', hidden_state_origin.shape)\n",
    "\n",
    "\n",
    "    # pooler_output_origin.shape\n",
    "    new_shape = [a, b] + list(pooler_output.shape[1:])\n",
    "    pooler_output_origin = pooler_output_origin.reshape(new_shape)\n",
    "    print('field_outputs.pooler_output_origin', pooler_output_origin.shape)\n",
    "\n",
    "\n",
    "    field_to_encoder_outputs[field] = {\n",
    "        'hidden_state': hidden_state_origin,\n",
    "        'pooler_output': pooler_output_origin,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd78d45",
   "metadata": {},
   "source": [
    "# StepConnector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a65a172",
   "metadata": {},
   "source": [
    "## Step 1: model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c620d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f631f07",
   "metadata": {},
   "source": [
    "## Step 2: model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ce0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_cgmlhm import StepConnector\n",
    "\n",
    "\n",
    "step_connector_model = StepConnector(sc_config)\n",
    "step_connector_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22026fcc",
   "metadata": {},
   "source": [
    "## Step 3: forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96eed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_state = lsm_outputs.last_hidden_state\n",
    "target_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_states = [encoder_outputs['pooler_output'] for field, encoder_outputs in field_to_encoder_outputs.items()]# ['Diet--event_indicators'].shape\n",
    "\n",
    "field_states\n",
    "# field_list= [i for i in field_to_encoder_outputs]\n",
    "\n",
    "step_state_list = [target_state] + field_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9042c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(step_state_list) > 1:\n",
    "    # get step_state, this should be the encoder. \n",
    "    step_field_states = torch.stack(step_state_list, dim=1)\n",
    "    connector_output = step_connector_model(step_field_states)\n",
    "    step_states = connector_output.pooler_output\n",
    "else:\n",
    "    step_states = target_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90cccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e6577",
   "metadata": {},
   "source": [
    "# CGMLHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e746ac22",
   "metadata": {},
   "source": [
    "## Step 1: model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932df161",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f365e7e0",
   "metadata": {},
   "source": [
    "## Step 2: model_structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_cgmlhm import CgmLhmModel\n",
    "\n",
    "model = CgmLhmModel(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca5c1d",
   "metadata": {},
   "source": [
    "## Step 3: forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**batch)\n",
    "\n",
    "# model: repr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bc587",
   "metadata": {},
   "source": [
    "# CGMLHM-LMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_cgmlhm import GgmLhmLMHeadModel\n",
    "\n",
    "model = GgmLhmLMHeadModel(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (lm_head): Linear(in_features=768, out_features=409, bias=False)\n",
    "# 768: embed_size, hidden_size\n",
    "# 409: vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b92537",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhm_outputs = model.lhm(**batch)\n",
    "repr_output = lhm_outputs.last_hidden_state\n",
    "repr_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6071169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in lhm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a121d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_output = lhm_outputs[0]\n",
    "repr_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7aefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15adddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_logits = model.lm_head(repr_output)\n",
    "lm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5141b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repr_tensor \n",
    "\n",
    "# prediction layer \n",
    "\n",
    "# logits \n",
    "\n",
    "# loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss manually for next token prediction\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get the labels from the batch\n",
    "labels = batch['labels']\n",
    "\n",
    "# For next token prediction, we need to shift the labels\n",
    "# Input: [t0, t1, t2, t3, ...]\n",
    "# Logits predict: [t1, t2, t3, t4, ...]\n",
    "# So labels should be: [t1, t2, t3, t4, ...]\n",
    "input_ids = batch['input_ids']\n",
    "shifted_labels = labels.clone()\n",
    "shifted_labels[:, :-1] = labels[:, 1:].clone()\n",
    "# The last position predicts a padding token or similar\n",
    "shifted_labels[:, -1] = -100  # Ignore last position in loss calculation\n",
    "\n",
    "# Reshape logits and shifted labels for loss calculation\n",
    "lm_logits_flat = lm_logits.view(-1, lm_logits.size(-1))\n",
    "shifted_labels_flat = shifted_labels.view(-1)\n",
    "\n",
    "# Calculate cross entropy loss with shifted labels\n",
    "loss = F.cross_entropy(lm_logits_flat, shifted_labels_flat, ignore_index=-100)\n",
    "print(f\"Manually calculated loss for next token prediction: {loss.item()}\")\n",
    "\n",
    "# This should now match the output.loss from model(**batch) in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1520ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**batch)\n",
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67752cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233053c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}