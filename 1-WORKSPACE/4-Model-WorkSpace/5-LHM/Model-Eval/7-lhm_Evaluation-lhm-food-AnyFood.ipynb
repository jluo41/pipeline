{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881d73c8-f12f-4a9b-a485-996a76289767",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b19d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "SPACE['MODEL_ENDPOINT'] = 'vTest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57492949",
   "metadata": {},
   "source": [
    "# Part 1: AIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c78ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.aidata import AIData\n",
    "\n",
    "DATA_AIDATA = SPACE['DATA_AIDATA']\n",
    "OneAIDataName = 'CgmLhm_Bf24Af2Af2t8H_5Min_3Cohort_EventFlt_ds0p50_foodnumGE1_SubTD_bf24af2'\n",
    "\n",
    "OneEntryArgs = {\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "\n",
    "        'Tagging': {\n",
    "            # 'TagName_to_TaggingMethod': {\n",
    "            #     # TagName: TaggingMethod {Rules: [(x,x,x)], Op: and or}\n",
    "            # },\n",
    "            # 'ColumnsAddToDsCase': [],\n",
    "            'TagFilter': True, # <--- still need to add Fitlter Tag, as we need to do the RandomDownSample.\n",
    "            'TagSplit': False, # <--- do not need to add Split Tag anymore, as we already have. \n",
    "        },\n",
    "\n",
    "        'Filtering': {\n",
    "            # 'FilterTagging': None,\n",
    "            'FilterTagging': {\n",
    "                \"Rules\": [\n",
    "                    ['RandDownSample', '<=', 0.2],\n",
    "                    ['co.Bf24H_Food_recnum:recnum', '>=', 1], \n",
    "                    # ['co.Af2H_Food_recnum:recnum', '>=', 1], \n",
    "                    ], \n",
    "                'Op': 'and',\n",
    "            }\n",
    "        }, \n",
    "        \n",
    "        'Splitting': {\n",
    "            # 'SplitTagging': { # <----- for the Tagging part.\n",
    "            #     'RANDOM_SEED': 32,\n",
    "            #     'out_ratio': 0.1,\n",
    "            #     'test_ratio': 'tail0.1',\n",
    "            #     'valid_ratio': 0.1\n",
    "            # },\n",
    "            'TrainEvals': {\n",
    "                'TrainSetName_InTrain': 'In-Train', \n",
    "                'EvalSetNames_InTrain': [\n",
    "                    'In-Test_T1D', \n",
    "                    'In-Test_T2D', \n",
    "                    'In-Valid_T1D', \n",
    "                    'In-Valid_T2D', \n",
    "                    'Out_T1D', \n",
    "                    'Out_T2D',\n",
    "                ],\n",
    "\n",
    "                'TrainSetName': 'In-Train', \n",
    "                'EvalSetNames': [\n",
    "                    'In-Test', \n",
    "                    'In-Valid', \n",
    "                    'Out',\n",
    "                ],\n",
    "                'DivideEvalConfig': {\n",
    "                    'Columns': ['DiseaseTypeGroup'],\n",
    "                    'SubGroupNames': {\n",
    "                        'T2D': ['DiseaseType.2.0'],\n",
    "                        'T1D': ['DiseaseType.1.0'],\n",
    "                    },\n",
    "                },\n",
    "                'DivideTrainConfig': {\n",
    "                    # 'Columns': ['DiseaseTypeGroup'],\n",
    "                    # 'SubGroupNames': {\n",
    "                    #     'T2D': ['DiseaseType.2.0'],\n",
    "                    #     'T1D': ['DiseaseType.1.0'],\n",
    "                    # },\n",
    "\n",
    "                    # 'Columns': ['DiseaseTypeGroup', 'GenderGroup'],\n",
    "                    # 'SubGroupNames': {\n",
    "                    #     'T2D.Male': ['DiseaseType.2.0', 'Gender.1'],\n",
    "                    #     'T1D.Male': ['DiseaseType.1.0', 'Gender.1'],\n",
    "                    #     'T2D.Female': ['DiseaseType.2.0', 'Gender.2'],\n",
    "                    #     'T1D.Female': ['DiseaseType.1.0', 'Gender.2'],\n",
    "                    # },\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "            # 'cf.TimeSparse_Bf24H', \n",
    "            # 'cf.TimeSparse_Af2H',\n",
    "            'cf.DietSparse_Bf24H',\n",
    "            'cf.DietSparse_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        # 'TimeField':   'Time',\n",
    "        'EventFields': [\n",
    "            'Diet',\n",
    "        ],\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'NTP',\n",
    "    },\n",
    "}\n",
    "\n",
    "aidata = AIData.load_aidata(DATA_AIDATA, OneAIDataName, SPACE)\n",
    "aidata.update_NameToData_with_OneEntryArgs(OneEntryArgs)\n",
    "dataset = aidata.Name_to_DS\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata.Name_to_DsAIData\n",
    "\n",
    "split_name = [i for i in  aidata.Name_to_Data][0]\n",
    "Name_to_Data = aidata.Name_to_Data# [split_name]\n",
    "Data = Name_to_Data[split_name]\n",
    "df_case = Data['df_case']\n",
    "\n",
    "df_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfm = Data['ds_tfm']\n",
    "# ds_tfm\n",
    "\n",
    "batch_size = 4\n",
    "batch = ds_tfm[:batch_size]\n",
    "for k, v in batch.items(): print(k, v.shape)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1be4a",
   "metadata": {},
   "source": [
    "# Part 2: Model Init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4677e",
   "metadata": {},
   "source": [
    "## Step 1: init_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9028ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_cgmlhm import GgmLhmLMHeadModel\n",
    "\n",
    "\n",
    "model_path = '../_Model/CgmLhm_Bf24Af2Af2t8H_5Min_3Cohort_EventFlt_ds0p50_foodnumGE1_SubTD_bf24af2_lhm-foodL3-ds0p5-frozen-lsm/checkpoint-3600'\n",
    "\n",
    "model = GgmLhmLMHeadModel.from_pretrained(model_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd78d45",
   "metadata": {},
   "source": [
    "# Part 3: Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.inference_cgmlhm import process_a_single_batch\n",
    "\n",
    "\n",
    "\n",
    "# batch_gen['input_ids'].shape\n",
    "InferenceArgs = {\n",
    "    'NTP_Args': {\n",
    "        'num_old_tokens': 289, \n",
    "        'items_list': ['losses_each_seq', 'losses_each_token', 'predicted_ntp_labels']\n",
    "    }, \n",
    "    'GEN_Args': {\n",
    "        'num_old_tokens': 289,\n",
    "        'max_new_tokens': 24,\n",
    "        'do_sample': False,\n",
    "        'items_list': ['hist', 'real', 'pred_wfe', 'logits_wfe', 'pred_nfe', 'logits_nfe'], # wfe: with future events, nfe: without future events\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "batch_output = process_a_single_batch(model, batch, InferenceArgs)\n",
    "\n",
    "df_batch = pd.DataFrame(batch_output)\n",
    "df_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1125745",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "Split_Name = [i for i in aidata.Name_to_Data][0]\n",
    "Data = aidata.Name_to_Data[Split_Name]\n",
    "########################\n",
    "\n",
    "ds_tfm  = Data['ds_tfm']\n",
    "df_case = Data['df_case']\n",
    "print(ds_tfm)\n",
    "display(df_case.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e3ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets \n",
    "\n",
    "Name_list = [\n",
    " # 'In-Train',\n",
    "#  'In-Test_T2D',\n",
    "#  'In-Test_T1D',\n",
    "#  'In-Valid_T2D',\n",
    "#  'In-Valid_T1D',\n",
    " 'Out_T2D'\n",
    " ]\n",
    "\n",
    "\n",
    "ds_tfm_list = []\n",
    "df_case_list = []\n",
    "for Name in Name_list:\n",
    "    Data = aidata.Name_to_Data[Name]\n",
    "    ds_tfm = Data['ds_tfm']\n",
    "    df_case = Data['df_case']\n",
    "    # print(ds_tfm)\n",
    "    # display(df_case.head())\n",
    "    ds_tfm_list.append(ds_tfm)\n",
    "    df_case_list.append(df_case)\n",
    "\n",
    "\n",
    "df_case = pd.concat(df_case_list, axis = 0)\n",
    "ds_case = datasets.concatenate_datasets(ds_tfm_list)\n",
    "print(ds_case)\n",
    "print(df_case.shape)\n",
    "\n",
    "Data = {'ds_case': ds_case, 'df_case': df_case}\n",
    "CF_to_CFvocab = aidata.CF_to_CFvocab\n",
    "Data = aidata.entry_builder.setup_EntryFn_to_Data(Data, CF_to_CFvocab)\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "#################################\n",
    "max_inference_num = 2000\n",
    "save_df = False \n",
    "load_df = False \n",
    "chunk_size = 12800\n",
    "batch_size = 16\n",
    "#################################\n",
    "\n",
    "# case_id_columns = aidata.case_id_columns\n",
    "model = model\n",
    "\n",
    "if max_inference_num is not None and max_inference_num < len(ds_tfm): \n",
    "    random_indices = np.random.randint(0, len(ds_tfm), max_inference_num)\n",
    "    ds_tfm = ds_tfm.select(random_indices)\n",
    "    df_case = df_case.iloc[random_indices]\n",
    "\n",
    "print(ds_tfm)\n",
    "print(df_case.shape)\n",
    "display(df_case.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch \n",
    "from datetime import datetime\n",
    "\n",
    "###################\n",
    "# df_case\n",
    "# ds_tfm\n",
    "###################\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "print(model.device)\n",
    "\n",
    "chunk_numbers = len(df_case) // chunk_size\n",
    "print(chunk_numbers)\n",
    "\n",
    "for chunk_id in range(chunk_numbers+1):\n",
    "    # chunk_id = 0\n",
    "    start = chunk_id * chunk_size\n",
    "    end = min((chunk_id+1) * chunk_size, len(df_case))\n",
    "    print(start, end)\n",
    "\n",
    "\n",
    "    df_case_chunk = df_case.iloc[start:end].reset_index(drop = True)\n",
    "    ds_tfm_chunk = ds_tfm.select(range(start, end))\n",
    "    print(ds_tfm_chunk)\n",
    "    print(df_case_chunk.shape)\n",
    "\n",
    "\n",
    "    df_eval_chunk = pd.DataFrame()\n",
    "    # for batch_s in tqdm(range(0, len(ds_tfm_chunk), batch_size)):\n",
    "    for batch_s in range(0, len(ds_tfm_chunk), batch_size):\n",
    "        batch_e = min(batch_s + batch_size, len(ds_tfm_chunk))\n",
    "        \n",
    "        \n",
    "        s = datetime.now()\n",
    "        batch = ds_tfm_chunk[batch_s: batch_e]\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.to(model.device)\n",
    "        e = datetime.now()\n",
    "        print(f'{batch_s} prepare batch: {e - s}')\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            s = datetime.now()\n",
    "            output = process_a_single_batch(model, batch, InferenceArgs)\n",
    "            e = datetime.now()\n",
    "            print(f'{batch_s} forward batch: {e - s}')\n",
    "            \n",
    "        df_batch = pd.DataFrame(output)\n",
    "        df_eval_chunk = pd.concat([df_eval_chunk, df_batch], axis = 0)\n",
    "\n",
    "    df_eval_chunk = df_eval_chunk.reset_index(drop=True)  \n",
    "\n",
    "    df_chunk = pd.concat([df_case_chunk, df_eval_chunk], axis = 1)\n",
    "\n",
    "    # df_chunk\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case_eval = df_chunk\n",
    "df_case_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.eval.seqeval import SeqEvalForOneEvalSet\n",
    "\n",
    "setname = 'test'\n",
    "x_hist_seq_name = 'hist'\n",
    "y_real_seq_name = 'real'\n",
    "y_pred_seq_name = 'pred_wfe'\n",
    "\n",
    "metric_list = ['rMSE']\n",
    "\n",
    "horizon_to_se = {\n",
    "    '000-030min': [0, 6],\n",
    "    '000-060min': [0, 12],\n",
    "    '000-120min': [0, 18],\n",
    "    '000-180min': [0, 24],\n",
    "    '060-120min': [6, 18],\n",
    "}\n",
    "\n",
    "\n",
    "df_case_eval = df_case_eval\n",
    "\n",
    "eval_instance = SeqEvalForOneEvalSet(\n",
    "    setname = setname,\n",
    "    df_case_eval = df_case_eval, \n",
    "    x_hist_seq_name = x_hist_seq_name,\n",
    "    y_real_seq_name = y_real_seq_name, \n",
    "    y_pred_seq_name = y_pred_seq_name,\n",
    "    metric_list = metric_list,\n",
    "    horizon_to_se = horizon_to_se, \n",
    ")\n",
    "\n",
    "eval_results = eval_instance.get_evaluation_report()\n",
    "eval_results\n",
    "\n",
    "\n",
    "# Test1 Test2 Out2\n",
    "# '000-030min_rMSE': 7.525231092436974,\n",
    "# '000-060min_rMSE': 13.154212184873948,\n",
    "# '000-120min_rMSE': 18.734353991596638,\n",
    "# '000-180min_rMSE': 24.163114495798318,\n",
    "# '060-120min_rMSE': 21.933193277310927,\n",
    "\n",
    "\n",
    "# Test1 Test2 Out2\n",
    "# '000-030min_rMSE': 6.932545854732208,\n",
    "# '000-060min_rMSE': 12.072663242846662,\n",
    "# '000-120min_rMSE': 17.17441672780631,\n",
    "# '000-180min_rMSE': 22.22123257520176,\n",
    "# '060-120min_rMSE': 20.11437270726339,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887cdaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.eval.seqeval import SeqEvalForOneEvalSet\n",
    "\n",
    "setname = 'test'\n",
    "x_hist_seq_name = 'hist'\n",
    "y_real_seq_name = 'real'\n",
    "y_pred_seq_name = 'pred_nfe'\n",
    "\n",
    "metric_list = ['rMSE']\n",
    "\n",
    "horizon_to_se = {\n",
    "    '000-030min': [0, 6],\n",
    "    '000-060min': [0, 12],\n",
    "    '000-120min': [0, 18],\n",
    "    '000-180min': [0, 24],\n",
    "    '060-120min': [6, 18],\n",
    "}\n",
    "\n",
    "\n",
    "df_case_eval = df_case_eval\n",
    "\n",
    "eval_instance = SeqEvalForOneEvalSet(\n",
    "    setname = setname,\n",
    "    df_case_eval = df_case_eval, \n",
    "    x_hist_seq_name = x_hist_seq_name,\n",
    "    y_real_seq_name = y_real_seq_name, \n",
    "    y_pred_seq_name = y_pred_seq_name,\n",
    "    metric_list = metric_list,\n",
    "    horizon_to_se = horizon_to_se, \n",
    ")\n",
    "\n",
    "eval_results = eval_instance.get_evaluation_report()\n",
    "eval_results\n",
    "\n",
    "# '000-030min_rMSE': 7.43746,\n",
    "#  '000-060min_rMSE': 13.02185,\n",
    "#  '000-120min_rMSE': 17.66305,\n",
    "#  '000-180min_rMSE': 21.87347,\n",
    "#  '060-120min_rMSE': 20.6729,\n",
    "\n",
    "# '000-030min_rMSE': 7.508,\n",
    "#  '000-060min_rMSE': 13.16405,\n",
    "#  '000-120min_rMSE': 17.78696,\n",
    "#  '000-180min_rMSE': 21.99143,\n",
    "#  '060-120min_rMSE': 20.82129,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f07af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}