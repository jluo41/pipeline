{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881d73c8-f12f-4a9b-a485-996a76289767",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b19d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "SPACE['MODEL_ENDPOINT'] = 'vTest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57492949",
   "metadata": {},
   "source": [
    "# Part 1: AIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.aidata import AIData\n",
    "\n",
    "DATA_AIDATA = SPACE['DATA_AIDATA']\n",
    "OneAIDataName = 'CgmLhm_Bf24Af2Af2t8H_5Min_3Cohort_EventFlt_Sample'\n",
    "\n",
    "\n",
    "OneEntryArgs = {\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "\n",
    "        'Tagging': {\n",
    "            # 'TagName_to_TaggingMethod': {\n",
    "            #     # TagName: TaggingMethod {Rules: [(x,x,x)], Op: and or}\n",
    "            # },\n",
    "            # 'ColumnsAddToDsCase': [],\n",
    "            'TagFilter': True, # <--- still need to add Fitlter Tag, as we need to do the RandomDownSample.\n",
    "            'TagSplit': False, # <--- do not need to add Split Tag anymore, as we already have. \n",
    "        },\n",
    "\n",
    "        'Filtering': {\n",
    "            # 'FilterTagging': None,\n",
    "            'FilterTagging': {\n",
    "                \"Rules\": [\n",
    "                    ['RandDownSample', '<=', 0.5],\n",
    "                    ['co.Bf24H_Food_recnum:recnum', '>=', 1], \n",
    "                    ], \n",
    "                'Op': 'and',\n",
    "            }\n",
    "        }, \n",
    "        \n",
    "        'Splitting': {\n",
    "            # 'SplitTagging': { # <----- for the Tagging part.\n",
    "            #     'RANDOM_SEED': 32,\n",
    "            #     'out_ratio': 0.1,\n",
    "            #     'test_ratio': 'tail0.1',\n",
    "            #     'valid_ratio': 0.1\n",
    "            # },\n",
    "            'TrainEvals': {\n",
    "                'TrainSetName': 'In-Train', \n",
    "                'EvalSetNames': ['In-Test', 'In-Valid', 'Out']\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "            'cf.TimeSparse_Bf24H', \n",
    "            'cf.TimeSparse_Af2H',\n",
    "            'cf.DietSparse_Bf24H',\n",
    "            'cf.DietSparse_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        'TimeField':   'Time',\n",
    "        'EventFields': [\n",
    "            'Diet',\n",
    "        ],\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'NTP',\n",
    "    },\n",
    "}\n",
    "\n",
    "aidata = AIData.load_aidata(DATA_AIDATA, OneAIDataName, SPACE)\n",
    "aidata.update_NameToData_with_OneEntryArgs(OneEntryArgs)\n",
    "dataset = aidata.Name_to_DS\n",
    "dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata.Name_to_DsAIData\n",
    "split_name = [i for i in  aidata.Name_to_Data][0]\n",
    "Name_to_Data = aidata.Name_to_Data# [split_name]\n",
    "Data = Name_to_Data[split_name]\n",
    "df_case = Data['df_case']\n",
    "df_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7282d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7847d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "batch = ds_tfm[:batch_size]\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1be4a",
   "metadata": {},
   "source": [
    "# Part 2: Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e151e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata.CF_to_CFvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata.OneEntryArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPart = aidata.OneEntryArgs['Input_Part']\n",
    "TargetField = InputPart['TargetField']\n",
    "TimeField = InputPart['TimeField']\n",
    "EventFields = InputPart['EventFields']\n",
    "\n",
    "\n",
    "CF_list = InputPart['CF_list']  \n",
    "FieldList = [TimeField] + EventFields\n",
    "# FieldList\n",
    "\n",
    "Field_to_CFs = {Field: [CF for CF in CF_list if Field in CF] for Field in FieldList}\n",
    "# Field_to_CFs\n",
    "\n",
    "\n",
    "CF_to_CFvocab = aidata.CF_to_CFvocab\n",
    "Field_to_CFvocab = {Field: CF_to_CFvocab[CFs[0]] for Field, CFs in Field_to_CFs.items()}\n",
    "# Field_to_CFvocab\n",
    "\n",
    "\n",
    "field_to_vocabsize = {Field: len(Field_to_CFvocab[Field]['input_ids']['tkn2tid']) for Field in FieldList}\n",
    "field_to_vocabsize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749664f4",
   "metadata": {},
   "source": [
    "### CgmLhmConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nn.cgmlhm.configuration_cgmlhm import CgmLhmConfig\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Any, List, Mapping, Optional\n",
    "\n",
    "from transformers import PreTrainedTokenizer, TensorType, is_torch_available\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "from transformers.onnx import OnnxConfigWithPast, PatchingSpec\n",
    "from transformers.utils import logging\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "class CgmLhmConfig(PretrainedConfig):\n",
    "    model_type = \"cgmlhm\"\n",
    "    keys_to_ignore_at_inference = [\"past_key_values\"]\n",
    "    attribute_map = {\n",
    "        'n_layer': 'tf_n_layer',\n",
    "        \"hidden_size\": \"n_embd\",\n",
    "        \"max_position_embeddings\": \"n_positions\",\n",
    "        \"num_attention_heads\": \"n_head\",\n",
    "        \"num_hidden_layers\": \"n_layer\",\n",
    "        \"layer_norm_epsilon\": \"layer_norm_eps\",\n",
    "        \"hidden_act\": \"activation_function\",\n",
    "        # \"hidden_dropout_prob\": \n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_embd=768,\n",
    "        initializer_range=0.02,\n",
    "        use_cache=True,\n",
    "\n",
    "        time_field = 'Time',\n",
    "\n",
    "        # lsm_config\n",
    "        lsm_n_positions=1024,\n",
    "        lsm_n_layer=12,\n",
    "        lsm_n_head=12,\n",
    "        lsm_n_inner=None,\n",
    "        lsm_activation_function=\"gelu_new\",\n",
    "        lsm_resid_pdrop=0.1,\n",
    "        lsm_embd_pdrop=0.1,\n",
    "        lsm_attn_pdrop=0.1,\n",
    "        lsm_layer_norm_epsilon=1e-5,\n",
    "        # lsm_initializer_range=0.02,\n",
    "        lsm_summary_type=\"cls_index\",\n",
    "        lsm_summary_use_proj=True,\n",
    "        lsm_summary_activation=None,\n",
    "        lsm_summary_proj_to_labels=True,\n",
    "        lsm_summary_first_dropout=0.1,\n",
    "        lsm_scale_attn_weights=True,\n",
    "        lsm_scale_attn_by_inverse_layer_idx=False,\n",
    "        lsm_reorder_and_upcast_attn=False,\n",
    "\n",
    "\n",
    "        # fieldeconder_settings.\n",
    "        fe_num_hidden_layers=6,\n",
    "        fe_timestep_lookback = 600,\n",
    "        fe_timestep_lookahead = 300,\n",
    "        fe_embd_pdrop = 0.1,\n",
    "        fe_use_field_type_embedding = True,\n",
    "        fe_num_attention_heads=12,\n",
    "        fe_intermediate_size=3072,\n",
    "        fe_hidden_act=\"gelu\",\n",
    "        fe_hidden_dropout_prob=0.1,\n",
    "        fe_attention_probs_dropout_prob=0.1,\n",
    "        fe_max_position_embeddings=512,\n",
    "        # fe_initializer_range=0.02,\n",
    "        fe_layer_norm_eps=1e-12,\n",
    "        fe_position_embedding_type=\"absolute\",\n",
    "        # fe_use_cache=True,\n",
    "        fe_classifier_dropout=None,\n",
    "\n",
    "\n",
    "        # step connector \n",
    "        sc_num_hidden_layers=2,\n",
    "        sc_num_attention_heads=12,\n",
    "        sc_intermediate_size=3072,\n",
    "        sc_hidden_act=\"gelu\",\n",
    "        sc_hidden_dropout_prob=0.1,\n",
    "        sc_attention_probs_dropout_prob=0.1,\n",
    "        sc_max_position_embeddings=512,\n",
    "        # sc_initializer_range=0.02,\n",
    "        sc_layer_norm_eps=1e-12,\n",
    "        sc_position_embedding_type=\"absolute\",\n",
    "        # sc_use_cache=True,\n",
    "        sc_classifier_dropout=None,\n",
    "        \n",
    "        # temporal fusor \n",
    "        tf_n_layer=4,\n",
    "        tf_n_head=12,\n",
    "        tf_n_inner=None,\n",
    "        tf_activation_function=\"gelu_new\",\n",
    "        tf_resid_pdrop=0.1,\n",
    "        tf_embd_pdrop=0.1,\n",
    "        tf_attn_pdrop=0.1,\n",
    "        tf_layer_norm_epsilon=1e-5,\n",
    "        # tf_initializer_range=0.02,\n",
    "        tf_summary_type=\"cls_index\",\n",
    "        tf_summary_use_proj=True,\n",
    "        tf_summary_activation=None,\n",
    "        tf_summary_proj_to_labels=True,\n",
    "        tf_summary_first_dropout=0.1,\n",
    "        tf_scale_attn_weights=True,\n",
    "        # tf_use_cache=True,\n",
    "        tf_scale_attn_by_inverse_layer_idx=False,\n",
    "        tf_reorder_and_upcast_attn=False,\n",
    "        \n",
    "        # entry_args = None, # Add this line\n",
    "        CF_to_CFvocab = None, # Add this line\n",
    "        OneEntryArgs = None, # Add this line\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_embd = n_embd\n",
    "        self.initializer_range = initializer_range\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "        self.time_field = time_field\n",
    "\n",
    "        self.lsm_n_embd = n_embd\n",
    "        self.lsm_n_positions = lsm_n_positions\n",
    "        self.lsm_n_layer = lsm_n_layer\n",
    "        self.lsm_n_head = lsm_n_head\n",
    "        self.lsm_n_inner = lsm_n_inner\n",
    "        self.lsm_activation_function = lsm_activation_function\n",
    "        self.lsm_resid_pdrop = lsm_resid_pdrop\n",
    "        self.lsm_embd_pdrop = lsm_embd_pdrop\n",
    "        self.lsm_attn_pdrop = lsm_attn_pdrop\n",
    "        self.lsm_layer_norm_epsilon = lsm_layer_norm_epsilon\n",
    "        self.lsm_initializer_range = initializer_range\n",
    "        self.lsm_summary_type = lsm_summary_type\n",
    "        self.lsm_summary_use_proj = lsm_summary_use_proj\n",
    "        self.lsm_summary_activation = lsm_summary_activation\n",
    "        self.lsm_summary_proj_to_labels = lsm_summary_proj_to_labels\n",
    "        self.lsm_summary_first_dropout = lsm_summary_first_dropout\n",
    "        self.lsm_scale_attn_weights = lsm_scale_attn_weights\n",
    "        self.lsm_use_cache = use_cache\n",
    "        self.lsm_scale_attn_by_inverse_layer_idx = lsm_scale_attn_by_inverse_layer_idx\n",
    "        self.lsm_reorder_and_upcast_attn = lsm_reorder_and_upcast_attn\n",
    "\n",
    "\n",
    "        self.fe_hidden_size = n_embd\n",
    "        self.fe_timestep_lookback = fe_timestep_lookback\n",
    "        self.fe_timestep_lookahead = fe_timestep_lookahead\n",
    "        self.fe_embd_pdrop = fe_embd_pdrop\n",
    "        self.fe_use_field_type_embedding = fe_use_field_type_embedding\n",
    "        self.fe_num_hidden_layers = fe_num_hidden_layers\n",
    "        self.fe_num_attention_heads = fe_num_attention_heads\n",
    "        self.fe_intermediate_size = fe_intermediate_size\n",
    "        self.fe_hidden_act = fe_hidden_act\n",
    "        self.fe_hidden_dropout_prob = fe_hidden_dropout_prob\n",
    "        self.fe_attention_probs_dropout_prob = fe_attention_probs_dropout_prob\n",
    "        self.fe_max_position_embeddings = fe_max_position_embeddings\n",
    "        self.fe_initializer_range = initializer_range\n",
    "        self.fe_layer_norm_eps = fe_layer_norm_eps\n",
    "        self.fe_position_embedding_type = fe_position_embedding_type\n",
    "        self.fe_use_cache = use_cache\n",
    "        self.fe_classifier_dropout = fe_classifier_dropout\n",
    "\n",
    "\n",
    "        self.sc_hidden_size = n_embd\n",
    "        self.sc_num_hidden_layers = sc_num_hidden_layers\n",
    "        self.sc_num_attention_heads = sc_num_attention_heads\n",
    "        self.sc_intermediate_size = sc_intermediate_size\n",
    "        self.sc_hidden_act = sc_hidden_act\n",
    "        self.sc_hidden_dropout_prob = sc_hidden_dropout_prob\n",
    "        self.sc_attention_probs_dropout_prob = sc_attention_probs_dropout_prob\n",
    "        self.sc_max_position_embeddings = sc_max_position_embeddings\n",
    "        self.sc_initializer_range = initializer_range\n",
    "        self.sc_layer_norm_eps = sc_layer_norm_eps\n",
    "        self.sc_position_embedding_type = sc_position_embedding_type\n",
    "        self.sc_use_cache = use_cache\n",
    "        self.sc_classifier_dropout = sc_classifier_dropout\n",
    "\n",
    "\n",
    "        self.n_layer = tf_n_layer\n",
    "        self.tf_n_embd = n_embd\n",
    "        self.tf_n_layer = tf_n_layer\n",
    "        self.tf_n_head = tf_n_head\n",
    "        self.tf_n_inner = tf_n_inner\n",
    "        self.tf_activation_function = tf_activation_function\n",
    "        self.tf_resid_pdrop = tf_resid_pdrop\n",
    "        self.tf_embd_pdrop = tf_embd_pdrop\n",
    "        self.tf_attn_pdrop = tf_attn_pdrop\n",
    "        self.tf_layer_norm_epsilon = tf_layer_norm_epsilon\n",
    "        self.tf_initializer_range = initializer_range\n",
    "        self.tf_summary_type = tf_summary_type\n",
    "        self.tf_summary_use_proj = tf_summary_use_proj\n",
    "        self.tf_summary_activation = tf_summary_activation\n",
    "        self.tf_summary_proj_to_labels = tf_summary_proj_to_labels\n",
    "        self.tf_summary_first_dropout = tf_summary_first_dropout\n",
    "        self.tf_scale_attn_weights = tf_scale_attn_weights\n",
    "        self.tf_use_cache = use_cache\n",
    "        self.tf_scale_attn_by_inverse_layer_idx = tf_scale_attn_by_inverse_layer_idx\n",
    "        self.tf_reorder_and_upcast_attn = tf_reorder_and_upcast_attn\n",
    "\n",
    "        self.OneEntryArgs = OneEntryArgs\n",
    "        self.CF_to_CFvocab = CF_to_CFvocab\n",
    "        if OneEntryArgs is not None and CF_to_CFvocab is not None:\n",
    "            self.initalize_field_info()\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def initalize_field_info(self):\n",
    "        if not hasattr(self, 'OneEntryArgs') or not hasattr(self, 'CF_to_CFvocab'):\n",
    "            return None \n",
    "        \n",
    "        # self.CF_to_CFvocab = CF_to_CFvocab\n",
    "        # self.Field_to_CFvocab = None\n",
    "\n",
    "        # self.set_field_info_with_OneEntryArgs(OneEntryArgs, CF_to_CFvocab)  \n",
    "        # self.entry_args = entry_args # Add this line\n",
    "\n",
    "        # self.OneEntryArgs = OneEntryArgs\n",
    "        # self.CF_to_CFvocab = CF_to_CFvocab\n",
    "        # print('in set_field_info_with_OneEntryArgs')\n",
    "        # print(OneEntryArgs)\n",
    "        # print(CF_to_CFvocab)\n",
    "\n",
    "        OneEntryArgs = self.OneEntryArgs\n",
    "        CF_to_CFvocab = self.CF_to_CFvocab\n",
    "        InputPart = OneEntryArgs['Input_Part']\n",
    "        TargetField = InputPart['TargetField']\n",
    "        TimeField = InputPart['TimeField']\n",
    "        EventFields = InputPart['EventFields']\n",
    "\n",
    "\n",
    "        CF_list = InputPart['CF_list']  \n",
    "        FieldList = [TimeField] + EventFields\n",
    "        # FieldList\n",
    "\n",
    "        Field_to_CFs = {Field: [CF for CF in CF_list if Field in CF] for Field in FieldList}\n",
    "        # Field_to_CFs\n",
    "\n",
    "        Field_to_CFvocab = {Field: CF_to_CFvocab[CFs[0]] for Field, CFs in Field_to_CFs.items()}\n",
    "        # Field_to_CFvocab\n",
    "\n",
    "        # self.Field_to_CFvocab = Field_to_CFvocab  \n",
    "\n",
    "        field_to_fieldinfo = {}\n",
    "\n",
    "        for field in FieldList:\n",
    "            tkn2tid = Field_to_CFvocab[field]['input_ids']['tkn2tid']\n",
    "            # field_to_vocabsize = {field: len(tkn2tid)}\n",
    "            vocab_size = len(tkn2tid) \n",
    "            bos_token_id = tkn2tid['[BOS]']\n",
    "            eos_token_id = tkn2tid['[EOS]']\n",
    "            pad_token_id = 0\n",
    "            field_to_fieldinfo[field] = {\n",
    "                'vocab_size': vocab_size,\n",
    "                'bos_token_id': bos_token_id,\n",
    "                'eos_token_id': eos_token_id,\n",
    "                'pad_token_id': pad_token_id,\n",
    "            }\n",
    "\n",
    "        self.field_to_fieldinfo = field_to_fieldinfo\n",
    "\n",
    "\n",
    "        TargetField_CFs = [CF for CF in CF_list if TargetField in CF] \n",
    "        target_field_vocab = CF_to_CFvocab[TargetField_CFs[0]]\n",
    "        self.target_field_vocab = target_field_vocab\n",
    "        tkn2tid = target_field_vocab['input_ids']['tkn2tid']   \n",
    "        self.lsm_vocab_size = len(tkn2tid)\n",
    "        self.lsm_bos_token_id = tkn2tid['[BOS]']\n",
    "        self.lsm_eos_token_id = tkn2tid['[EOS]']\n",
    "        self.lsm_pad_token_id = 0\n",
    "\n",
    "        \n",
    "    def to_dict(self):\n",
    "        output = super().to_dict()\n",
    "        \n",
    "        # List of fields to exclude\n",
    "        fields_to_exclude = ['CF_to_CFvocab', 'target_field_vocab', 'OneEntryArgs']\n",
    "        \n",
    "        # Remove excluded fields if they exist\n",
    "        for field in fields_to_exclude:\n",
    "            if field in output:\n",
    "                del output[field]\n",
    "                \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArgs = {\n",
    "    'model_type': 'cgmlhm',\n",
    "    'OneEntryArgs': aidata.OneEntryArgs,\n",
    "    'CF_to_CFvocab': aidata.CF_to_CFvocab,\n",
    "}\n",
    "\n",
    "config = CgmLhmConfig(**ModelArgs)\n",
    "# print(config)\n",
    "config.field_to_fieldinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ca73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3069de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.configuration_cgmlsm import CgmLsmConfig\n",
    "\n",
    "lsm_kwargs = {k.split('lsm_')[1]: v for k, v in config.to_dict().items() if 'lsm_' in k}\n",
    "lsm_kwargs\n",
    "\n",
    "lsm_config = CgmLsmConfig(**lsm_kwargs)\n",
    "lsm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ff95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_kwargs = {k.split('fe_')[1]: v for k, v in config.to_dict().items() if 'fe_' in k}\n",
    "# fe_kwargs['n_embd'] = config.n_embd\n",
    "\n",
    "from nn.cgmlhm.configuration_fieldencoder import FieldEncoderConfig\n",
    "\n",
    "field_to_feconfig = {}\n",
    "for field, fieldinfo in config.field_to_fieldinfo.items():\n",
    "    fe_config = FieldEncoderConfig(**{'field': field, 'fieldinfo': fieldinfo}, **fieldinfo, **fe_kwargs)\n",
    "    field_to_feconfig[field] = fe_config\n",
    "\n",
    "pprint(field_to_feconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bf50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_kwargs = {k.split('sc_')[1]: v for k, v in config.to_dict().items() if 'sc_' in k}\n",
    "pprint(sc_kwargs, compact=True, sort_dicts=True)\n",
    "\n",
    "\n",
    "from nn.cgmlhm.configuration_fieldencoder import FieldEncoderConfig\n",
    "\n",
    "sc_config = FieldEncoderConfig(**sc_kwargs)\n",
    "sc_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_kwargs = {k.split('tf_')[1]: v for k, v in config.to_dict().items() if 'tf_' in k}\n",
    "\n",
    "from nn.cgmlhm.configuration_cgmlsm import CgmLsmConfig\n",
    "\n",
    "\n",
    "tf_config = CgmLsmConfig(**tf_kwargs)\n",
    "tf_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c75762",
   "metadata": {},
   "source": [
    "# CGMLSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac011e37",
   "metadata": {},
   "source": [
    "## Step 1: model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a285a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e8813",
   "metadata": {},
   "source": [
    "## Step 2: model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f81ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_cgmlsm import CgmLsmModel\n",
    "\n",
    "lsm_model = CgmLsmModel(lsm_config)\n",
    "lsm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ef1f6",
   "metadata": {},
   "source": [
    "## Step 3: forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df471ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsm_model_inputs = {k: v for k, v in batch.items() if '--' not in k}\n",
    "# lsm_model_inputs\n",
    "\n",
    "\n",
    "lsm_model_inputs = {\n",
    "    'input_ids': batch['input_ids'],\n",
    "}\n",
    "\n",
    "\n",
    "lsm_outputs = lsm_model(**lsm_model_inputs)\n",
    "lsm_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc9aea",
   "metadata": {},
   "source": [
    "\n",
    "# FieldEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c3c02",
   "metadata": {},
   "source": [
    "## Step 1:model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ec6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_feconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a5067",
   "metadata": {},
   "source": [
    "## Step 2: model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_fieldencoder import FieldEncoderModel\n",
    "import torch \n",
    "\n",
    "\n",
    "field_encoders = torch.nn.ModuleDict()\n",
    "\n",
    "\n",
    "for field, fe_config in field_to_feconfig.items():\n",
    "    field_encoder = FieldEncoderModel(fe_config)\n",
    "    field_encoders[field] = field_encoder\n",
    "\n",
    "field_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf99b2",
   "metadata": {},
   "source": [
    "## step 3: forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_to_encoder_outputs = {}\n",
    "\n",
    "for field, fe_config in field_to_feconfig.items():\n",
    "\n",
    "    print('\\n===================')\n",
    "    print(field)\n",
    "    field_encoder = field_encoders[field]   \n",
    "\n",
    "\n",
    "    batch_field_inputs = {k.split('--')[1]: v for k, v in batch.items() if field + '--' in k}\n",
    "\n",
    "\n",
    "    for value_name, values in batch_field_inputs.items():\n",
    "        print(value_name, values.shape)\n",
    "\n",
    "\n",
    "    print('reshape')\n",
    "    for value_name, values in batch_field_inputs.items():\n",
    "        # print('before', value_name, values.shape)\n",
    "        a, b = values.size(0), values.size(1)\n",
    "        values = values.view(a * b, -1)\n",
    "        batch_field_inputs[value_name] = values\n",
    "        print(value_name, values.shape)\n",
    "\n",
    "    use_event_indictors = False\n",
    "    if 'event_indicators' in batch_field_inputs:\n",
    "        use_event_indictors = True\n",
    "        event_indicators = batch_field_inputs['event_indicators'] \n",
    "        mask = event_indicators.bool().squeeze() \n",
    "        batch_field_inputs_filtered = {}\n",
    "        for k, v in batch_field_inputs.items():\n",
    "            if k == 'event_indicators': continue\n",
    "            batch_field_inputs_filtered[k] = v[mask]\n",
    "        batch_field_inputs = batch_field_inputs_filtered\n",
    "\n",
    "    input_ids_field = batch_field_inputs['input_ids']\n",
    "    attention_mask_field = input_ids_field.ne(fe_config.pad_token_id)\n",
    "    batch_field_inputs['attention_mask'] = attention_mask_field\n",
    "\n",
    "\n",
    "    print('\\nfinal batch_field_inputs')\n",
    "    for k, v in batch_field_inputs.items(): print(k, v.shape)\n",
    "\n",
    "\n",
    "    ###### test the field_embeddings\n",
    "    # # field_encoder(**batch_field_inputs)\n",
    "    # field_embeddings = field_encoder.embeddings\n",
    "    # # print(field_embeddings)\n",
    "    # embed_results = field_embeddings(**batch_field_inputs)\n",
    "    # # print(results)\n",
    "    # print('field_embeddings', embed_results.shape)\n",
    "\n",
    "    print('\\nfield_encoder')\n",
    "    field_outputs = field_encoder(**batch_field_inputs)\n",
    "    hidden_state = field_outputs.last_hidden_state#.shape\n",
    "    print('field_outputs.hidden_state', hidden_state.shape)\n",
    "\n",
    "    pooler_output =field_outputs.pooler_output# .shape\n",
    "    print('field_outputs.pooler_output', pooler_output.shape)\n",
    "\n",
    "\n",
    "    # hidden_state\n",
    "    if use_event_indictors:\n",
    "        hidden_state_origin = torch.zeros([len(mask),] + list(hidden_state.shape[1:]))\n",
    "        hidden_state_origin[mask] = hidden_state\n",
    "    \n",
    "        pooler_output_origin = torch.zeros([len(mask),] + list(pooler_output.shape[1:]))\n",
    "        pooler_output_origin[mask] = pooler_output\n",
    "\n",
    "\n",
    "    else:\n",
    "        hidden_state_origin  = hidden_state\n",
    "        pooler_output_origin = pooler_output\n",
    "\n",
    "\n",
    "    new_shape = [a, b] + list(hidden_state.shape[1:])\n",
    "    # new_shape\n",
    "    hidden_state_origin = hidden_state_origin.reshape(new_shape)\n",
    "    print('field_outputs.hidden_state_origin', hidden_state_origin.shape)\n",
    "\n",
    "\n",
    "    # pooler_output_origin.shape\n",
    "    new_shape = [a, b] + list(pooler_output.shape[1:])\n",
    "    pooler_output_origin = pooler_output_origin.reshape(new_shape)\n",
    "    print('field_outputs.pooler_output_origin', pooler_output_origin.shape)\n",
    "\n",
    "\n",
    "    field_to_encoder_outputs[field] = {\n",
    "        'hidden_state': hidden_state_origin,\n",
    "        'pooler_output': pooler_output_origin,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd78d45",
   "metadata": {},
   "source": [
    "# StepConnector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a65a172",
   "metadata": {},
   "source": [
    "## Step 1: model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c620d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f631f07",
   "metadata": {},
   "source": [
    "## Step 2: model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ce0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_cgmlhm import StepConnector\n",
    "\n",
    "\n",
    "step_connector_model = StepConnector(sc_config)\n",
    "step_connector_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22026fcc",
   "metadata": {},
   "source": [
    "## Step 3: forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96eed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_state = lsm_outputs.last_hidden_state\n",
    "target_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_states = [encoder_outputs['pooler_output'] for field, encoder_outputs in field_to_encoder_outputs.items()]# ['Diet--event_indicators'].shape\n",
    "\n",
    "field_states\n",
    "# field_list= [i for i in field_to_encoder_outputs]\n",
    "\n",
    "step_state_list = [target_state] + field_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9042c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(step_state_list) > 1:\n",
    "    # get step_state, this should be the encoder. \n",
    "    step_field_states = torch.stack(step_state_list, dim=1)\n",
    "    connector_output = step_connector_model(step_field_states)\n",
    "    step_states = connector_output.pooler_output\n",
    "else:\n",
    "    step_states = target_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90cccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e6577",
   "metadata": {},
   "source": [
    "# CGMLHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e746ac22",
   "metadata": {},
   "source": [
    "## Step 1: model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932df161",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f365e7e0",
   "metadata": {},
   "source": [
    "## Step 2: model_structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_cgmlhm import CgmLhmModel\n",
    "\n",
    "model = CgmLhmModel(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca5c1d",
   "metadata": {},
   "source": [
    "## Step 3: forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bc587",
   "metadata": {},
   "source": [
    "# CGMLHM-LMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.cgmlhm.modeling_cgmlhm import GgmLhmLMHeadModel\n",
    "\n",
    "model = GgmLhmLMHeadModel(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b92537",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhm_outputs = model.lhm(**batch)\n",
    "lhm_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a121d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = lhm_outputs[0]\n",
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15adddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_logits = model.lm_head(hidden_states)\n",
    "lm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1520ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**batch)\n",
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67752cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233053c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}