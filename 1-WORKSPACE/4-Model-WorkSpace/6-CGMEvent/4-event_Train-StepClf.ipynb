{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881d73c8-f12f-4a9b-a485-996a76289767",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b19d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "SPACE['MODEL_ENDPOINT'] = 'vTest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57492949",
   "metadata": {},
   "source": [
    "# Part 1: AIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cbd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.aidata import AIData\n",
    "\n",
    "DATA_AIDATA = SPACE['DATA_AIDATA']\n",
    "OneAIDataName = 'CgmLhm_Bf24Af2Af2t8H_5Min_3Cohort_EventFlt_Sample'\n",
    "\n",
    "aidata = AIData.load_aidata(DATA_AIDATA, OneAIDataName, SPACE)\n",
    "aidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs = {\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "\n",
    "        'Tagging': {\n",
    "            # 'TagName_to_TaggingMethod': {\n",
    "            #     # TagName: TaggingMethod {Rules: [(x,x,x)], Op: and or}\n",
    "            # },\n",
    "            # 'ColumnsAddToDsCase': [],\n",
    "            'TagFilter': True, # <--- still need to add Fitlter Tag, as we need to do the RandomDownSample.\n",
    "            'TagSplit': False, # <--- do not need to add Split Tag anymore, as we already have. \n",
    "        },\n",
    "\n",
    "        'Filtering': {\n",
    "            # 'FilterTagging': None,\n",
    "            'FilterTagging': {\n",
    "                \"Rules\": [\n",
    "                    ['RandDownSample', '<=', 0.5],\n",
    "                    ['co.Bf24H_Food_recnum:recnum', '>=', 1], \n",
    "                    ], \n",
    "                'Op': 'and',\n",
    "            }\n",
    "        }, \n",
    "        \n",
    "        'Splitting': {\n",
    "            # 'SplitTagging': { # <----- for the Tagging part.\n",
    "            #     'RANDOM_SEED': 32,\n",
    "            #     'out_ratio': 0.1,\n",
    "            #     'test_ratio': 'tail0.1',\n",
    "            #     'valid_ratio': 0.1\n",
    "            # },\n",
    "            'TrainEvals': {\n",
    "                'TrainSetName': 'In-Train', \n",
    "                'EvalSetNames': ['In-Test', 'In-Valid', 'Out']\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "\n",
    "            'cf.ActivitySparse_Bf24H',\n",
    "            'cf.ActivitySparse_Af2H',\n",
    "\n",
    "            # 'cf.TimeSparse_Bf24H', \n",
    "            # 'cf.TimeSparse_Af2H',\n",
    "\n",
    "\n",
    "            'cf.DietSparse_Bf24H',\n",
    "            'cf.DietSparse_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        # 'TimeField':   'Time',\n",
    "        'EventFields': [\n",
    "            'Activity',\n",
    "            'Diet',\n",
    "        ],\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'EventPrediction',\n",
    "        # 'MaskingRate': 0,\n",
    "        'Task_Label': 'Diet',\n",
    "        # other parameters toward X and Y value\n",
    "        'agg_function':None,\n",
    "        'label_process': None, \n",
    "        'use_gaussian_blur': False,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "aidata.update_NameToData_with_OneEntryArgs(OneEntryArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata.Name_to_DsAIData\n",
    "\n",
    "split_name = [i for i in  aidata.Name_to_Data][0]\n",
    "Name_to_Data = aidata.Name_to_Data# [split_name]\n",
    "Data = Name_to_Data[split_name]\n",
    "df_case = Data['df_case']\n",
    "\n",
    "df_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfm = Data['ds_tfm']\n",
    "# ds_tfm\n",
    "\n",
    "batch_size = 4\n",
    "batch = ds_tfm[:batch_size]\n",
    "for k, v in batch.items(): print(k, v.shape)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1be4a",
   "metadata": {},
   "source": [
    "# Part 2: Model Init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4677e",
   "metadata": {},
   "source": [
    "## Step 1: init_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nn.cgmlhm.configuration_cgmlhm import CgmLhmConfig \n",
    "from nn.cgmevent.configuration_fieldencoder import FieldEncoderConfig\n",
    "\n",
    "ModelArgs = {\n",
    "    'model_type': 'cgm_encoder',\n",
    "    'num_classes': 2,\n",
    "    'num_hidden_layers': 6,\n",
    "}\n",
    "config = FieldEncoderConfig(**ModelArgs)\n",
    "# print(config)\n",
    "# config.field_to_fieldinfo\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9028ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nn.cgmevent.modeling_fieldencoder import FieldEncoderForStepClassification\n",
    "\n",
    "model = FieldEncoderForStepClassification(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, params in model.named_parameters():\n",
    "    print(layer_name, params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd78d45",
   "metadata": {},
   "source": [
    "# Part 3: Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "batch2dp = 8\n",
    "batch = ds_tfm.select(range(batch2dp))[:batch2dp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**batch)\n",
    "output.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f08bb",
   "metadata": {},
   "source": [
    "# Part 4: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata.TrainEvalsInTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb897ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata.Name_to_DsAIData\n",
    "###############################\n",
    "TrainSetName = aidata.TrainEvals['TrainSetName']\n",
    "EvalSetNames = aidata.TrainEvals['EvalSetNames']\n",
    "max_train_samples = 1000\n",
    "max_eval_samples = 64\n",
    "###############################\n",
    "\n",
    "\n",
    "# ------------ train datasets ------------\n",
    "TrainData = aidata.Name_to_Data[TrainSetName]\n",
    "ds_tfm_train = TrainData['ds_tfm']\n",
    "if max_train_samples is not None:\n",
    "    max_train_samples = min(len(ds_tfm_train), max_train_samples)\n",
    "    ds_tfm_train = ds_tfm_train.shuffle(seed=42).select(range(max_train_samples))\n",
    "logger.info(ds_tfm_train)\n",
    "\n",
    "\n",
    "# ------------ eval datasets ------------\n",
    "eval_dataset_dict = {}\n",
    "for evalname in EvalSetNames:\n",
    "    if evalname not in aidata.Name_to_Data: \n",
    "        logger.info(f'{evalname} not in aidata.Name_to_Data')\n",
    "        continue\n",
    "    eval_dataset = aidata.Name_to_Data[evalname]['ds_tfm']\n",
    "    if max_eval_samples is not None:\n",
    "        max_eval_samples = min(len(eval_dataset), max_eval_samples)\n",
    "        eval_dataset = eval_dataset.shuffle(seed=42).select(range(max_eval_samples))\n",
    "    eval_dataset_dict[evalname] = eval_dataset\n",
    "logger.info(f'---- eval_datasets ----')\n",
    "logger.info(eval_dataset_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0fb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ds_tfm_train))\n",
    "for k, v in eval_dataset_dict.items():\n",
    "    print(k, len(v))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c77a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0face",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, TrainerCallback\n",
    "\n",
    "\n",
    "#################################\n",
    "HuggingFaceTrainingArgs = {\n",
    "    'output_dir': '_test',  # will be updated to model_instance.model_checkpoint_path\n",
    "    'overwrite_output_dir': False,\n",
    "\n",
    "    'do_train': True, \n",
    "    'num_train_epochs': 10,\n",
    "    'per_device_train_batch_size': 4, # 64, # 4, # 64\n",
    "    'per_device_eval_batch_size': 4, # 64, # 4, # 64\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'save_strategy': 'epoch',\n",
    "    'save_total_limit': 10, \n",
    "\n",
    "    'logging_steps': 1,\n",
    "\n",
    "    'do_eval': True, \n",
    "    'eval_steps': 100, \n",
    "    'eval_strategy': 'steps',\n",
    "    'report_to': 'wandb',\n",
    "\n",
    "\n",
    "    'save_strategy': 'steps',\n",
    "    'save_steps': 1000,\n",
    "    'save_total_limit': 3,\n",
    "\n",
    "    \n",
    "    \n",
    "    # ------- do not change these -------\n",
    "    'remove_unused_columns': False, # <--- must be False.\n",
    "    'dataloader_drop_last': True,\n",
    "}\n",
    "#################################\n",
    "\n",
    "training_args = TrainingArguments(**HuggingFaceTrainingArgs)\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c57d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_FOR_CAUSAL_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    is_torch_tpu_available,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "print(training_args.seed)\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datasets.fingerprint import Hasher \n",
    "\n",
    "###################\n",
    "AfTknNum = 24\n",
    "###################\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H\")\n",
    "experiment_id = timestamp + \"-\" + Hasher().hash([aidata.OneAIDataArgs, config])\n",
    "\n",
    "print(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66397508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimestampCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        # Add the current timestamp to the logs\n",
    "        logs[\"step\"] = state.global_step\n",
    "        logs[\"timestamp\"] = str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "## Change this one. \n",
    "\n",
    "\n",
    "def compute_metrics_for_ntp(eval_preds, experiment_id, AfTknNum = 24):\n",
    "\n",
    "    metric_acc = evaluate.load(\"accuracy\", experiment_id = experiment_id)\n",
    "    metric_mse = evaluate.load('mse',      experiment_id = experiment_id)\n",
    "\n",
    "    preds, labels = eval_preds\n",
    "    # print(preds.shape, labels.shape)\n",
    "    # print(preds.shape, labels.shape)\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics but we need to shift the labels\n",
    "    labels = labels[:, 1:]\n",
    "    preds  = preds[:, :-1] \n",
    "    # print(preds.shape, labels.shape)\n",
    "\n",
    "    all_labels = labels.reshape(-1)\n",
    "    all_preds = preds.reshape(-1)\n",
    "    # print(all_labels.shape, all_preds.shape)\n",
    "\n",
    "\n",
    "    af_labels = labels[:, -AfTknNum:].reshape(-1)\n",
    "    af_preds  = preds[:, -AfTknNum:].reshape(-1)\n",
    "    # print(af_labels.shape, af_preds.shape)\n",
    "    \n",
    "    d_accu = metric_acc.compute(predictions=all_preds, references=all_labels)\n",
    "    d_mse = metric_mse.compute(predictions=all_preds, references=all_labels)\n",
    "    d_accu_af = metric_acc.compute(predictions=af_preds, references=af_labels)\n",
    "    d_mse_af = metric_mse.compute(predictions=af_preds, references=af_labels)\n",
    "    \n",
    "    d = {}\n",
    "    for k, v in d_accu.items(): d[k] = v\n",
    "    for k, v in d_accu_af.items(): d[k + '_af'] = v\n",
    "\n",
    "    for k, v in d_mse.items(): d[k] = v\n",
    "    for k, v in d_mse_af.items(): d[k + '_af'] = v\n",
    "\n",
    "    d['rMSE'] = np.sqrt(d['mse'])\n",
    "    d['rMSEaf'] = np.sqrt(d['mse_af'])\n",
    "    \n",
    "    d['ACUU']   = d['accuracy'] # np.sqrt()\n",
    "    d['ACUUaf'] = d['accuracy_af'] # np.sqrt()\n",
    "    \n",
    "    del d['mse'], d['mse_af'], d['accuracy'], d['accuracy_af']\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e26f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        # Depending on the model and config, logits may contain extra tensors,\n",
    "        # like past_key_values, but logits always come first\n",
    "        logits = logits[0]\n",
    "    # print(logits.shape, type(logits), '<----- logits')\n",
    "    return logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca635626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.profiler import profile, ProfilerActivity, schedule as profiler_schedule\n",
    "\n",
    "# class CorrectProfilerCallback(TrainerCallback):\n",
    "#     def __init__(self, wait=1, warmup=1, active=3):\n",
    "#         self.wait_steps = wait\n",
    "#         self.warmup_steps = warmup\n",
    "#         self.active_steps = active\n",
    "#         self.profiler = None\n",
    "#         self.step_count = 0\n",
    "#         self.profiling_active = False  # Track state manually\n",
    "\n",
    "#     def on_train_begin(self, args, state, control, **kwargs):\n",
    "#         self.profiler = profile(\n",
    "#             activities=[ProfilerActivity.CUDA],\n",
    "#             schedule=profiler_schedule(\n",
    "#                 wait=self.wait_steps,\n",
    "#                 warmup=self.warmup_steps,\n",
    "#                 active=self.active_steps,\n",
    "#                 repeat=1\n",
    "#             ),\n",
    "#             on_trace_ready=self._on_trace_ready,\n",
    "#             record_shapes=True\n",
    "#         )\n",
    "\n",
    "#     def _on_trace_ready(self, prof):\n",
    "#         print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n",
    "\n",
    "#     def on_step_begin(self, args, state, control, **kwargs):\n",
    "#         if not self.profiling_active and state.global_step >= self.wait_steps:\n",
    "#             self.profiler.start()\n",
    "#             self.profiling_active = True\n",
    "\n",
    "#     def on_step_end(self, args, state, control, **kwargs):\n",
    "#         if self.profiling_active:\n",
    "#             self.profiler.step()\n",
    "#             self.step_count += 1\n",
    "\n",
    "#     def on_train_end(self, args, state, control, **kwargs):\n",
    "#         if self.profiling_active:\n",
    "#             self.profiler.stop()\n",
    "#             self.profiling_active = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    ########## you have your model \n",
    "    model = model,\n",
    "    ########## you have your training_args\n",
    "    args = training_args,\n",
    "    ########## get train_dataset\n",
    "    train_dataset = ds_tfm_train, # if training_args.do_train else None,\n",
    "    ########## get eval_dataset\n",
    "    eval_dataset = eval_dataset_dict, # <--- for in-training evaluation\n",
    "    ########## huge question here: is it ok to ignore the tokenizer?\n",
    "    # tokenizer = tokenizer, # Apr 2024: don't add tokenizer, hard to save.\n",
    "    ########## huge question here: data_collator\n",
    "    data_collator = default_data_collator,\n",
    "    compute_metrics = lambda x: compute_metrics_for_ntp(x, experiment_id, AfTknNum),\n",
    "    preprocess_logits_for_metrics = preprocess_logits_for_metrics,\n",
    "    # callbacks = [CorrectProfilerCallback(wait=1, warmup=1, active=3)],\n",
    ")\n",
    "\n",
    "logger.info(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training (for exactly 5 steps: wait=1 + warmup=1 + active=3)\n",
    "# training_args.max_steps = 5\n",
    "# training_args.max_steps = None \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe22bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()  # Before starting profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e0369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c90283a2",
   "metadata": {},
   "source": [
    "# Final Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds_tfm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93483762",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ccaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "def prepare_last_checkpoint(training_args):\n",
    "    # ------------------------------- part 3: last checkpoint -------------------------------\n",
    "    # Detecting last checkpoint.\n",
    "    last_checkpoint = None\n",
    "\n",
    "    dont_overwrite_output_dir = bool(not training_args.overwrite_output_dir)\n",
    "\n",
    "    if os.path.isdir(training_args.output_dir) and training_args.do_train and dont_overwrite_output_dir:\n",
    "\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "               f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "            logger.info(\n",
    "               f\"Checkpoint detected, resuming training at {last_checkpoint}.\"\n",
    "                \"To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    return last_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8401d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = prepare_last_checkpoint(training_args)\n",
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e364e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in trainer.get_train_dataloader():\n",
    "    print(f\"Batch shape: {batch['input_ids'].shape}\")\n",
    "    break  # Just check the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61380794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5466579 / 64 / 4 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533a8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train(resume_from_checkpoint = checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887cdaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}