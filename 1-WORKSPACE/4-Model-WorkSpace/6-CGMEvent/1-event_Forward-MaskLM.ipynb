{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881d73c8-f12f-4a9b-a485-996a76289767",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51dc73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "SPACE['MODEL_ENDPOINT'] = 'vTest'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3efc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "SPACE['MODEL_ENDPOINT'] = 'vTest'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034206a",
   "metadata": {},
   "source": [
    "# Part 1: AIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.aidata import AIData\n",
    "\n",
    "DATA_AIDATA = SPACE['DATA_AIDATA']\n",
    "OneAIDataName = 'CgmLhm_Bf24Af2Af2t8H_5Min_3Cohort_EventFlt_Sample'\n",
    "\n",
    "aidata = AIData.load_aidata(DATA_AIDATA, OneAIDataName, SPACE)\n",
    "aidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs = {\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "\n",
    "        'Tagging': {\n",
    "            # 'TagName_to_TaggingMethod': {\n",
    "            #     # TagName: TaggingMethod {Rules: [(x,x,x)], Op: and or}\n",
    "            # },\n",
    "            # 'ColumnsAddToDsCase': [],\n",
    "            'TagFilter': True, # <--- still need to add Fitlter Tag, as we need to do the RandomDownSample.\n",
    "            'TagSplit': False, # <--- do not need to add Split Tag anymore, as we already have. \n",
    "        },\n",
    "\n",
    "        'Filtering': {\n",
    "            # 'FilterTagging': None,\n",
    "            'FilterTagging': {\n",
    "                \"Rules\": [\n",
    "                    ['RandDownSample', '<=', 0.5],\n",
    "                    ['co.Bf24H_Food_recnum:recnum', '>=', 1], \n",
    "                    ], \n",
    "                'Op': 'and',\n",
    "            }\n",
    "        }, \n",
    "        \n",
    "        'Splitting': {\n",
    "            # 'SplitTagging': { # <----- for the Tagging part.\n",
    "            #     'RANDOM_SEED': 32,\n",
    "            #     'out_ratio': 0.1,\n",
    "            #     'test_ratio': 'tail0.1',\n",
    "            #     'valid_ratio': 0.1\n",
    "            # },\n",
    "            'TrainEvals': {\n",
    "                'TrainSetName': 'In-Train', \n",
    "                'EvalSetNames': ['In-Test', 'In-Valid', 'Out']\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "\n",
    "            'cf.ActivitySparse_Bf24H',\n",
    "            'cf.ActivitySparse_Af2H',\n",
    "\n",
    "            # 'cf.TimeSparse_Bf24H', \n",
    "            # 'cf.TimeSparse_Af2H',\n",
    "\n",
    "\n",
    "            'cf.DietSparse_Bf24H',\n",
    "            'cf.DietSparse_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        # 'TimeField':   'Time',\n",
    "        'EventFields': [\n",
    "            'Activity',\n",
    "            'Diet',\n",
    "        ],\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'EventPrediction',\n",
    "        # 'MaskingRate': 0,\n",
    "        'Task_Label': 'Diet',\n",
    "        # other parameters toward X and Y value\n",
    "        'agg_function':None,\n",
    "        'label_process': None, \n",
    "        'use_gaussian_blur': False,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "aidata.update_NameToData_with_OneEntryArgs(OneEntryArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525821a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata.Name_to_DsAIData\n",
    "split_name = [i for i in  aidata.Name_to_Data][0]\n",
    "Name_to_Data = aidata.Name_to_Data# [split_name]\n",
    "Data = Name_to_Data[split_name]\n",
    "df_case = Data['df_case']\n",
    "df_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bacbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['df_case'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1229a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "batch = ds_tfm[:batch_size]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ee9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['labels'][0]# .sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c629a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aidata.CF_to_CFvocab\n",
    "\n",
    "# aidata.OneEntryArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a520c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import evaluate  # New Hugging Face library for evaluation metrics\n",
    "\n",
    "# # Load accuracy metric\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     preds = np.argmax(logits, axis=-1)  # Get highest probability token\n",
    "\n",
    "#     # Flatten for sequence-based accuracy\n",
    "#     preds = preds.flatten()\n",
    "#     labels = labels.flatten()\n",
    "\n",
    "#     return metric.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ea518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "# import torch\n",
    "# from transformers import RobertaTokenizer\n",
    "\n",
    "# batch_size = 4\n",
    "# # Hugging Face Dataset expects input as a dictionary\n",
    "# data = ds_tfm[:batch_size]\n",
    "\n",
    "# # Create Hugging Face Dataset\n",
    "# dataset = Dataset.from_dict(data)\n",
    "\n",
    "# # Load tokenizer\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# pad_token_id = tokenizer.pad_token_id\n",
    "# max_length = 8\n",
    "\n",
    "# # Define padding and truncation function\n",
    "# def preprocess_function(examples):\n",
    "#     # Truncate and pad input_ids\n",
    "#     padded_inputs = []\n",
    "#     attention_masks = []\n",
    "#     for input_id in examples[\"input_ids\"]:\n",
    "#         # Truncate or pad to max_length\n",
    "#         if len(input_id) > max_length:\n",
    "#             input_id = input_id[:max_length]\n",
    "#         else:\n",
    "#             input_id = input_id + [pad_token_id] * (max_length - len(input_id))\n",
    "        \n",
    "#         # Generate attention mask\n",
    "#         attention_mask = [1 if token != pad_token_id else 0 for token in input_id]\n",
    "        \n",
    "#         padded_inputs.append(input_id)\n",
    "#         attention_masks.append(attention_mask)\n",
    "    \n",
    "#     examples[\"input_ids\"] = padded_inputs\n",
    "#     examples[\"attention_mask\"] = attention_masks\n",
    "#     return examples\n",
    "\n",
    "# # Apply the preprocessing to the dataset\n",
    "# processed_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# processed_dataset.set_format(\n",
    "#     type=\"torch\", \n",
    "#     columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "# )\n",
    "\n",
    "\n",
    "# # Fetch a batch (batch_size = 4)\n",
    "# batch_size = 4\n",
    "# batch = processed_dataset[:batch_size]\n",
    "# print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['input_ids'] .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = processed_dataset['input_ids']\n",
    "# input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1423e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522216e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids[2, :] # 313 = 288 (24h) +  1 (obspoint) + 24 (2h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7738243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = batch['labels']\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d202eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1be4a",
   "metadata": {},
   "source": [
    "# Part 2: Model Init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4677e",
   "metadata": {},
   "source": [
    "## CgmEventConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArgs = {\n",
    "    'model_type': 'cgm_encoder',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9028ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import logging\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_FOR_CAUSAL_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    ")\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_CAUSAL_LM_MAPPING.keys())\n",
    "# MODEL_CONFIG_CLASSES\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "# MODEL_TYPES\n",
    "\n",
    "############# this is the NN development that showing our novelty #############\n",
    "from nn.cgmevent.configuration_fieldencoder import FieldEncoderConfig\n",
    "# from nn.cgmevent.modeling_fieldencoder_cgm import FieldEncoderModel\n",
    "from nn.cgmevent.modeling_fieldencoder import FieldEncoderForStepClassification\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- within the method of init_model.\n",
    "CF_to_CFvocab = aidata.CF_to_CFvocab\n",
    "CF = list(CF_to_CFvocab.keys())[0]\n",
    "CFvocab = CF_to_CFvocab[CF]\n",
    "tkn2tid = CFvocab['input_ids']['tkn2tid']\n",
    "\n",
    "config_kwargs = {\n",
    "    # \"cache_dir\": model_args.cache_dir,\n",
    "    # \"revision\": model_args.model_revision,\n",
    "    # \"token\": model_args.token,\n",
    "    # \"trust_remote_code\": model_args.trust_remote_code,\n",
    "    ###########\n",
    "    'vocab_size': len(tkn2tid),\n",
    "    'bos_token_id': tkn2tid['[BOS]'],\n",
    "    'eos_token_id': tkn2tid['[EOS]'],\n",
    "    'pad_token_id':  0,\n",
    "    ###########\n",
    "}\n",
    "\n",
    "ModelArgs.update(config_kwargs)\n",
    "\n",
    "# pprint(ModelArgs)\n",
    "config = FieldEncoderConfig(**ModelArgs)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be85e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FieldEncoderForStepClassification(config) \n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd78d45",
   "metadata": {},
   "source": [
    "# Part 3: Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "\n",
    "batch2dp = 8\n",
    "\n",
    "batch = ds_tfm.select(range(batch2dp))[:batch2dp]\n",
    "inputs = batch \n",
    "\n",
    "input_batch = {'input_ids': torch.LongTensor(inputs['input_ids']),\n",
    "               'labels': torch.LongTensor(inputs['labels'])}\n",
    "for k, v in input_batch.items():\n",
    "    print(k, v.shape)   \n",
    "    \n",
    "inputs = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9afe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b92537",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_outputs = model.forward(**input_batch)\n",
    "transformer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874dd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in transformer_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_outputs['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1520ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**input_batch)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fcbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(output).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}