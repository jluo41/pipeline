{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "SPACE['MODEL_ENDPOINT'] = 'vTest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Record and CaseSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_record.Cohort import CohortName_to_OneCohortArgs\n",
    "from config.config_case.CKPD import Ckpd_to_CkpdObsConfig\n",
    "from recfldtkn.record_base import Record_Base\n",
    "\n",
    "###################################\n",
    "HumanRecordRecfeat_Args = {\n",
    "    'P': {\n",
    "        'BP': [],\n",
    "        'CGM5Min': ['CGM5Min-N2Cin1'],\n",
    "        'Carb': ['Carb-N2Cin20'],\n",
    "        'Exercise': ['Exercise-Nume'],\n",
    "        'Food': ['Food-NutriNume'],\n",
    "        'P': ['P-DemoCate'],\n",
    "        'Sleep': ['Sleep-Nume'],\n",
    "        'Step': ['Step-Nume'],\n",
    "        'Weight': ['Weight-Nume'],\n",
    "        'PHeight': [], \n",
    "    }\n",
    "}\n",
    "\n",
    "# CohortName = '20240701_Spiriva'\n",
    "CohortName_list = [\n",
    "    # 'WellDoc2022CGM', \n",
    "    # 'WellDoc2023CVSTDC',\n",
    "    'WellDoc2023CVSDeRx'\n",
    "]\n",
    "HumanRecordRecfeat_Args = HumanRecordRecfeat_Args\n",
    "Record_Proc_Config = {'save_data': True, 'load_data': True, 'via_method': 'ds'}\n",
    "Inference_Entry = None # this is not inference mode\n",
    "###################################\n",
    "\n",
    "\n",
    "record_base = Record_Base(CohortName_list, \n",
    "                        HumanRecordRecfeat_Args,\n",
    "                        CohortName_to_OneCohortArgs,\n",
    "                        SPACE = SPACE, \n",
    "                        Inference_Entry = Inference_Entry,\n",
    "                        Record_Proc_Config = Record_Proc_Config,\n",
    "                        )\n",
    "record_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_case.GROUP import GROUP_TO_GROUPMethodArgs\n",
    "from config.config_case.CF import CF_to_CFArgs\n",
    "from config.config_case.CKPD import Ckpd_to_CkpdObsConfig\n",
    "from config.config_case.TagRec import TagRec_to_TagRecArgs\n",
    "from config.config_case.TagCF import TagCF_to_TagCFArgs \n",
    "from config.config_case.Flt import FltName_to_FltArgs\n",
    "from config.config_case.CASE import TriggerCaseBaseName_to_TriggerCaseBaseArgs\n",
    "\n",
    "from recfldtkn.case_base.case_base import OneCohortTrigger_CaseBase\n",
    "from recfldtkn.case_base.case_base import CaseSetManager, Case_Base\n",
    "\n",
    "Case_Args_Settings = {\n",
    "    'Ckpd_to_CkpdObsConfig': Ckpd_to_CkpdObsConfig,\n",
    "    'CF_to_CFArgs': CF_to_CFArgs,\n",
    "    'TagCF_to_TagCFArgs': TagCF_to_TagCFArgs,\n",
    "    'TagRec_to_TagRecArgs': TagRec_to_TagRecArgs,\n",
    "    'FltName_to_FltArgs': FltName_to_FltArgs,\n",
    "    'GROUP_TO_GROUPMethodArgs': GROUP_TO_GROUPMethodArgs,\n",
    "}\n",
    "\n",
    "Case_Proc_Config = {\n",
    "    'max_trigger_case_num': None, \n",
    "    'use_task_cache': False, \n",
    "    'caseset_chunk_size': 10000, # 200k for CGM, 50k for others.\n",
    "    'save_data': True, \n",
    "    'load_data': True, \n",
    "    'load_casecollection': True,\n",
    "    'via_method': 'ds',\n",
    "    'n_cpus': 1, \n",
    "    'batch_size': 1000,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "TriggerCaseBaseName = 'WeightEntry-FutureWeightAndMultiHistoricalEgm'\n",
    "\n",
    "\n",
    "TriggerCaseBaseArgs =  {\n",
    "    'Trigger': {\n",
    "        'TriggerName': 'WeightEntry', \n",
    "        'TagRec': [\n",
    "            'TagRec.PDemoFromP',\n",
    "        ],\n",
    "        'Filter': 'FltBasicDemo',\n",
    "        'Group': 'GrpGenderDisease', # <--- get CaseSetName_to_CaseSet \n",
    "        'ObsTask': {\n",
    "            'TagCF_list': [\n",
    "                'TagCF.FutureWeightInfo', \n",
    "            ],\n",
    "            'CF_list':  [\n",
    "                'cf.PDemo',\n",
    "                'cf.Bf1mRecNum',\n",
    "                'cf.Bf24hCGMFeat',\n",
    "                'cf.Bf24hMedalFeat',\n",
    "                'cf.Bf1mMedalFeat',\n",
    "                'cf.Bf2mMedalFeat',\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# CohortTriggerCaseBaseArgs = Name_to_CohortTriggerCaseBaseArgs[TriggerCaseBaseName]\n",
    "TriggerCaseBaseName_to_TriggerCaseBaseArgs[TriggerCaseBaseName] = TriggerCaseBaseArgs\n",
    "pprint(TriggerCaseBaseArgs, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TriggerCaseBaseName_to_CohortNameList = {\n",
    "    TriggerCaseBaseName: CohortName_list,\n",
    "}\n",
    "\n",
    "TriggerCaseBaseName_to_CohortNameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_base = Case_Base(\n",
    "    record_base = record_base, \n",
    "    TriggerCaseBaseName_to_CohortNameList = TriggerCaseBaseName_to_CohortNameList, \n",
    "    TriggerCaseBaseName_to_TriggerCaseBaseArgs = TriggerCaseBaseName_to_TriggerCaseBaseArgs,\n",
    "    Case_Proc_Config = Case_Proc_Config,\n",
    "    Case_Args_Settings = Case_Args_Settings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: AIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneDataName = 'UnilabelWeightpredAf1M'\n",
    "\n",
    "\n",
    "OneEntryArgsTemplate = {\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "        'Tagging': {\n",
    "            'TagName_to_TaggingMethod': {\n",
    "                # TagName: TaggingMethod {Rules: [(x,x,x)], Op: and or}\n",
    "            },\n",
    "            'ColumnsAddToDsCase': [],\n",
    "            'TagFilter': True,\n",
    "            'TagSplit': True, \n",
    "        },\n",
    "\n",
    "        'Filtering': {\n",
    "            'FilterTagging': {\n",
    "                'Rules': [\n",
    "                    ('co.Weight_Af1Minfo:no_future_weight', '!=', 1),\n",
    "                ],\n",
    "                'Op': 'and',\n",
    "            }\n",
    "        }, \n",
    "        \n",
    "        'Splitting': {\n",
    "            'SplitTagging': {\n",
    "                'RANDOM_SEED': 42,\n",
    "                # 'downsample_ratio': 1,\n",
    "                'out_ratio': 0.0, # hold-out patients. \n",
    "                'test_ratio': 0.2,\n",
    "                'valid_ratio': 0.0\n",
    "            },\n",
    "            'TrainEvals': {\n",
    "                'TrainSetName': 'Train',\n",
    "                'EvalSetNames': ['Test'],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'SparseMatrixFromMultiCF',\n",
    "        'InputCFs_Args': [\n",
    "            'cf.PDemo',\n",
    "            'cf.Bf1mRecNum',\n",
    "            'cf.Bf24hCGMFeat',\n",
    "            'cf.Bf24hMedalFeat',\n",
    "            'cf.Bf1mMedalFeat',\n",
    "            'cf.Bf2mMedalFeat',\n",
    "        ],\n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'MLUniLabel',\n",
    "        \n",
    "        # -----------\n",
    "        # 'Labeling': ('co.Weight_Af1Minfo:weight_loss_pct', '>', 0.02), \n",
    "        'Labeling': None, \n",
    "        # -----------\n",
    "    },\n",
    "}\n",
    "\n",
    "DataVariantName_to_Args = {\n",
    "    'WeightLossPctLarge2': {\n",
    "        'Output_Part:Labeling': ('co.Weight_Af1Minfo:weight_loss_pct', '>', 0.02),\n",
    "    },\n",
    "    # 'WeightLossPctLarge4': {\n",
    "    #     'Output_Part:Labeling': ('co.Weight_Af1Minfo:weight_loss_pct', '>', 0.04),\n",
    "    # },\n",
    "    # 'WeightLossPctLarge6': {\n",
    "    #     'Output_Part:Labeling': ('co.Weight_Af1Minfo:weight_loss_pct', '>', 0.04),\n",
    "    # },\n",
    "    # 'WeightLossPctLarge8': {\n",
    "    #     'Output_Part:Labeling': ('co.Weight_Af1Minfo:weight_loss_pct', '>', 0.08),\n",
    "    # },\n",
    "    # 'WeightLossPctLarge10': {\n",
    "    #     'Output_Part:Labeling': ('co.Weight_Af1Minfo:weight_loss_pct', '>', 0.10),\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.aidata_base import get_OneAIDataName_to_OneAIDataArgs\n",
    "\n",
    "# SeriesName = 'UnilabelWeightpredAf1M' \n",
    "# OneEntryArgsTemplate = SeriesName_to_OneEntryArgsTemplate[SeriesName]\n",
    "####################\n",
    "OneAIDataName_to_OneAIDataArgs = get_OneAIDataName_to_OneAIDataArgs(OneDataName, \n",
    "                                                                    CohortName_list, \n",
    "                                                                    TriggerCaseBaseName,\n",
    "                                                                    TriggerCaseBaseArgs, \n",
    "                                                                    OneEntryArgsTemplate, \n",
    "                                                                    DataVariantName_to_Args)\n",
    "####################\n",
    "\n",
    "\n",
    "pprint(OneAIDataName_to_OneAIDataArgs, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.aidata_base import AIData_Base\n",
    "\n",
    "############## inference mode ####################\n",
    "# AIDataArgs_items_for_inference = ['TriggerCaseBaseName', 'Input_Args']\n",
    "# CohortName_list_for_inference = ['Inference']\n",
    "\n",
    "############## training mode ####################\n",
    "aidata_base = AIData_Base(\n",
    "    case_base = case_base, \n",
    "    OneAIDataName_to_OneAIDataArgs = OneAIDataName_to_OneAIDataArgs,\n",
    "    SPACE = SPACE, \n",
    ")   \n",
    "\n",
    "# pprint(aidata_base.OneAIDataName_to_OneAIDataArgs, sort_dicts=False)\n",
    "# pprint(aidata_base.AIDataHashName_to_AIDataArgs, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIDataName_list = aidata_base.get_AIDataName_list()\n",
    "\n",
    "OneAIDataName = AIDataName_list[0] \n",
    "\n",
    "OneAIData_Args = aidata_base.get_OneAIDataArgs_from_OneAIDataName(OneAIDataName)\n",
    "# pprint(OneAIData_Args, sort_dicts=False)\n",
    "\n",
    "aidata = aidata_base.get_aidata_from_OneAIDataName(OneAIDataName)\n",
    "aidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name_to_Data = aidata.Name_to_Data\n",
    "for Name, Data in Name_to_Data.items():\n",
    "    print(Name, [i for i in Data])\n",
    "    print(Name, ':', Data['ds_case'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Instance Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect \n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%% user generation\n",
    "ModelArgs = {\n",
    "    'model_type': 'XGBClassifierV1',\n",
    "    'random_state': 42, \n",
    "    'max_depth': 10,\n",
    "}\n",
    "\n",
    "TrainingArgs = {\n",
    "    'n_estimators': 1000, # num_boost_round\n",
    "    'learning_rate': 0.01, # eta\n",
    "    'objective': 'binary:logistic', \n",
    "    'early_stopping_rounds': 10,\n",
    "    'eval_metric': 'logloss',  \n",
    "}\n",
    "\n",
    "InferenceArgs = {}\n",
    "\n",
    "EvaluationArgs = {\n",
    "    'subgroup_config_list': [\n",
    "        ['EvalName'],\n",
    "        # ['EvalName', 'ageBucketGroup'], \n",
    "    ],\n",
    "    'y_real_label_name': 'y_real_label', \n",
    "    'y_pred_score_name': 'y_pred_score',\n",
    "    'EachThreshold_step': 100, \n",
    "    'PredScoreGroup_step': 100, \n",
    "    'GroupNum': 100,\n",
    "}\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%% user generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Model Instance Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.xgboost.instance_xgboost import XGBClassifierInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifierInstance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelInstance = XGBClassifierInstance\n",
    "model_artifact = ModelInstance(\n",
    "    aidata = aidata, \n",
    "    ModelArgs = ModelArgs, \n",
    "    TrainingArgs = TrainingArgs, \n",
    "    InferenceArgs = InferenceArgs, \n",
    "    EvaluationArgs = EvaluationArgs,\n",
    "    SPACE = SPACE,\n",
    ")\n",
    "\n",
    "print(model_artifact.model_artifact_name)\n",
    "print(model_artifact.model_artifact_path)\n",
    "\n",
    "model_artifact.init_model()\n",
    "model_artifact.model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_instance.model.save_model(model_path)\n",
    "######################## testing \n",
    "model_artifact_path = model_artifact.model_artifact_path\n",
    "######################## testing \n",
    "\n",
    "\n",
    "if not os.path.exists(model_artifact_path):\n",
    "    os.makedirs(model_artifact_path)\n",
    "\n",
    "model_path = os.path.join(model_artifact_path, 'model.json')\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_artifact.model_artifact_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_instance.fit()\n",
    "# model_instance.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost \n",
    "\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    logger.info(f'Loading model from {model_path}')\n",
    "    model = xgboost.XGBClassifier()\n",
    "    model.load_model(model_path)\n",
    "    model_artifact.model = model\n",
    "else:\n",
    "    model_artifact.fit()\n",
    "    model_artifact.model.save_model(model_path)\n",
    "    logger.info(f'Saved model to {model_path}')\n",
    "\n",
    "\n",
    "model_artifact.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in aidata.Name_to_Data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case_list = []\n",
    "\n",
    "for SetName in aidata.TrainEvals['EvalSetNames']:\n",
    "    Data = aidata.Name_to_Data[SetName]\n",
    "    # dataset = aidata.Name_to_DsAIData[SetName]\n",
    "    df_case = Data['df_case'].copy()\n",
    "    df_case['EvalName'] = SetName   \n",
    "    inference_results = model_artifact.inference(Data)\n",
    "    for k, v in inference_results.items():\n",
    "        print(k, len(v), len(df_case))\n",
    "        df_case[k] = v\n",
    "    df_case_list.append(df_case)\n",
    "\n",
    "df_case_eval = pd.concat(df_case_list)\n",
    "df_case_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case_eval['y_real_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SetName = 'Test'\n",
    "Data = aidata.Name_to_Data[SetName]\n",
    "# Data = aidata.Name_to_DsAIData[SetName]\n",
    "\n",
    "inference_results = model_artifact.inference(Data)\n",
    "inference_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact.EvaluationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact.evaluate()\n",
    "model_artifact.df_report_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact_path = model_artifact.model_artifact_path\n",
    "model_artifact_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "SPACE['MODEL_ENDPOINT'] = 'vTest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint_path = model_instance.model_checkpoint_path\n",
    "# model_artifact_path = '../_Model/Timely-Model/vTest/UniLabelPred-InvAf1w.AllBrand-Inv.Link-XGBClassifierV0.6-2024.08.31-f593c453f40068a0'\n",
    "model_artifact_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from recfldtkn.aidata_base.aidata import AIData \n",
    "from recfldtkn.model_base.model_base import load_model_artifact\n",
    "from nn import load_model_instance_from_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = load_model_artifact(model_artifact_path, load_model_instance_from_nn, SPACE)\n",
    "model_artifact.model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact.df_case_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact.df_report_neat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}