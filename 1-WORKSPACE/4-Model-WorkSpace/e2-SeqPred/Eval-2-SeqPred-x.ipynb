{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881d73c8-f12f-4a9b-a485-996a76289767",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b19d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "SPACE['MODEL_Task'] = 'Test_ntp'\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "SPACE['MODEL_VERSION'] = 'vTest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc6557",
   "metadata": {},
   "source": [
    "# Part 1: AIData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2d138",
   "metadata": {},
   "source": [
    "## Step 1: Record and Case Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ed4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_record.Cohort import CohortName_to_OneCohortArgs\n",
    "from config.config_case.CKPD import Ckpd_to_CkpdObsConfig\n",
    "from recfldtkn.record_base import Record_Base\n",
    "CohortNames = [i for i in CohortName_to_OneCohortArgs.keys()]\n",
    "print(CohortNames)\n",
    "\n",
    "###################################\n",
    "\n",
    "HumanRecordRecfeat_Args = {\n",
    "    'P': {\n",
    "        # 'BP': [],\n",
    "        'CGM5Min': ['CGM5Min-N2Cin1'],\n",
    "        # 'Carb': ['Carb-N2Cin20'],\n",
    "        # 'Exercise': ['Exercise-Nume'],\n",
    "        # 'Food': ['Food-NutriNume'],\n",
    "        'P': ['P-DemoCate'],\n",
    "        # 'Sleep': ['Sleep-Nume'],\n",
    "        # 'Step': ['Step-Nume'],\n",
    "        # 'Weight': ['Weight-Nume'],\n",
    "        # 'PHeight': [], \n",
    "    }\n",
    "}\n",
    "\n",
    "CohortName_list = [\n",
    "    # 'WellDoc2022CGM', \n",
    "    # 'WellDoc2023CVSTDC', \n",
    "    'WellDoc2023CVSDeRx',\n",
    "]\n",
    "HumanRecordRecfeat_Args = HumanRecordRecfeat_Args\n",
    "Record_Proc_Config = {'save_data': True, 'load_data':True, 'via_method': 'ds'}\n",
    "Inference_Entry = None # this is not inference mode\n",
    "###################################\n",
    "\n",
    "record_base = Record_Base(\n",
    "    CohortName_list, \n",
    "    HumanRecordRecfeat_Args,\n",
    "    CohortName_to_OneCohortArgs,\n",
    "    SPACE = SPACE, \n",
    "    Inference_Entry = Inference_Entry,\n",
    "    Record_Proc_Config = Record_Proc_Config,\n",
    ")\n",
    "\n",
    "record_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e66972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_case.GROUP import GROUP_TO_GROUPMethodArgs\n",
    "from config.config_case.CF import CF_to_CFArgs\n",
    "from config.config_case.CKPD import Ckpd_to_CkpdObsConfig\n",
    "from config.config_case.TagRec import TagRec_to_TagRecArgs\n",
    "from config.config_case.TagCF import TagCF_to_TagCFArgs \n",
    "from config.config_case.Flt import FltName_to_FltArgs\n",
    "from config.config_case.CASE import TriggerCaseBaseName_to_TriggerCaseBaseArgs\n",
    "\n",
    "from recfldtkn.case_base.case_base import OneCohortTrigger_CaseBase\n",
    "from recfldtkn.case_base.case_base import CaseSetManager, Case_Base\n",
    "\n",
    "Case_Args_Settings = {\n",
    "    'Ckpd_to_CkpdObsConfig': Ckpd_to_CkpdObsConfig,\n",
    "    'CF_to_CFArgs': CF_to_CFArgs,\n",
    "    'TagCF_to_TagCFArgs': TagCF_to_TagCFArgs,\n",
    "    'TagRec_to_TagRecArgs': TagRec_to_TagRecArgs,\n",
    "    'FltName_to_FltArgs': FltName_to_FltArgs,\n",
    "    'GROUP_TO_GROUPMethodArgs': GROUP_TO_GROUPMethodArgs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aedc5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Case_Proc_Config = {\n",
    "    'max_trigger_case_num': None, \n",
    "    'use_task_cache': False, \n",
    "    'caseset_chunk_size': 200000, # 200k for CGM, 50k for others.\n",
    "    'save_data': True, \n",
    "    'load_data': True, \n",
    "    'load_casecollection': True, \n",
    "    'via_method': 'ds',\n",
    "    'n_cpus': 8, \n",
    "    'batch_size': 1000,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25167e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TriggerCaseBaseName = 'Bf24HAf2H_CGM'\n",
    "TriggerCaseBaseArgs =  {\n",
    "    # --------- this three are relatively stable ----------------\n",
    "    'Trigger': {\n",
    "        'TriggerName': 'CGM5MinEntry', \n",
    "        'TagRec': [\n",
    "            'TagRec.PDemoFromP',\n",
    "        ],\n",
    "        'Group': 'GrpGenderDisease', # \n",
    "        'Filter': 'FltBasicDemo',\n",
    "        'ObsTask': {\n",
    "            'TagCF_list': [\n",
    "                'TagCF.Bf24hCGMinfo', \n",
    "                'TagCF.Af2hCGMinfo',\n",
    "            ],\n",
    "            'CF_list':  [],\n",
    "        }\n",
    "    },\n",
    "    # --------------------------------\n",
    "    \n",
    "    # --------------------------------\n",
    "    'FilterCaseSet': {\n",
    "        'Filter': 'FltMiniBfAfCGMRecInfo',\n",
    "        'ObsTask': {\n",
    "            'TagCF_list': [\n",
    "                'TagCF.Bf24hCGMinfo', \n",
    "                'TagCF.Af2hCGMinfo',\n",
    "            ],\n",
    "            'CF_list':  [\n",
    "                'cf.TargetCGM_Bf24H', \n",
    "                'cf.TargetCGM_Af2H',\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "    # --------------------------------\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TriggerCaseBaseName_to_CohortNameList = {\n",
    "    TriggerCaseBaseName: CohortName_list,\n",
    "}\n",
    "\n",
    "TriggerCaseBaseName_to_CohortNameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13727fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TriggerCaseBaseName_to_TriggerCaseBaseArgs[TriggerCaseBaseName] = TriggerCaseBaseArgs\n",
    "pprint(TriggerCaseBaseArgs, sort_dicts=False)\n",
    "\n",
    "TriggerCaseBaseName_to_CohortNameList = {\n",
    "    TriggerCaseBaseName: CohortName_list,\n",
    "}\n",
    "\n",
    "# 2min 1 cpu\n",
    "# 1m40s 8 cpus\n",
    "case_base = Case_Base(\n",
    "    record_base = record_base, \n",
    "    TriggerCaseBaseName_to_CohortNameList = TriggerCaseBaseName_to_CohortNameList, \n",
    "    TriggerCaseBaseName_to_TriggerCaseBaseArgs = TriggerCaseBaseName_to_TriggerCaseBaseArgs,\n",
    "    Case_Proc_Config = Case_Proc_Config,\n",
    "    Case_Args_Settings = Case_Args_Settings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CaseSetNameToCaseset = case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset['Bf24HAf2H_CGM']\n",
    "CaseSetNameToCaseset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449406f9",
   "metadata": {},
   "source": [
    "## Step 2: AIData Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcc83b",
   "metadata": {},
   "source": [
    "### Input Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9842a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_aidata.ConfigInput import InputName_to_Settings\n",
    "\n",
    "## %%%%%%%%%%%%%%%%%%%%%%%% user generation \n",
    "# ------------------------ Input Args ------------------------\n",
    "inputcf_name = 'before_after_26h_CGM'\n",
    "INPUT_CFs_Args = {\n",
    "    inputcf_name: {\n",
    "        'InputCFs': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "\n",
    "InputName_to_Settings['INPUT_CFs_Args'] = INPUT_CFs_Args\n",
    "\n",
    "EntryInputMethod = 'Mto1Period_1TknInStep'\n",
    "Input_Args = {\n",
    "    'TriggerName': 'CGM5MinEntry',\n",
    "    'INPUT_CFs_Args': inputcf_name,\n",
    "    'EntryInputMethod': EntryInputMethod,\n",
    "    # we might add the Filtering for Input Data as well. \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386147b",
   "metadata": {},
   "source": [
    "### Task Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_aidata.ConfigTasks import TasksName_to_Settings\n",
    "\n",
    "\n",
    "# ------------------------ Task Args ------------------------\n",
    "TaskType          = 'NextOneTknPred'\n",
    "TaskSeriesName    = 'NextOneTknPred'\n",
    "TaskName          = 'NextOneTknPred'\n",
    "\n",
    "EntryOutputMethod = 'NextOneTknPred'\n",
    "\n",
    "Tasks_Args = {\n",
    "    'TaskType':          TaskType, # task type \n",
    "    'TaskSeriesName':    TaskSeriesName, # 'SurveyPred',\n",
    "    'TaskName':          TaskName,\n",
    "    'EntryOutputMethod': EntryOutputMethod,\n",
    "    # 'Filtering': [], \n",
    "}\n",
    "TasksName_to_Settings[TaskSeriesName] = {}\n",
    "TasksName_to_Settings[TaskSeriesName][TaskName] = Tasks_Args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1888d",
   "metadata": {},
   "source": [
    "### AIDev Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_aidata.ConfigAIDev import AIDevName_to_Settings\n",
    "\n",
    "# SplitTagging \n",
    "pprint(AIDevName_to_Settings, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "SplitTagging_Args = AIDevName_to_Settings['SplitTagging']\n",
    "\n",
    "# -----------------------\n",
    "SplitTaggingName = 'Rs32out1Tail1Valid1'\n",
    "SplitTagging_Args[SplitTaggingName] = {\n",
    "    'RANDOM_SEED': 32,\n",
    "    'out_ratio': 0.1,\n",
    "    'test_ratio': 'tail0.1',\n",
    "    'valid_ratio': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708361e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "TrainEvals_Args = AIDevName_to_Settings['TrainEvals']\n",
    "TrainEvalName = 'Train-EvaOutTestValidatio'\n",
    "\n",
    "TrainEvals_Args[TrainEvalName] = {\n",
    "    'TrainSetName': 'In-Train', \n",
    "    'EvalSetNames': ['In-Test', 'In-Valid', 'Out']\n",
    "}\n",
    "\n",
    "AIDevName_to_Settings['SplitTagging'] = SplitTagging_Args\n",
    "AIDevName_to_Settings['TrainEvals']   = TrainEvals_Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0399ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIDev_Args = {\n",
    "    'NewName_to_OldNames': 'BaseAll',  # 'BaseC1', \n",
    "    'SplitTagging': SplitTaggingName,\n",
    "    'TrainEvals': TrainEvalName, \n",
    "    'Filtering': 'FltNone', # 'FltBaseSMS', #  # \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f05c1",
   "metadata": {},
   "source": [
    "### AIData_Job_Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed97323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------- # \n",
    "# this one should be put in the training script.\n",
    "AIData_Job_Args = {\n",
    "    'TriggerCaseBaseName': TriggerCaseBaseName,\n",
    "    'CohortName_list': CohortName_list,\n",
    "\n",
    "    'AIDev_Args': AIDev_Args,\n",
    "\n",
    "    'Input_Args': Input_Args,\n",
    "\n",
    "    ###################################\n",
    "    'Tasks_Series_Args': {\n",
    "        'TaskType': 'NextOneTknPred',                     \n",
    "        'EntryOutputMethod': EntryOutputMethod, \n",
    "        'TaskSeriesName_List': [\n",
    "            'NextOneTknPred',\n",
    "        ],\n",
    "    },\n",
    "    ###################################\n",
    "}\n",
    "\n",
    "\n",
    "from config.config_aidata.ConfigTasks import TaskType_to_EntryOutputMethod\n",
    "from recfldtkn.aidata_base.aidata import convert_AIDataSeriesArgs_to_TaskFullNameToAIDataArgs\n",
    "\n",
    "TaskFullName_to_AIDataArgs = convert_AIDataSeriesArgs_to_TaskFullNameToAIDataArgs(AIData_Job_Args, \n",
    "                                                                                  TasksName_to_Settings)\n",
    "\n",
    "pprint(TaskFullName_to_AIDataArgs, sort_dicts=False)\n",
    "# AIDataArgs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb855a8f",
   "metadata": {},
   "source": [
    "## Step 3: AIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77765ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_aidata.ConfigInput import InputName_to_Settings\n",
    "from config.config_aidata.ConfigTasks import TasksName_to_Settings\n",
    "from config.config_aidata.ConfigAIDev import AIDevName_to_Settings\n",
    "from recfldtkn.aidata_base.aidata_base import AIData_Base\n",
    "\n",
    "\n",
    "AIDataSettings = {\n",
    "    'InputName_to_Settings': InputName_to_Settings,\n",
    "    'TasksName_to_Settings': TasksName_to_Settings,\n",
    "    'AIDevName_to_Settings': AIDevName_to_Settings,\n",
    "}\n",
    "\n",
    "############## inference mode ####################\n",
    "# AIDataArgs_columns = ['TriggerCaseBaseName', 'Input_Args']\n",
    "# CohortName_list = ['Inference']\n",
    "\n",
    "############## training mode ####################\n",
    "AIDataArgs_columns = None\n",
    "CohortName_list = None\n",
    "\n",
    "aidata_base = AIData_Base(\n",
    "    case_base = case_base, \n",
    "    TaskFullName_to_AIDataArgs = TaskFullName_to_AIDataArgs,\n",
    "    AIDataArgs_columns = AIDataArgs_columns,\n",
    "    CohortName_list = CohortName_list, \n",
    "    AIDataSettings = AIDataSettings, \n",
    "    SPACE = SPACE, \n",
    ")   \n",
    "\n",
    "pprint(aidata_base.TaskFullName_to_AIDataArgsFinal, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee91de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskFullName_list = [i for i in aidata_base.TaskFullName_to_AIDataArgsFinal]\n",
    "pprint(TaskFullName_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "taskfullname = TaskFullName_list[0]\n",
    "taskfullname "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneAIData_Args = aidata_base.TaskFullName_to_AIDataArgsFinal[taskfullname]\n",
    "pprint(OneAIData_Args, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166439ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata = aidata_base.get_aidata_from_taskfullname(taskfullname)\n",
    "aidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskFullName_list = [i for i in aidata_base.TaskFullName_to_AIDataArgsFinal]\n",
    "pprint(TaskFullName_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name_to_Data = aidata.Name_to_Data\n",
    "for Name, Data in Name_to_Data.items():\n",
    "    print(Name, ':', Data['ds_case'])\n",
    "\n",
    "\n",
    "# hold-out\n",
    "# hold-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d4ce3",
   "metadata": {},
   "source": [
    "## Step 4: Prepare A Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80463b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidata.Name_to_DsAIData\n",
    "\n",
    "split = 'In-Train'\n",
    "dataset = aidata.Name_to_Data[split]\n",
    "dataset['df_case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aecb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_case = aidata.Name_to_Data['In-Train']['ds_case']\n",
    "ds_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "batch = ds_case[:batch_size]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batch['input_ids']\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1423e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522216e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids[2, :] # 313 = 288 (24h) +  1 (obspoint) + 24 (2h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7738243",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch['labels']\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d202eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6016ed6c",
   "metadata": {},
   "source": [
    "# Part 2: Model Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b93d760",
   "metadata": {},
   "source": [
    "## Step 1: `__init__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b320e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArgs = {\n",
    "    'model_name_or_path': \"cgmgpt_medal\",\n",
    "    'task': None,\n",
    "    'config_name': None,\n",
    "    'algorithm_name': None,\n",
    "    'model_type': 'cgmgpt_medal',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79eba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingArgs = {\n",
    "    'output_dir': '_test', \n",
    "    'overwrite_output_dir': False,\n",
    "    \n",
    "    'do_train': True, \n",
    "    'num_train_epochs': 10,\n",
    "    'per_device_train_batch_size': 4, # 64, # 4, # 64\n",
    "    'per_device_eval_batch_size': 4, # 64, # 4, # 64\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'save_strategy': 'epoch',\n",
    "    'save_total_limit': 10, \n",
    "    \n",
    "    'logging_steps': 1,\n",
    "    \n",
    "    'do_eval': True, \n",
    "    'eval_steps': 100, \n",
    "    'evaluation_strategy': 'steps',\n",
    "    \n",
    "    'report_to': 'wandb',\n",
    "    'remove_unused_columns': False, # <--- must be False.\n",
    "    'dataloader_drop_last': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InferenceArgs = {\n",
    "#     # save_df: means save the dataframe to the disk.\n",
    "#     'save_df': False, \n",
    "\n",
    "#     # get_df: means get the dataframe from the disk.\n",
    "#     'get_df': True,\n",
    "\n",
    "#     # task: means the task name, which is used to save the dataframe.\n",
    "#     'task': 'ntp',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9271f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "InferenceArgs = {\n",
    "    'save_df': False, \n",
    "    'get_df': True, \n",
    "    'task': 'gen',\n",
    "    'GenArgs': {\n",
    "        'max_new_tokens': 24,\n",
    "        'do_sample': False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7851e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluationArgs = {\n",
    "    'max_inference_num': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb118384",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1774485f",
   "metadata": {},
   "source": [
    "## Step 2: init_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043bf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import logging\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_FOR_CAUSAL_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_CAUSAL_LM_MAPPING.keys())\n",
    "# MODEL_CONFIG_CLASSES\n",
    "\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "# MODEL_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4713b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# this is the NN development that showing our novelty #############\n",
    "from nn.cgmlsm.configuration_cgmgpt import CgmGptConfig\n",
    "from nn.cgmlsm.instance_cgmgpt import CgmGptInstance\n",
    "from nn.cgmlsm.modeling_cgmgpt import CgmGptLMHeadModel\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- within the method of init_model.\n",
    "CF_to_CFvocab = aidata.CF_to_CFvocab\n",
    "CF = list(CF_to_CFvocab.keys())[0]\n",
    "CFvocab = CF_to_CFvocab[CF]\n",
    "tkn2tid = CFvocab['input_ids']['tkn2tid']\n",
    "\n",
    "config_kwargs = {\n",
    "    # \"cache_dir\": model_args.cache_dir,\n",
    "    # \"revision\": model_args.model_revision,\n",
    "    # \"token\": model_args.token,\n",
    "    # \"trust_remote_code\": model_args.trust_remote_code,\n",
    "    ###########\n",
    "    'vocab_size': len(tkn2tid),\n",
    "    'bos_token_id': tkn2tid['[BOS]'],\n",
    "    'eos_token_id': tkn2tid['[EOS]'],\n",
    "    'pad_token_id':  0,\n",
    "    ###########\n",
    "}\n",
    "\n",
    "ModelArgs.update(config_kwargs)\n",
    "\n",
    "pprint(ModelArgs)\n",
    "config = CgmGptConfig(**ModelArgs)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CgmGptLMHeadModel(config) \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f385025",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = CgmGptInstance(aidata, ModelArgs, TrainingArgs, InferenceArgs, EvaluationArgs, SPACE= SPACE)\n",
    "model_instance.init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc9868",
   "metadata": {},
   "source": [
    "## Step 3: One Single Batch\n",
    "\n",
    "\n",
    "1. Training ---> Loss\n",
    "2. Inference ---> Evaluation NTP or Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd2a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "batch2dp = 8\n",
    "batch = ds_case.select(range(batch2dp))[:batch2dp]\n",
    "inputs = batch\n",
    "\n",
    "input_batch = {'input_ids': torch.LongTensor(inputs['input_ids'])}\n",
    "for k, v in input_batch.items():\n",
    "    print(k, v.shape)   \n",
    "\n",
    "inputs=batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede39ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_outputs = model.transformer(**input_batch)\n",
    "\n",
    "transformer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc607ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = transformer_outputs[0]\n",
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_logits = model.lm_head(hidden_states)\n",
    "lm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**batch)\n",
    "output.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9261998",
   "metadata": {},
   "source": [
    "## Step 4: fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e725d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ce1cd",
   "metadata": {},
   "source": [
    "## Step 5: inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10880fa3",
   "metadata": {},
   "source": [
    "### process_a_single_batch_for_ntp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d770bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in batch.items():\n",
    "    batch[k] = v.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae13352",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19335c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted_labels\n",
    "lm_logits = output.logits\n",
    "predicted_labels = torch.argmax(lm_logits, dim=-1)\n",
    "\n",
    "# get the loss each token\n",
    "labels = batch['labels']\n",
    "shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "logits_permuted = shift_logits.permute(0, 2, 1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "losses = loss_fn(logits_permuted, shift_labels)\n",
    "\n",
    "# organize the output \n",
    "output = {\n",
    "    # 'loss': loss,\n",
    "    'losses_each_seq': losses.mean(dim=1),\n",
    "    'losses_each_seqbf24': losses[:, :288].mean(dim=1),\n",
    "    'losses_each_seqaf2h': losses[:, 288:].mean(dim=1),\n",
    "    'losses_each_token': losses,\n",
    "    'predicted_labels': predicted_labels,\n",
    "}\n",
    "\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_a_single_batch_for_ntp(model, batch, InferenceArgs = None):\n",
    "\n",
    "    # model should be activate with the model.eval() within the inference. \n",
    "    output = model(**batch)\n",
    "    \n",
    "    # get predicted_labels\n",
    "    lm_logits = output.logits\n",
    "    predicted_labels = torch.argmax(lm_logits, dim=-1)\n",
    "\n",
    "    # get the loss each token\n",
    "    labels = batch['labels']\n",
    "    shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "    shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "    logits_permuted = shift_logits.permute(0, 2, 1)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    losses = loss_fn(logits_permuted, shift_labels)\n",
    "\n",
    "    # organize the output \n",
    "    output = {\n",
    "        # 'loss': loss,\n",
    "        'losses_each_seq': losses.mean(dim=1),\n",
    "        'losses_each_seqbf24': losses[:, :288].mean(dim=1),\n",
    "        'losses_each_seqaf2h': losses[:, 288:].mean(dim=1),\n",
    "        'losses_each_token': losses,\n",
    "        'predicted_labels': predicted_labels,\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ef1cc",
   "metadata": {},
   "source": [
    "### process_a_single_batch_for_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "InferenceArgs = {\n",
    "    'save_df': False, \n",
    "    'get_df': True, \n",
    "    'task': 'gen',\n",
    "    'GenArgs': {\n",
    "        'max_new_tokens': 12,\n",
    "        'do_sample': False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80bb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "\n",
    "GenArgs = InferenceArgs['GenArgs']\n",
    "GenArgs['pad_token_id'] = model.config.pad_token_id\n",
    "GenArgs\n",
    "\n",
    "generation_config = GenerationConfig(**GenArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = GenArgs['max_new_tokens']\n",
    "max_input_tokens = len(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e937f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(generation_config = generation_config, **batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d008d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_a_single_batch_for_gen(model, batch, InferenceArgs = None):\n",
    "\n",
    "    # ---------\n",
    "    # to add things here. \n",
    "\n",
    "    GenArgs = InferenceArgs['GenArgs']\n",
    "    GenArgs['pad_token_id'] = model.config.pad_token_id\n",
    "    # GenArgs\n",
    "\n",
    "    generation_config = GenerationConfig(**GenArgs)\n",
    "\n",
    "\n",
    "    max_new_tokens = GenArgs['max_new_tokens']\n",
    "    max_input_tokens = len(batch['input_ids'])\n",
    "\n",
    "    outputs = model.generate(generation_config = generation_config, **batch)\n",
    "\n",
    "    # ---------\n",
    "    output = {\n",
    "        f\"hist_{max_input_tokens}\": batch['input_ids'],\n",
    "        f\"real_{max_new_tokens}\": batch['labels'],\n",
    "        f\"pred_{max_new_tokens}\": outputs.cpu().numpy()[:, -max_new_tokens:], \n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = process_a_single_batch_for_gen(model, batch, InferenceArgs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa59a7",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe605ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = aidata.Name_to_Data['In-Train']\n",
    "dataset = Data['ds_case']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82463ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPACE\n",
    "\n",
    "max_inference_num = 1000\n",
    "dataset = dataset.select(range(max_inference_num))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a189a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_instance.inference(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e35c9e",
   "metadata": {},
   "source": [
    "## Step 6: evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a334f3",
   "metadata": {},
   "source": [
    "### One df_case_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "self= model_instance\n",
    "\n",
    "aidata = self.aidata    \n",
    "EvaluationArgs = self.EvaluationArgs\n",
    "model_instance = self\n",
    "eval_instance = self.eval_instance\n",
    "\n",
    "df_case_list = []\n",
    "for SetName in aidata.TrainEvals['EvalSetNames']:\n",
    "    if SetName=='Out':\n",
    "        break\n",
    "    logger.info(f'Evaluate on {SetName}...')\n",
    "    Data     = aidata.Name_to_Data[SetName] # Data['df_case'] (meta), Data['ds_case'] (CF). \n",
    "    DsAIData = aidata.Name_to_DsAIData[SetName]  # dataset (into the model)\n",
    "    dataset = DsAIData['ds_case']   \n",
    "    max_inference_num= self.EvaluationArgs['max_inference_num']\n",
    "    dataset = dataset.select(range(max_inference_num))\n",
    "    df_case = model_instance.inference(dataset)\n",
    "    df_case_list.append(df_case)\n",
    "\n",
    "df_case_eval = pd.concat(df_case_list, axis = 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6746fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef21c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 24\n",
    "gen_id_col = f'pred_{max_new_tokens}'\n",
    "real_id_col = f'real_{max_new_tokens}'\n",
    "input_id_col = 'hist_313'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1faf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_case_eval['var'] = df_case_eval[input_id_col].apply(lambda x: np.var(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = df_case_eval[gen_id_col]\n",
    "real = df_case_eval[real_id_col]\n",
    "\n",
    "print(gen)\n",
    "print(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_to_se = {\n",
    "    '30Min': (0, 6),\n",
    "    '1stH ': (0, 12),\n",
    "    '2ndH ': (12, 24), \n",
    "    '2H   ': (0, 24)\n",
    "}\n",
    "\n",
    "case_columns_id = ['PID', 'ObsDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = df_case_eval.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624225ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.eval_instance.plot_cgm_sensor(example, gen_id_col, real_id_col, input_id_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals= self.eval_instance.get_complete_metrics(example, gen_id_col,real_id_col,horizon_to_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca83eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evals.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50755a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in evals.items():\n",
    "    print(k,\":\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_columns_id = ['PID', 'ObsDT']\n",
    "report = pd.concat([pd.DataFrame([example[case_columns_id]]), pd.DataFrame([evals])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a05a0",
   "metadata": {},
   "source": [
    "### Looping over all df_case_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_report= model_instance.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befdbaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['rMSE_30Min', 'rMSE_1stH ', 'rMSE_2ndH ', 'rMSE_2H   ',]\n",
    "\n",
    "df_full_report[columns].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}