{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: AIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oneday: 288, 24pd. 1/12\n",
    "from datasets import load_from_disk\n",
    "\n",
    "AIDataName = 'EventFood2CGM_bf5min_WellDoc_v2' # v2 6 cohorts. \n",
    "path = os.path.join(SPACE['DATA_AIDATA'], AIDataName)\n",
    "print(path)\n",
    "dataset = load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dataset.info.__dict__['config_name']# .features['cf'].feature.vocab\n",
    "print([i for i in config])\n",
    "CF_to_CFvocab = config['CF_to_CFvocab']\n",
    "pprint([i for i in CF_to_CFvocab], sort_dicts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = {\n",
    "    'ds_case': dataset,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: EntryFn - Input_Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "\n",
    "            # 'cf.TimeSparse_Bf24H', \n",
    "            # 'cf.TimeSparse_Af2H',\n",
    "\n",
    "            'cf.Diet5MinBaseLMH_Bf24H',\n",
    "            'cf.Diet5MinBaseLMH_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        # 'TimeField':   'Time',\n",
    "        'EventFields': [\n",
    "            # 'Activity',\n",
    "            'Diet5MinBaseLMH',\n",
    "        ],\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "}\n",
    "\n",
    "EntryInputMethod = OneEntryArgs['Input_Part']['EntryInputMethod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InputCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import datasets\n",
    "import inspect\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import itertools\n",
    "\n",
    "## %%%%%%%%%%%%%%%%%%%%% user functions\n",
    "def get_INPUT_CFs(OneEntryArgs):\n",
    "    Input_Part = OneEntryArgs['Input_Part']\n",
    "    CF_list = Input_Part['CF_list']\n",
    "    ############################ # INPUT_CFs\n",
    "    assert type(CF_list) == list, f'InputCFs must be a list, but got {type(CF_list)}'\n",
    "    # INPUT_CFs = sorted(InputCFs_Args)\n",
    "    INPUT_CFs = CF_list\n",
    "\n",
    "    InferenceMode = Input_Part['InferenceMode'] \n",
    "    BeforePeriods = Input_Part['BeforePeriods']\n",
    "    TargetField = Input_Part['TargetField']\n",
    "    if InferenceMode == 'NoFutureEvent':\n",
    "        INPUT_CFs = [i for i in INPUT_CFs if any([j in i for j in BeforePeriods])]\n",
    "    elif InferenceMode == 'WithFutureEvent':\n",
    "        INPUT_CFs = [i for i in INPUT_CFs if any([j in i for j in BeforePeriods]) or TargetField not in i]\n",
    "\n",
    "    ############################\n",
    "    return INPUT_CFs\n",
    "\n",
    "get_INPUT_CFs.fn_string = inspect.getsource(get_INPUT_CFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EntryInputMethod = OneEntryArgs['Input_Part']['EntryInputMethod']\n",
    "InputCFs = get_INPUT_CFs(OneEntryArgs)\n",
    "InputCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_case = Data['ds_case']\n",
    "ds_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field_to_CFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input_Part = OneEntryArgs['Input_Part']\n",
    "# TargetField = Input_Part['TargetField']\n",
    "# TimeField = Input_Part['TimeField']\n",
    "# EventFields = Input_Part['EventFields']\n",
    "\n",
    "# FieldList = [TargetField, TimeField] + EventFields\n",
    "# Field_to_CFs = {\n",
    "#     field: [i for i in InputCFs if field in i] for field in FieldList\n",
    "# }\n",
    "\n",
    "# Field_to_CFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CF_to_CFvocab['cf.DietSparse_Bf24H']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ds_case.shuffle(seed=42)[:64] # .select(range(5))  \n",
    "# examples = ds_case[:4] \n",
    "pprint(examples, sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Part = OneEntryArgs['Input_Part']\n",
    "Input_Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputCFs = Input_Part['CF_list']\n",
    "InputCFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TargetCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetField = Input_Part['TargetField']\n",
    "TargetField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetCFs = [i for i in InputCFs if TargetField in i]\n",
    "TargetCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "\n",
    "s = datetime.now()\n",
    "examples_tfm = {}\n",
    "\n",
    "############################################################\n",
    "# # 0:00:00.002059\n",
    "## method 1:\n",
    "# df = pd.DataFrame({cf: examples[cf + '--input_ids'] for cf in TargetCFs})\n",
    "# df['input_ids'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "# examples_tfm['input_ids'] = torch.LongTensor(np.array(df['input_ids'].to_list())) # ().copy()\n",
    "\n",
    "\n",
    "############################################################\n",
    "# # 0:00:00.000868\n",
    "# method 2: \n",
    "# Step 1: Directly access columns as numpy arrays\n",
    "target_arrays = [np.array(examples[f\"{cf}--input_ids\"]) for cf in TargetCFs]\n",
    "# Step 2: Concatenate along columns (axis=1) to combine features\n",
    "# Assuming each array has shape (batch_size, seq_len)\n",
    "stacked_ids = np.concatenate(target_arrays, axis=1)\n",
    "examples_tfm['input_ids'] = torch.LongTensor(stacked_ids)\n",
    "# examples_tfm['input_ids'] = stacked_ids # torch.LongTensor()\n",
    "\n",
    "\n",
    "e = datetime.now()\n",
    "print(f'TargetCFs: {e-s}')\n",
    "print(examples_tfm['input_ids'].shape)\n",
    "examples_tfm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the Emptiness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_empty_values(values):\n",
    "    if len(values) == 1 and len(values[0]) == 1 and int(values[0][0]) == 0:\n",
    "        EmptyFlag = True\n",
    "    else:\n",
    "        EmptyFlag = False\n",
    "    return EmptyFlag\n",
    "detect_empty_values.fn_string = inspect.getsource(detect_empty_values)\n",
    "\n",
    "\n",
    "def update_emptiness_of_examples(examples, CF):\n",
    "    # make sure your CF is an EventCF, which means your have steps. \n",
    "    batch_to_values = examples[CF + '--input_ids']\n",
    "    batch_to_empty = [detect_empty_values(values) for values in batch_to_values]\n",
    "    examples_updated = {}\n",
    "    for items in ['input_ids', 'input_wgts', 'timestep']:\n",
    "        if f'{CF}--{items}' not in examples: continue \n",
    "        batch_to_values = examples[CF + '--' + items]\n",
    "        batch_to_values_updated = []\n",
    "        empty_value = []\n",
    "        for dp_idx, empty in enumerate(batch_to_empty):\n",
    "            if empty:\n",
    "                batch_to_values_updated.append(empty_value)\n",
    "            else:\n",
    "                batch_to_values_updated.append(batch_to_values[dp_idx])\n",
    "        examples_updated[CF + '--' + items] = batch_to_values_updated\n",
    "    return examples_updated\n",
    "update_emptiness_of_examples.fn_string = inspect.getsource(update_emptiness_of_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples['cf.ActivitySparse_Af2H--input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples_tfm = {}\n",
    "# examples_tfm['input_ids'] = torch.LongTensor(np.array(df['input_ids'].to_list())) # ().copy()\n",
    "# examples_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeField = Input_Part['TimeField']\n",
    "# TimeField\n",
    "\n",
    "# TimeCFs = [i for i in InputCFs if TimeField in i]\n",
    "# TimeCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EventCFs = [i for i in InputCFs if TargetField not in i and TimeField not in i]\n",
    "# EventCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EventFields = Input_Part['EventFields']\n",
    "EventFields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = datetime.now()\n",
    "\n",
    "# for EventCF in EventCFs:\n",
    "#     examples_updated = update_emptiness_of_examples(examples, EventCF)\n",
    "#     for k, v in examples_updated.items():\n",
    "#         examples[k] = v\n",
    "\n",
    "# e = datetime.now()\n",
    "# print(f'update_emptiness_of_examples for EventCFs: {e-s}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEvent = EventFields[0]\n",
    "\n",
    "OneEventCFs = [i for i in InputCFs if OneEvent in i]\n",
    "\n",
    "print(OneEventCFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'input_ids'\n",
    "\n",
    "# method 1\n",
    "s = datetime.now()\n",
    "df = pd.DataFrame({cf: examples[cf + f'--{seqtype}'] for cf in OneEventCFs})\n",
    "df[seqtype] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "values = df[seqtype].to_list()\n",
    "e = datetime.now()\n",
    "print(f'{seqtype}: {e-s}')\n",
    "df1 = df\n",
    "\n",
    "\n",
    "# method 2\n",
    "s = datetime.now()\n",
    "columns_data = [examples[f\"{cf}--{seqtype}\"] for cf in OneEventCFs]\n",
    "values = []\n",
    "for sample_items in zip(*columns_data):\n",
    "    combined = list(itertools.chain(*sample_items))\n",
    "    values.append(combined)\n",
    "e = datetime.now()\n",
    "print(f'{seqtype}: {e-s}')\n",
    "df = pd.DataFrame({cf: examples[cf + f'--{seqtype}'] for cf in OneEventCFs})\n",
    "df[seqtype] = values\n",
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "# 0, -239. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqtype = 'input_wgts'\n",
    "\n",
    "# # method 1\n",
    "# s = datetime.now()\n",
    "# df = pd.DataFrame({cf: examples[cf + f'--{seqtype}'] for cf in OneEventCFs})\n",
    "# df[seqtype] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "# values = df[seqtype].to_list()\n",
    "# e = datetime.now()\n",
    "# print(f'{seqtype}: {e-s}')\n",
    "# df1 = df\n",
    "\n",
    "\n",
    "# # method 2\n",
    "# s = datetime.now()\n",
    "# columns_data = [examples[f\"{cf}--{seqtype}\"] for cf in OneEventCFs]\n",
    "# values = []\n",
    "# for sample_items in zip(*columns_data):\n",
    "#     combined = list(itertools.chain(*sample_items))\n",
    "#     values.append(combined)\n",
    "# e = datetime.now()\n",
    "# print(f'{seqtype}: {e-s}')\n",
    "# df = pd.DataFrame({cf: examples[cf + f'--{seqtype}'] for cf in OneEventCFs})\n",
    "# df[seqtype] = values\n",
    "# df2 = df\n",
    "\n",
    "# # df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'timestep'\n",
    "\n",
    "# method 1\n",
    "s = datetime.now()\n",
    "df = pd.DataFrame({cf: examples[cf + f'--{seqtype}'] for cf in OneEventCFs})\n",
    "df[seqtype] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "values = df[seqtype].to_list()\n",
    "e = datetime.now()\n",
    "print(f'{seqtype}: {e-s}')\n",
    "df1 = df\n",
    "\n",
    "\n",
    "# method 2\n",
    "s = datetime.now()\n",
    "columns_data = [examples[f\"{cf}--{seqtype}\"] for cf in OneEventCFs]\n",
    "values = []\n",
    "for sample_items in zip(*columns_data):\n",
    "    combined = list(itertools.chain(*sample_items))\n",
    "    values.append(combined)\n",
    "e = datetime.now()\n",
    "print(f'{seqtype}: {e-s}')\n",
    "df = pd.DataFrame({cf: examples[cf + f'--{seqtype}'] for cf in OneEventCFs})\n",
    "df[seqtype] = values\n",
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [i for i in examples]\n",
    "# df = pd.DataFrame({cf: examples[cf + '--input_wgts'] for cf in OneEventCFs})\n",
    "# df['input_wgts'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "\n",
    "example_event_info = {}\n",
    "\n",
    "for seqtype in ['input_ids', 'input_wgts', 'timestep']:\n",
    "    df = pd.DataFrame({cf: examples[cf + '--' + seqtype] for cf in OneEventCFs})\n",
    "    df[seqtype] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "    example_event_info[seqtype] = df[seqtype].to_list()\n",
    "\n",
    "# pprint(example_event_info, sort_dicts=False, compact=True)\n",
    "e = datetime.now()\n",
    "print(f'method 1: example_event_info: {e-s}')\n",
    "\n",
    "\n",
    "\n",
    "s = datetime.now()\n",
    "example_event_info = {}\n",
    "\n",
    "\n",
    "max_features = 0\n",
    "batch_size = 0\n",
    "for seqtype in ['input_ids', 'input_wgts', 'timestep']:\n",
    "    columns_data = [examples[f\"{cf}--{seqtype}\"] for cf in OneEventCFs]\n",
    "    batch_size = len(columns_data[0])\n",
    "    values = []\n",
    "    for sample_items in zip(*columns_data):\n",
    "        combined = list(itertools.chain(*sample_items))\n",
    "\n",
    "        # print(combined)\n",
    "        if seqtype == 'input_ids': \n",
    "            if len(combined) == 0:  \n",
    "                current_max_length = 0\n",
    "            else:\n",
    "                current_max_length = max(len(i) for i in combined)\n",
    "\n",
    "            max_features = max(max_features, current_max_length)\n",
    "        values.append(combined)\n",
    "    example_event_info[seqtype] = values\n",
    "# pprint(example_event_info, sort_dicts=False, compact=True)\n",
    "e = datetime.now()\n",
    "print(f'method 2: example_event_info: {e-s}')\n",
    "\n",
    "print(batch_size, max_features)\n",
    "\n",
    "if max_features == 0: \n",
    "    print('max_features is 0, which means in the batch, no data points contains this event. so we will skip it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 678\n",
    "# tkn = [Group-670, Level-670~680]\n",
    "# wgt = [1,         0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch = pd.DataFrame(example_event_info)\n",
    "df_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timestep info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEventCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFvocab = CF_to_CFvocab[OneEventCFs[0]]\n",
    "# CFvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_info(examples, OneEventCFs):\n",
    "    total_index_list = []\n",
    "    total_orig_ids = []\n",
    "    total_timedelta_info = []\n",
    "\n",
    "    for cf in OneEventCFs:\n",
    "        # Get time metadata in one lookup\n",
    "        timeinfo = examples[f\"{cf}--timeinfo\"][0]\n",
    "        timevalues = examples[f\"{cf}--timevalues\"][0]\n",
    "        metadata = dict(zip(timeinfo, timevalues))\n",
    "        \n",
    "        # Extract constant values once per CF\n",
    "        time_unit = metadata['TimeUnit']\n",
    "        time_step = metadata['TimeStepSize']\n",
    "        step_type = metadata['TimeStepType']\n",
    "        \n",
    "        # Process all index ranges\n",
    "        for key in (k for k in metadata if 'StartIdx-To-EndIdx' in k):\n",
    "            start, end = map(int, metadata[key].split(':To:'))\n",
    "            n = end - start + 1\n",
    "            \n",
    "            # Batch generate all entries for this range\n",
    "            total_index_list.extend(f\"{step_type}_{i}\" for i in range(start, end+1))\n",
    "            total_orig_ids.extend(range(start, end+1))\n",
    "            total_timedelta_info.extend([(time_step, time_unit)] * n)\n",
    "\n",
    "\n",
    "    index_map = {ts_id: idx for idx, ts_id in enumerate(total_orig_ids)}\n",
    "    \n",
    "    timestep_info = {\n",
    "        'timesteps': total_index_list,\n",
    "        'timestep_orig_ids': total_orig_ids,\n",
    "        'index_map': index_map,\n",
    "        'total_timedelta_info': total_timedelta_info\n",
    "    }\n",
    "    return timestep_info\n",
    "\n",
    "get_timestep_info.fn_string = inspect.getsource(get_timestep_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_info_old(examples, OneEventCFs): \n",
    "\n",
    "    # do not delete this. \n",
    "\n",
    "    total_index_list = []\n",
    "    total_timedelta_info = []\n",
    "\n",
    "    TimeUnit = None\n",
    "    TimeStep = None\n",
    "\n",
    "    for cf in OneEventCFs:\n",
    "        timeinfo_col   = f'{cf}--timeinfo'\n",
    "        timevalues_col = f'{cf}--timevalues'\n",
    "        d = dict(zip(examples[timeinfo_col][0], examples[timevalues_col][0]))\n",
    "        TimeUnit = d['TimeUnit'] \n",
    "        TimeStep = d['TimeStepSize']\n",
    "            \n",
    "        TimeStepType = d['TimeStepType']\n",
    "        StartIdx_To_EndIdx_columns = [i for i in d if 'StartIdx-To-EndIdx' in i]\n",
    "        \n",
    "        for StartIdx_To_EndIdx_col in StartIdx_To_EndIdx_columns:\n",
    "            start_to_end = d[StartIdx_To_EndIdx_col].split(':To:')\n",
    "            StartIdx = int(start_to_end[0])\n",
    "            EndIdx   = int(start_to_end[1])\n",
    "            index_list = [f'{TimeStepType}_{i}' for i in list(range(StartIdx, EndIdx + 1))]\n",
    "            timedelta_info = [(TimeStep, TimeUnit)] * len(index_list)\n",
    "            total_index_list = total_index_list + index_list\n",
    "            total_timedelta_info = total_timedelta_info + timedelta_info\n",
    "\n",
    "    timesteps = total_index_list\n",
    "    # timestep_ids = [FieldVocab['timestep_ids']['tkn2tid'][i] for i in total_index_list]\n",
    "    timestep_ids = total_index_list\n",
    "    timestep_orig_ids = [int(i.split('_')[-1]) for i in timesteps]\n",
    "\n",
    "    timestep_info = {\n",
    "        'timesteps': timesteps,\n",
    "        # 'timestep_ids': timestep_ids, \n",
    "        'timestep_orig_ids': timestep_orig_ids, \n",
    "        'total_timedelta_info': total_timedelta_info,\n",
    "    }\n",
    "    # timestep_info\n",
    "    return timestep_info\n",
    "\n",
    "get_timestep_info_old.fn_string = inspect.getsource(get_timestep_info_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "timestep_info_old = get_timestep_info_old(examples, OneEventCFs)\n",
    "e = datetime.now()\n",
    "print(f'get_timestep_info_old: {e-s}')\n",
    "# timestep_info\n",
    "\n",
    "\n",
    "s = datetime.now()\n",
    "timestep_info = get_timestep_info(examples, OneEventCFs)\n",
    "e = datetime.now()\n",
    "print(f'get_timestep_info_new: {e-s}')\n",
    "# timestep_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(timestep_info, sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(timestep_info, sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in examples]\n",
    "timestep_orig_ids = timestep_info['timestep_orig_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Array Filling with Sparse Events Crowd Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(timestep_info['timestep_orig_ids'], sort_dicts=False, compact=True)\n",
    "\n",
    "max_timesteps = len(timestep_info['timestep_orig_ids'])\n",
    "print(batch_size, max_timesteps, max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [i for i in example_event_info]\n",
    "for items_sample in zip(*example_event_info.values()):\n",
    "    print(items_sample)\n",
    "    single_data_point = dict(zip(names, items_sample))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_data_point['timestep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old method that takes too much time. \n",
    "\n",
    "timestep_orig_ids = timestep_info['timestep_orig_ids']\n",
    "index_map = timestep_info['index_map']\n",
    "timestep = single_data_point['timestep']\n",
    "ts_indices = [index_map[ts_id] for ts_id in timestep]\n",
    "print(timestep)\n",
    "print(ts_indices)\n",
    "\n",
    "template_len = len(timestep_orig_ids)\n",
    "UNK_ID = 1\n",
    "\n",
    "\n",
    "input_ids  = np.zeros((template_len, max_features), dtype=np.int64)\n",
    "input_wgts = np.zeros((template_len, max_features), dtype=np.float32)\n",
    "input_ids[:, 0] = UNK_ID\n",
    "input_wgts[:, 0] = 1.0\n",
    "\n",
    "for idx, ts_idx in zip(single_data_point['input_ids'], ts_indices):\n",
    "    print(ts_idx, idx)\n",
    "    input_ids[ts_idx, :len(idx)] = idx\n",
    "\n",
    "\n",
    "for wgt, ts_idx in zip(single_data_point['input_wgts'], ts_indices):\n",
    "    print(ts_idx, wgt)\n",
    "    input_wgts[ts_idx, :len(wgt)] = wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another method that takes too much time. \n",
    "\n",
    "s1 = datetime.now()\n",
    "input_ids = np.zeros((batch_size, template_len, max_features), dtype=np.int64)\n",
    "e1 = datetime.now()\n",
    "print(f'create templates:                    {e1-s1}')\n",
    "\n",
    "s2 = datetime.now()\n",
    "input_ids[:, :, 0] = UNK_ID\n",
    "e2 = datetime.now()\n",
    "print(f'assign UNK_ID:                       {e2-s2}') # we do not need to assign UNK_ID here anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Event's Tensor Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = datetime.now()\n",
    "\n",
    "s1 = datetime.now()\n",
    "input_ids_batch = np.zeros((batch_size, template_len, max_features), dtype=np.int64)\n",
    "e1 = datetime.now()\n",
    "print(f'create input_ids:                     {e1-s1}')\n",
    "print(input_ids_batch.shape)\n",
    "\n",
    "s1 = datetime.now()\n",
    "input_wgts_batch = np.zeros((batch_size, template_len, max_features), dtype=np.float32)\n",
    "e1 = datetime.now()\n",
    "print(f'create input_wgts:                    {e1-s1}')\n",
    "print(input_wgts_batch.shape)\n",
    "\n",
    "\n",
    "s = datetime.now()\n",
    "event_indicators_batch = np.zeros((batch_size, template_len), dtype=np.int64)\n",
    "e = datetime.now()\n",
    "print(f'create event_indicators:              {e-s}')\n",
    "print(event_indicators_batch.shape)\n",
    "\n",
    "s = datetime.now()\n",
    "# timestep_orig_ids_batch = np.array([timestep_orig_ids] * batch_size)\n",
    "timestep_orig_ids_batch = np.tile(timestep_orig_ids, (batch_size, 1))\n",
    "e = datetime.now()\n",
    "print(f'create timestep_orig_ids:             {e-s}')\n",
    "\n",
    "e0 = datetime.now()\n",
    "print(f'total time:                           {e0-s0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_info_final = {\n",
    "    'input_ids': input_ids_batch,\n",
    "    'input_wgts': input_wgts_batch,\n",
    "    'timestep_orig_ids': timestep_orig_ids_batch,\n",
    "    'event_indicators': event_indicators_batch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "\n",
    "\n",
    "index_map = timestep_info['index_map']\n",
    "\n",
    "\n",
    "names_orig = [i for i in example_event_info]\n",
    "for dp_idx, items_sample in enumerate(zip(*example_event_info.values())):\n",
    "    \n",
    "    single_data_point = dict(zip(names_orig, items_sample))\n",
    "\n",
    "\n",
    "    timestep = single_data_point['timestep']\n",
    "    ts_indices = [index_map[ts_id] for ts_id in timestep]\n",
    "\n",
    "\n",
    "    single_input_ids = event_info_final['input_ids'][dp_idx]\n",
    "    for idx, ts_idx in zip(single_data_point['input_ids'], ts_indices):\n",
    "        # print(ts_idx, idx)\n",
    "        single_input_ids[ts_idx, :len(idx)] = idx\n",
    "\n",
    "\n",
    "    single_input_wgts = event_info_final['input_wgts'][dp_idx]\n",
    "    for wgt, ts_idx in zip(single_data_point['input_wgts'], ts_indices):\n",
    "        # print(ts_idx, wgt)\n",
    "        single_input_wgts[ts_idx, :len(wgt)] = wgt\n",
    "\n",
    "    single_event_indicators = event_info_final['event_indicators'][dp_idx]\n",
    "    single_event_indicators[ts_indices] = 1\n",
    "\n",
    "\n",
    "e = datetime.now()\n",
    "print('New method: ', e-s)\n",
    "\n",
    "for k, v in event_info_final.items():\n",
    "    print(k, v.shape)\n",
    "\n",
    "\n",
    "# Old method:  0:00:00.014089\n",
    "# New method:  0:00:00.011910\n",
    "\n",
    "# Old method:  0:00:00.004705\n",
    "# New method:  0:00:00.001887\n",
    "\n",
    "# Old method:  0:00:00.004795\n",
    "# New method:  0:00:00.001790\n",
    "\n",
    "# Old method:  0:00:00.003432\n",
    "# New method:  0:00:00.000898\n",
    "\n",
    "\n",
    "# food-event, ---> tokenize it ---> [tkn1, tkn2, tkn3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the accuracy of the event_indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_tfm['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_indicators = event_info_final['event_indicators']\n",
    "event_indicators[0]#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_indicators.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = event_info_final['input_ids']\n",
    "input_wgts = event_info_final['input_wgts'] \n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "idx = 10 # datapoint idx from batch.\n",
    "########################\n",
    "\n",
    "one_input_ids = input_ids[idx]\n",
    "one_input_wgts = input_wgts[idx]\n",
    "one_event_indicators = event_indicators[idx] \n",
    "print(one_input_ids.shape)\n",
    "print(one_event_indicators.shape)\n",
    "print('total event number:', one_event_indicators.sum())\n",
    "\n",
    "for idx, (step_ids, event_indicator) in enumerate(zip(one_input_ids, one_event_indicators)):\n",
    "    # \n",
    "    if event_indicator != 1: continue \n",
    "    print('At the step', idx)\n",
    "    print('event_indicator', event_indicator)\n",
    "    print('input_ids at one step', step_ids)\n",
    "    step_weights = one_input_wgts[idx]\n",
    "    print('input_wgts at one step', step_weights)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = event_info_final['event_indicators']\n",
    "print(matrix.shape)\n",
    "pprint(matrix.tolist(), sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Field: Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_info = get_timestep_info(examples, TimeCFs)\n",
    "print([i for i in timestep_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstTimeCF = TimeCFs[0]\n",
    "FirstTimeCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFArgs = CF_to_CFArgs[FirstTimeCF]\n",
    "CFArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFvocab = CF_to_CFvocab[TimeCFs[0]]\n",
    "pprint(CFvocab, sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_orig_ids = np.array(timestep_info['timestep_orig_ids'])\n",
    "timedelta_info = timestep_info['total_timedelta_info']\n",
    "obs_dt = np.array(pd.to_datetime(examples['ObsDT']), dtype='datetime64[ns]')\n",
    "# obs_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_deltas = np.array([\n",
    "    pd.Timedelta(orig_id * int(ts), unit=unit)# .total_seconds() * 1e9\n",
    "    for orig_id, (ts, unit) in zip(timestep_orig_ids, timedelta_info)\n",
    "], dtype='timedelta64[ns]')\n",
    "# time_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized datetime calculation\n",
    "datetimes = obs_dt[:, None] + time_deltas  # shape: (n_samples, n_timesteps)\n",
    "# datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_timestepinfo_array(examples, timestep_info, CFvocab):\n",
    "    # Extract base components\n",
    "    timestep_orig_ids = np.array(timestep_info['timestep_orig_ids'])\n",
    "    timedelta_info = timestep_info['total_timedelta_info']\n",
    "    obs_dt = np.array(pd.to_datetime(examples['ObsDT']), dtype='datetime64[ns]')\n",
    "    \n",
    "    # Precompute time deltas in nanoseconds\n",
    "    time_deltas = np.array([\n",
    "        pd.Timedelta(orig_id * int(ts), unit=unit)# .total_seconds() * 1e9\n",
    "        for orig_id, (ts, unit) in zip(timestep_orig_ids, timedelta_info)\n",
    "    ], dtype='timedelta64[ns]')\n",
    "\n",
    "    # Vectorized datetime calculation\n",
    "    datetimes = obs_dt[:, None] + time_deltas  # shape: (n_samples, n_timesteps)\n",
    "\n",
    "    # Vectorized feature extraction\n",
    "    hours   = (datetimes.astype('datetime64[h]') - datetimes.astype('datetime64[D]')).astype(int)\n",
    "    minutes = (datetimes.astype('datetime64[m]') - datetimes.astype('datetime64[h]')).astype(int)\n",
    "\n",
    "    # Precompute vocabulary mappings\n",
    "    hour_tokens   = [f'f1:Hour{i}' for i in range(24)]\n",
    "    minute_tokens = [f'f1:Min{i}' for i in range(60)]\n",
    "    \n",
    "    hour_ids   = np.array([CFvocab['input_ids']['tkn2tid'].get(t, 0) for t in hour_tokens])\n",
    "    minute_ids = np.array([CFvocab['input_ids']['tkn2tid'].get(t, 0) for t in minute_tokens])\n",
    "\n",
    "    # Vectorized ID lookup\n",
    "    input_ids = np.stack([\n",
    "        hour_ids[hours],\n",
    "        minute_ids[minutes]\n",
    "    ], axis=-1)  # shape: (n_samples, n_timesteps, 2)\n",
    "\n",
    "    # Reshape to match expected format\n",
    "    # input_ids = input_ids.reshape(len(examples['ObsDT']), -1).tolist()\n",
    "\n",
    "    field_info_final = {\n",
    "        'input_ids': input_ids, # pad_with_numpy(input_ids),\n",
    "        'timestep_orig_ids': timestep_orig_ids.tolist()\n",
    "    }\n",
    "    return field_info_final\n",
    "\n",
    "get_timestepinfo_array.fn_string = inspect.getsource(get_timestepinfo_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFvocab = CF_to_CFvocab[TimeCFs[0]]\n",
    "\n",
    "s = datetime.now()\n",
    "field_info_final_new = get_timestepinfo_array(examples, timestep_info, CFvocab)\n",
    "e = datetime.now()\n",
    "print(f'get_timestepinfo_array_old: {e-s}')\n",
    "# pprint(field_info_final, sort_dicts=False, compact=True)\n",
    "\n",
    "# get_timestepinfo_array_old: 0:00:00.005049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_info_final_old['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_info_final_new['input_ids']\n",
    "\n",
    "field_info_final_new['input_ids'].shape\n",
    "\n",
    "x = field_info_final_new['input_ids'][0]\n",
    "x.shape\n",
    "# 313: -288, 24\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFvocab['input_ids']['tid2tkn'][42]\n",
    "# 10: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfm_fn_AIInputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab):\n",
    "    # s1 = datetime.now()\n",
    "    Input_Part = OneEntryArgs['Input_Part']\n",
    "    InputCFs = get_INPUT_CFs(OneEntryArgs)\n",
    "    # e1 = datetime.now()\n",
    "    # print(f'get_INPUT_CFs: {e1-s1}')\n",
    "\n",
    "    examples_tfm = {}\n",
    "    # s2 = datetime.now()\n",
    "    # ------------------------------------------------------------ # \n",
    "    TargetField = Input_Part['TargetField']\n",
    "    TargetCFs = [i for i in InputCFs if TargetField in i]\n",
    "    \n",
    "    # df = pd.DataFrame({cf: examples[cf + '--input_ids'] for cf in TargetCFs})\n",
    "    # df['input_ids'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "    # examples_tfm['input_ids'] = torch.LongTensor(np.array(df['input_ids'].to_list())) # ().copy()\n",
    "    \n",
    "    target_arrays = [np.array(examples[f\"{cf}--input_ids\"]) for cf in TargetCFs]\n",
    "    stacked_ids = np.concatenate(target_arrays, axis=1) # # Assuming each array has shape (batch_size, seq_len)\n",
    "    examples_tfm['input_ids'] = torch.LongTensor(stacked_ids)\n",
    "\n",
    "    # e2 = datetime.now()\n",
    "    # print(f'TargetField: {e2-s2}')\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------ # \n",
    "    # already ordered\n",
    "    # s3 = datetime.now()\n",
    "    EventFields = Input_Part.get('EventFields', [])\n",
    "    if len(EventFields) > 0:\n",
    "        TimeField = Input_Part.get('TimeField', None)\n",
    "        if TimeField is not None:\n",
    "            EventCFs = [i for i in InputCFs if TargetField not in i and TimeField not in i]\n",
    "        else:\n",
    "            EventCFs = [i for i in InputCFs if TargetField not in i]\n",
    "    else:\n",
    "        EventCFs = []\n",
    "    # e3 = datetime.now()\n",
    "    # print(f'Get different Field Information: {e3-s3}')\n",
    "\n",
    "    # s4 = datetime.now()\n",
    "    # update emptiness of examples\n",
    "    for EventCF in EventCFs:\n",
    "        examples_updated = update_emptiness_of_examples(examples, EventCF)\n",
    "        for k, v in examples_updated.items(): examples[k] = v\n",
    "    # e4 = datetime.now()\n",
    "    # print(f'update_emptiness_of_examples: {e4-s4}')\n",
    "\n",
    "   \n",
    "    # Multi EventCFs\n",
    "    timestep_info = None\n",
    "    for OneEvent in EventFields:\n",
    "        # s5 = datetime.now()\n",
    "\n",
    "        OneEventCFs = [i for i in InputCFs if OneEvent in i]\n",
    "        # s6 = datetime.now()\n",
    "        ############################################################\n",
    "        example_event_info = {}\n",
    "        max_features = 0\n",
    "        batch_size = 0\n",
    "\n",
    "        for seqtype in ['input_ids', 'input_wgts', 'timestep']:\n",
    "            columns_data = [examples[f\"{cf}--{seqtype}\"] for cf in OneEventCFs]\n",
    "            batch_size = len(columns_data[0])\n",
    "            values = []\n",
    "            for sample_items in zip(*columns_data):\n",
    "                combined = list(itertools.chain(*sample_items))\n",
    "\n",
    "                if seqtype == 'input_ids': \n",
    "                    if len(combined) == 0:\n",
    "                        current_max_length = 0\n",
    "                    else:\n",
    "                        current_max_length = max(len(i) for i in combined)\n",
    "                    max_features = max(max_features, current_max_length)\n",
    "\n",
    "                values.append(combined)\n",
    "            example_event_info[seqtype] = values\n",
    "        ############################################################\n",
    "        # e6 = datetime.now()\n",
    "        # print(f'example_event_info: {e6-s6}')\n",
    "        if max_features == 0: \n",
    "            # skip this event. \n",
    "            continue \n",
    "\n",
    "        # Precompute timestep info once per Event type\n",
    "        if timestep_info is None: \n",
    "            timestep_info = get_timestep_info(examples, OneEventCFs)\n",
    "            # name = [i for i in examples]\n",
    "            timestep_orig_ids = timestep_info['timestep_orig_ids']\n",
    "            template_len = len(timestep_orig_ids) \n",
    "\n",
    "        # s7 = datetime.now()\n",
    "        input_ids_batch = np.zeros((batch_size, template_len, max_features), dtype=np.int64)\n",
    "        input_wgts_batch = np.zeros((batch_size, template_len, max_features), dtype=np.float32)\n",
    "        event_indicators_batch = np.zeros((batch_size, template_len), dtype=np.int64)\n",
    "        timestep_orig_ids_batch = np.tile(timestep_orig_ids, (batch_size, 1))\n",
    "\n",
    "        event_info_final = {\n",
    "            'input_ids': input_ids_batch,\n",
    "            'input_wgts': input_wgts_batch,\n",
    "            'timestep_orig_ids': timestep_orig_ids_batch,\n",
    "            'event_indicators': event_indicators_batch\n",
    "        }\n",
    "        \n",
    "        index_map = timestep_info['index_map']\n",
    "        names_orig = [i for i in example_event_info]\n",
    "        for dp_idx, items_sample in enumerate(zip(*example_event_info.values())):\n",
    "            \n",
    "            single_data_point = dict(zip(names_orig, items_sample))\n",
    "            timestep = single_data_point['timestep']\n",
    "            ts_indices = [index_map[ts_id] for ts_id in timestep]\n",
    "\n",
    "            single_input_ids = event_info_final['input_ids'][dp_idx]\n",
    "            for idx, ts_idx in zip(single_data_point['input_ids'], ts_indices):\n",
    "                # print(ts_idx, idx)\n",
    "                single_input_ids[ts_idx, :len(idx)] = idx\n",
    "\n",
    "            single_input_wgts = event_info_final['input_wgts'][dp_idx]\n",
    "            for wgt, ts_idx in zip(single_data_point['input_wgts'], ts_indices):\n",
    "                # print(ts_idx, wgt)\n",
    "                single_input_wgts[ts_idx, :len(wgt)] = wgt\n",
    "\n",
    "            single_event_indicators = event_info_final['event_indicators'][dp_idx]\n",
    "            single_event_indicators[ts_indices] = 1\n",
    "\n",
    "        # e7 = datetime.now()\n",
    "        # print(f'update_seqtype_base_on_timestep: {e7-s7}')\n",
    "\n",
    "\n",
    "        # s9 = datetime.now()\n",
    "        for k, v in event_info_final.items():\n",
    "            if '_wgt' in k:\n",
    "                event_info_final[k] = torch.FloatTensor(v)\n",
    "            else:\n",
    "                event_info_final[k] = torch.LongTensor(v)\n",
    "            examples_tfm[OneEvent + '--' + k] = event_info_final[k]\n",
    "        \n",
    "        # e9 = datetime.now()\n",
    "        # print(f'turn to tensor: {e9-s9}')\n",
    "\n",
    "\n",
    "        # e5 = datetime.now()\n",
    "        # print(f'Multi EventCFs -- {OneEvent}: {e5-s5}')\n",
    "\n",
    "\n",
    "    # s6 = datetime.now()\n",
    "    # ------------------------------------------------------------ # \n",
    "    TimeField = Input_Part.get('TimeField', None)\n",
    "    # TimeField\n",
    "    if TimeField is not None:\n",
    "        TimeCFs = [i for i in InputCFs if TimeField in i]\n",
    "        CFvocab = CF_to_CFvocab[TimeCFs[0]]\n",
    "        if timestep_info is None: timestep_info = get_timestep_info(examples, TimeCFs)\n",
    "\n",
    "        time_info_final = get_timestepinfo_array(examples, timestep_info, CFvocab)\n",
    "        for k, v in time_info_final.items():\n",
    "            if '_wgt' in k:\n",
    "                time_info_final[k] = torch.FloatTensor(v)\n",
    "            else:\n",
    "                time_info_final[k] = torch.LongTensor(v)\n",
    "\n",
    "            examples_tfm[TimeField + '--' + k] = time_info_final[k]\n",
    "    # e6 = datetime.now()\n",
    "    # print(f'TimeField: {e6-s6}')\n",
    "\n",
    "    return examples_tfm\n",
    "\n",
    "\n",
    "tfm_fn_AIInputData.fn_string = inspect.getsource(tfm_fn_AIInputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n==============================================\\n')\n",
    "from datetime import datetime\n",
    "s = datetime.now()\n",
    "\n",
    "# preprocess_fn(examples)\n",
    "examples_tfm = tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "e = datetime.now()\n",
    "print(f'tfm_fn_AIInputData_new: {e-s}')\n",
    "\n",
    "\n",
    "# old version\n",
    "# get_INPUT_CFs: 0:00:00.000003\n",
    "# TargetField: 0:00:00.001757\n",
    "# EventFields: 0:00:00.000003\n",
    "# update_emptiness_of_examples: 0:00:00.000056\n",
    "# Multi EventCFs -- Diet: 0:00:00.470472\n",
    "# TimeField: 0:00:00.205376\n",
    "# tfm_fn_AIInputData: 0:00:00.678363\n",
    "\n",
    "\n",
    "# Diet and Time\n",
    "# tfm_fn_AIInputData_new: 0:00:00.047536 \n",
    "\n",
    "\n",
    "# v0202\n",
    "# TargetField: 0:00:00.001437\n",
    "# example_event_info: 0:00:00.000135\n",
    "# update_seqtype_base_on_timestep: 0:00:00.004341\n",
    "# turn to tensor: 0:00:00.000072\n",
    "# Multi EventCFs -- Diet: 0:00:00.004749\n",
    "# TimeField: 0:00:00.005821\n",
    "# tfm_fn_AIInputData_new: 0:00:00.012326\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in examples_tfm.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entry_fn_AIInputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_fn_AIInputData(Data, \n",
    "                         CF_to_CFvocab, \n",
    "                         OneEntryArgs,\n",
    "                         tfm_fn_AIInputData = None):\n",
    "    \n",
    "    # Input feaures. \n",
    "    # INPUT_CFs = get_INPUT_CFs(OneEntryArgs)\n",
    "    # print(INPUT_CFs)\n",
    "    transform_fn = lambda examples: tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "\n",
    "    # ds_case \n",
    "    ds_case = Data['ds_case']\n",
    "    if type(ds_case) == pd.DataFrame:\n",
    "        ds_case = datasets.Dataset.from_pandas(ds_case) \n",
    "\n",
    "    use_map = OneEntryArgs.get('use_map', False)\n",
    "    num_proc = OneEntryArgs.get('num_proc', 4)\n",
    "    if use_map == False:\n",
    "        ds_case.set_transform(transform_fn)\n",
    "        ds_tfm = ds_case\n",
    "    else:\n",
    "        ds_tfm = ds_case.map(transform_fn, batched = True, num_proc = num_proc)\n",
    "    \n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    return Data\n",
    "\n",
    "tfm_fn_AIInputData.fn_string = inspect.getsource(tfm_fn_AIInputData)\n",
    "entry_fn_AIInputData.fn_string = inspect.getsource(entry_fn_AIInputData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = entry_fn_AIInputData(Data, \n",
    "                            CF_to_CFvocab, \n",
    "                            OneEntryArgs,\n",
    "                            tfm_fn_AIInputData)\n",
    "\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_tfm[:4]\n",
    "# batch\n",
    "\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Save Entry Fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.entry import AIDATA_ENTRYINPUT_PATH\n",
    "from recfldtkn.base import Base\n",
    "\n",
    "pypath = os.path.join(SPACE['CODE_FN'],  AIDATA_ENTRYINPUT_PATH, f'{EntryInputMethod}.py')\n",
    "# print(pypath) \n",
    "\n",
    "prefix = [\n",
    "    'import copy',\n",
    "    'import itertools',\n",
    "    'import pandas as pd', \n",
    "    'import numpy as np', \n",
    "    'import datasets',\n",
    "    'import torch',\n",
    "    'from datetime import datetime',\n",
    "    ]\n",
    "\n",
    "fn_variables = [\n",
    "    # vectorized_pad,\n",
    "    detect_empty_values,\n",
    "    get_timestep_info, \n",
    "    update_emptiness_of_examples,\n",
    "    # update_seqtype_base_on_timestep, \n",
    "    # pad_with_numpy,\n",
    "    get_INPUT_CFs,\n",
    "    # extract_datetime_components_as_list,\n",
    "    get_timestepinfo_array,\n",
    "    tfm_fn_AIInputData,\n",
    "    entry_fn_AIInputData,\n",
    "]\n",
    "\n",
    "pycode = Base.convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "\n",
    "print(pypath)\n",
    "if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: EntryFn - Output_Part: NTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TaskType = 'MLUniLabel'\n",
    "SeriesName  = 'Bf24.Af2H'\n",
    "OneTaskName = 'cgm_lhm_bf24h_af2h_5min'\n",
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "\n",
    "            'cf.ActivitySparse_Bf24H',\n",
    "            'cf.ActivitySparse_Af2H',\n",
    "\n",
    "            'cf.TimeSparse_Bf24H', \n",
    "            'cf.TimeSparse_Af2H',\n",
    "            'cf.DietSparse_Bf24H',\n",
    "            'cf.DietSparse_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        'TimeField':   'Time',\n",
    "        'EventFields': [\n",
    "            'Activity',\n",
    "            'Diet',\n",
    "        ],\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'NTP',\n",
    "    },\n",
    "\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "        'Tagging': [],\n",
    "        'Filtering': [], \n",
    "    },\n",
    "}\n",
    "\n",
    "# Data = {'df_case': caseset.df_case, 'ds_case': caseset.ds_case}\n",
    "\n",
    "EntryOutputMethod = OneEntryArgs['Output_Part']['EntryOutputMethod']\n",
    "CF_to_CFvocab = case_base.TriggerCaseBaseName_to_CFtoCFvocab[TriggerCaseBaseName]\n",
    "print([i for i in CF_to_CFvocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%%%%%%%%%%%%%%%%%%%%\n",
    "# UniLabel\n",
    "import inspect \n",
    "import numpy as np \n",
    "# from recfldtkn.loadtools import convert_variables_to_pystirng\n",
    "\n",
    "def get_OUTPUT_CFs(OneEntryArgs):\n",
    "    if 'Output_Part' not in OneEntryArgs:\n",
    "        return []\n",
    "    else:\n",
    "        return OneEntryArgs['Output_Part'].get('CF_list', [])\n",
    "get_OUTPUT_CFs.fn_string = inspect.getsource(get_OUTPUT_CFs)\n",
    "\n",
    "\n",
    "def transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab):\n",
    "    examples_tfm = tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "    # examples_tfm['labels'] = torch.LongTensor([[i] for i in examples['Labeling']])\n",
    "    examples_tfm['labels'] = examples_tfm['input_ids'].clone() \n",
    "    return examples_tfm\n",
    "\n",
    "transform_fn_output.fn_string = inspect.getsource(transform_fn_output)\n",
    "\n",
    "\n",
    "def entry_fn_AITaskData(Data, \n",
    "                        CF_to_CFvocab, \n",
    "                        OneEntryArgs,\n",
    "                        tfm_fn_AIInputData = None,\n",
    "                        entry_fn_AIInputData = None,\n",
    "                        ):\n",
    "\n",
    "    # InputCFs = OneEntryArgs['Input_FullArgs']['INPUT_CFs_Args']['InputCFs']\n",
    "    transform_fn = lambda examples: transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab)\n",
    "    ds_case = Data['ds_case']\n",
    "\n",
    "    if type(ds_case) == pd.DataFrame:\n",
    "        ds_case = datasets.Dataset.from_pandas(ds_case)\n",
    "        \n",
    "    # ds_case.set_transform(transform_fn)\n",
    "    use_map = OneEntryArgs.get('use_map', False)\n",
    "    num_proc = OneEntryArgs.get('num_proc', 4)\n",
    "    if use_map == False:\n",
    "        ds_case.set_transform(transform_fn)\n",
    "        ds_tfm = ds_case\n",
    "    else:\n",
    "        ds_tfm = ds_case.map(transform_fn, batched = True, num_proc = num_proc)\n",
    "\n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    \n",
    "    return Data\n",
    "\n",
    "entry_fn_AITaskData.fn_string = inspect.getsource(entry_fn_AITaskData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = entry_fn_AITaskData(Data, \n",
    "                           CF_to_CFvocab, \n",
    "                           OneEntryArgs,\n",
    "                           tfm_fn_AIInputData,\n",
    "                           entry_fn_AIInputData)\n",
    "\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_tfm[:4]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntp. \n",
    "\n",
    "# pretrain dataset. \n",
    "\n",
    "\n",
    "\n",
    "# GPT2: token ids: [1, 3324, 3453]\n",
    "# GPT2:    labels: [1, 3324, 3453]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.base import Base\n",
    "from recfldtkn.aidata_base.entry import AIDATA_ENTRYOUTPUT_PATH\n",
    "\n",
    "prefix = [\n",
    "    'import torch',\n",
    "    'import pandas as pd', \n",
    "    'import numpy as np', \n",
    "    'import datasets',\n",
    "    ]\n",
    "fn_variables = [\n",
    "    get_OUTPUT_CFs,\n",
    "    transform_fn_output,\n",
    "    entry_fn_AITaskData,\n",
    "]\n",
    "pycode = Base.convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "pypath = os.path.join(SPACE['CODE_FN'], AIDATA_ENTRYOUTPUT_PATH, f'{EntryOutputMethod}.py')\n",
    "print(pypath)\n",
    "if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: EntryFn - Output_Part: MaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TaskType = 'MLUniLabel'\n",
    "SeriesName  = 'Bf24.Af2H'\n",
    "OneTaskName = 'cgm_lhm_bf24h_af2h_5min'\n",
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "\n",
    "            # 'cf.ActivitySparse_Bf24H',\n",
    "            # 'cf.ActivitySparse_Af2H',\n",
    "\n",
    "            'cf.TimeSparse_Bf24H', \n",
    "            'cf.TimeSparse_Af2H',\n",
    "\n",
    "\n",
    "            # 'cf.DietSparse_Bf24H',\n",
    "            # 'cf.DietSparse_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        'TimeField':   'Time',\n",
    "        'EventFields': [\n",
    "            # 'Activity',\n",
    "            # 'Diet',\n",
    "        ],\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'MaskedLM',\n",
    "        'MaskingRate': 0.15,\n",
    "    },\n",
    "\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "        'Tagging': [],\n",
    "        'Filtering': [], \n",
    "    },\n",
    "}\n",
    "\n",
    "# Data = {'df_case': caseset.df_case, 'ds_case': caseset.ds_case}\n",
    "\n",
    "EntryOutputMethod = OneEntryArgs['Output_Part']['EntryOutputMethod']\n",
    "CF_to_CFvocab = case_base.TriggerCaseBaseName_to_CFtoCFvocab[TriggerCaseBaseName]\n",
    "print([i for i in CF_to_CFvocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%%%%%%%%%%%%%%%%%%%%\n",
    "# UniLabel\n",
    "import inspect \n",
    "import numpy as np \n",
    "# from recfldtkn.loadtools import convert_variables_to_pystirng\n",
    "\n",
    "def get_OUTPUT_CFs(OneEntryArgs):\n",
    "    if 'Output_Part' not in OneEntryArgs:\n",
    "        return []\n",
    "    else:\n",
    "        return OneEntryArgs['Output_Part'].get('CF_list', [])\n",
    "get_OUTPUT_CFs.fn_string = inspect.getsource(get_OUTPUT_CFs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in CF_to_CFvocab]\n",
    "\n",
    "# CF_to_CFvocab['cf.TargetCGM_Af2H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetField = OneEntryArgs['Input_Part']['TargetField']\n",
    "\n",
    "TargetField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab):\n",
    "#     examples_tfm = tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "#     # examples_tfm['labels'] = torch.LongTensor([[i] for i in examples['Labeling']])\n",
    "#     examples_tfm['labels'] = examples_tfm['input_ids'].clone() \n",
    "\n",
    "#     masking_rate = OneEntryArgs['Output_Part']['MaskingRate']\n",
    "\n",
    "#     return examples_tfm\n",
    "\n",
    "# transform_fn_output.fn_string = inspect.getsource(transform_fn_output)\n",
    "\n",
    "\n",
    "def transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab):\n",
    "    examples_tfm = tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "    \n",
    "    masking_rate = OneEntryArgs['Output_Part']['MaskingRate']\n",
    "\n",
    "    TargetField = OneEntryArgs['Input_Part']['TargetField']\n",
    "    TargetField_CF = [i for i in CF_to_CFvocab if TargetField in i][0]\n",
    "    CFvocab = CF_to_CFvocab[TargetField_CF]\n",
    "    tkn2tid = CFvocab['input_ids']['tkn2tid']\n",
    "    mask_token_id = tkn2tid['[MASK]']\n",
    "    \n",
    "\n",
    "    \n",
    "    original_input_ids = examples_tfm['input_ids'].clone()\n",
    "    device = original_input_ids.device\n",
    "    \n",
    "    # Create mask where tokens are selected for masking\n",
    "    mask = torch.rand(original_input_ids.shape, device=device) < masking_rate\n",
    "    mask_indices = mask.nonzero(as_tuple=True)\n",
    "    original_token_ids = original_input_ids[mask_indices]\n",
    "    \n",
    "    # Determine replacement strategy for masked tokens\n",
    "    random_tensor = torch.rand(original_token_ids.shape, device=device)\n",
    "    mask_selected = (random_tensor <= 1)        \n",
    "\n",
    "    # Apply [MASK] replacements\n",
    "    replaced_token_ids = torch.where(\n",
    "        mask_selected,\n",
    "        torch.tensor(mask_token_id, device=device),\n",
    "        original_token_ids\n",
    "    )\n",
    "    # Generate masked input_ids\n",
    "    masked_input_ids = original_input_ids.clone()\n",
    "    masked_input_ids[mask_indices] = replaced_token_ids\n",
    "    \n",
    "    # Create labels with non-masked tokens ignored (-100)\n",
    "    labels = original_input_ids.clone()\n",
    "    labels[~mask] = -100\n",
    "    \n",
    "    examples_tfm['input_ids'] = masked_input_ids\n",
    "    examples_tfm['labels'] = labels\n",
    "    \n",
    "    return examples_tfm\n",
    "\n",
    "transform_fn_output.fn_string = inspect.getsource(transform_fn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_tfm = transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in examples_tfm.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = examples_tfm['input_ids']\n",
    "labels = examples_tfm['labels']\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def entry_fn_AITaskData(Data, \n",
    "                        CF_to_CFvocab, \n",
    "                        OneEntryArgs,\n",
    "                        tfm_fn_AIInputData = None,\n",
    "                        entry_fn_AIInputData = None,\n",
    "                        ):\n",
    "\n",
    "    # InputCFs = OneEntryArgs['Input_FullArgs']['INPUT_CFs_Args']['InputCFs']\n",
    "    transform_fn = lambda examples: transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab)\n",
    "    ds_case = Data['ds_case']\n",
    "\n",
    "    if type(ds_case) == pd.DataFrame:\n",
    "        ds_case = datasets.Dataset.from_pandas(ds_case)\n",
    "        \n",
    "    # ds_case.set_transform(transform_fn)\n",
    "    use_map = OneEntryArgs.get('use_map', False)\n",
    "    num_proc = OneEntryArgs.get('num_proc', 4)\n",
    "    if use_map == False:\n",
    "        ds_case.set_transform(transform_fn)\n",
    "        ds_tfm = ds_case\n",
    "    else:\n",
    "        ds_tfm = ds_case.map(transform_fn, batched = True, num_proc = num_proc)\n",
    "\n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    \n",
    "    return Data\n",
    "\n",
    "entry_fn_AITaskData.fn_string = inspect.getsource(entry_fn_AITaskData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = entry_fn_AITaskData(Data, \n",
    "                           CF_to_CFvocab, \n",
    "                           OneEntryArgs,\n",
    "                           tfm_fn_AIInputData,\n",
    "                           entry_fn_AIInputData)\n",
    "\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_tfm[:4]\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.base import Base\n",
    "from recfldtkn.aidata_base.entry import AIDATA_ENTRYOUTPUT_PATH\n",
    "\n",
    "prefix = [\n",
    "    'import torch',\n",
    "    'import pandas as pd', \n",
    "    'import numpy as np', \n",
    "    'import datasets',\n",
    "    ]\n",
    "fn_variables = [\n",
    "    get_OUTPUT_CFs,\n",
    "    transform_fn_output,\n",
    "    entry_fn_AITaskData,\n",
    "]\n",
    "pycode = Base.convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "pypath = os.path.join(SPACE['CODE_FN'], AIDATA_ENTRYOUTPUT_PATH, f'{EntryOutputMethod}.py')\n",
    "print(pypath)\n",
    "if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: EntryFn - Output_Part: EventPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create DataLoader with your actual training parameters\n",
    "loader = DataLoader(\n",
    "    dataset=ds_tfm,  # Your dataset with set_transform\n",
    "    batch_size=32,            # Use your real batch size\n",
    "    num_workers=1,            # Match your training setup\n",
    "    pin_memory=True,          # Same as training config\n",
    "    shuffle=False             # Disable for consistent measurement\n",
    ")\n",
    "\n",
    "# 2. Warm-up run (initial batches are slower due to setup)\n",
    "print(\"Warming up...\")\n",
    "for _ in loader: pass\n",
    "\n",
    "# 3. Timed measurement\n",
    "num_batches = len(loader)\n",
    "print(f\"Testing with {num_batches} batches...\")\n",
    "\n",
    "start_time = time.perf_counter()  # More precise timer\n",
    "for _ in loader:\n",
    "    pass\n",
    "total_time = time.perf_counter() - start_time\n",
    "\n",
    "# 4. Calculate metrics\n",
    "throughput = num_batches / total_time\n",
    "samples_per_sec = len(ds_tfm) / total_time\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"- Batches/s: {throughput:.1f}\")\n",
    "print(f\"- Samples/s: {samples_per_sec:.1f}\")\n",
    "print(f\"- Batch time: {1000*total_time/num_batches:.1f}ms\")\n",
    "print(f\"- Total time: {total_time:.2f}s\")\n",
    "\n",
    "\n",
    "# Warming up...\n",
    "# Testing with 1657 batches...\n",
    "\n",
    "# Results:\n",
    "# - Batches/s: 47.8\n",
    "# - Samples/s: 1527.5\n",
    "# - Batch time: 20.9ms\n",
    "# - Total time: 34.69s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one CPU\n",
    "\n",
    "# Warming up...\n",
    "# Testing with 1657 batches...\n",
    "\n",
    "# Results:\n",
    "# - Batches/s: 37.1\n",
    "# - Samples/s: 1186.0\n",
    "# - Batch time: 27.0ms\n",
    "# - Total time: 44.68s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create DataLoader with your actual training parameters\n",
    "loader = DataLoader(\n",
    "    dataset=ds_tfm,  # Your dataset with set_transform\n",
    "    batch_size=64,            # Use your real batch size\n",
    "    num_workers=1,            # Match your training setup\n",
    "    pin_memory=True,          # Same as training config\n",
    "    shuffle=False             # Disable for consistent measurement\n",
    ")\n",
    "\n",
    "# 2. Warm-up run (initial batches are slower due to setup)\n",
    "print(\"Warming up...\")\n",
    "for _ in loader: pass\n",
    "\n",
    "# 3. Timed measurement\n",
    "num_batches = len(loader)\n",
    "print(f\"Testing with {num_batches} batches...\")\n",
    "\n",
    "start_time = time.perf_counter()  # More precise timer\n",
    "for _ in loader:\n",
    "    pass\n",
    "total_time = time.perf_counter() - start_time\n",
    "\n",
    "# 4. Calculate metrics\n",
    "throughput = num_batches / total_time\n",
    "samples_per_sec = len(ds_tfm) / total_time\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"- Batches/s: {throughput:.1f}\")\n",
    "print(f\"- Samples/s: {samples_per_sec:.1f}\")\n",
    "print(f\"- Batch time: {1000*total_time/num_batches:.1f}ms\")\n",
    "print(f\"- Total time: {total_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}