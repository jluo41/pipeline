{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Record and Case Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_case.GROUP import GROUP_TO_GROUPMethodArgs\n",
    "from config.config_case.CF import CF_to_CFArgs\n",
    "from config.config_case.CKPD import Ckpd_to_CkpdObsConfig\n",
    "from config.config_case.TagRec import TagRec_to_TagRecArgs\n",
    "from config.config_case.TagCF import TagCF_to_TagCFArgs \n",
    "from config.config_case.Flt import FltName_to_FltArgs\n",
    "from config.config_case.CASE import TriggerCaseBaseName_to_TriggerCaseBaseArgs\n",
    "\n",
    "from config.config_record.Cohort import CohortName_to_OneCohortArgs\n",
    "from config.config_case.CKPD import Ckpd_to_CkpdObsConfig\n",
    "\n",
    "from recfldtkn.record_base import Record_Base\n",
    "from recfldtkn.case_base.case_base import Case_Base\n",
    "\n",
    "CohortNames = [i for i in CohortName_to_OneCohortArgs.keys()]\n",
    "print(CohortNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "Inference_Entry = None # this is not inference mode\n",
    "Case_Args_Settings = {\n",
    "    'Ckpd_to_CkpdObsConfig': Ckpd_to_CkpdObsConfig,\n",
    "    'CF_to_CFArgs': CF_to_CFArgs,\n",
    "    'TagCF_to_TagCFArgs': TagCF_to_TagCFArgs,\n",
    "    'TagRec_to_TagRecArgs': TagRec_to_TagRecArgs,\n",
    "    'FltName_to_FltArgs': FltName_to_FltArgs,\n",
    "    'GROUP_TO_GROUPMethodArgs': GROUP_TO_GROUPMethodArgs,\n",
    "}\n",
    "\n",
    "\n",
    "Record_Proc_Config = {\n",
    "    'save_data': True, \n",
    "    'load_data':True, \n",
    "    'via_method': 'ds',\n",
    "}\n",
    "\n",
    "Case_Proc_Config = {\n",
    "    'max_trigger_case_num': None, \n",
    "    'use_task_cache': False, \n",
    "    'caseset_chunk_size': 200000, # 200k for CGM, 50k for others.\n",
    "    'save_data': True, \n",
    "    'load_data': True, \n",
    "    'load_casecollection': True, \n",
    "    'via_method': 'ds',\n",
    "    'n_cpus': 1, \n",
    "    'batch_size': 1000,  \n",
    "}\n",
    "###################################  \n",
    "\n",
    "CohortName_list = [ \n",
    "    'WellDoc2023CVSDeRx',\n",
    "]\n",
    "\n",
    "TriggerCaseBaseName = 'Bf24HAf2H_CGM_And_Event'\n",
    "TriggerCaseBaseArgs =  {\n",
    "    # --------- this three are relatively stable ----------------\n",
    "    'Trigger': {\n",
    "        'TriggerName': 'CGM5MinEntry', \n",
    "        'TagRec': [\n",
    "            'TagRec.PDemoFromP',\n",
    "        ],\n",
    "        'Group': 'GrpGenderDisease', # \n",
    "        'Filter': 'FltBasicDemo',\n",
    "        'ObsTask': {\n",
    "            'TagCF_list': [\n",
    "                'TagCF.Bf24hCGMinfo', \n",
    "                'TagCF.Af2hCGMinfo',\n",
    "            ],\n",
    "            'CF_list':  [],\n",
    "        }\n",
    "    },\n",
    "    # --------------------------------\n",
    "\n",
    "    # --------------------------------\n",
    "    'FilterCaseSet': {\n",
    "        'Filter': 'FltMiniBfAfCGMRecInfo',\n",
    "        'ObsTask': {\n",
    "            'TagCF_list': [\n",
    "                'TagCF.Bf24hCGMinfo', \n",
    "                'TagCF.Af2hCGMinfo',\n",
    "            ],\n",
    "            'CF_list':  [\n",
    "                'cf.TargetCGM_Bf24H', \n",
    "                'cf.TargetCGM_Af2H',\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # --------------------------------\n",
    "    'FilterCaseSetWithAnyEvents': {\n",
    "        'Filter': 'FltWithBf24hAf2HAf2Ht8H-MEDAL-OR',\n",
    "        # 'Filter': 'FltWithBf24hFood', \n",
    "        'ObsTask': {\n",
    "            'TagCF_list': [\n",
    "                'TagCF.Bf24hCGMinfo', \n",
    "                'TagCF.Af2hCGMinfo',\n",
    "                \n",
    "                'TagCF.Bf24hRecNum',\n",
    "                'TagCF.Af2hRecNum',\n",
    "                # 'TagCF.Af2ht8hRecNum',\n",
    "            ],\n",
    "\n",
    "            'CF_list':  [\n",
    "                'cf.PDemo',\n",
    "                'cf.TargetCGM_Bf24H', \n",
    "                'cf.TargetCGM_Af2H',\n",
    "                # 'cf.TargetCGM_Af2Hto8H',\n",
    "                'cf.TimeSparse_Bf24H', \n",
    "                'cf.TimeSparse_Af2H',\n",
    "                # 'cf.TimeSparse_Af2Hto8H',\n",
    "                'cf.DietSparse_Bf24H',\n",
    "                'cf.DietSparse_Af2H',\n",
    "                # 'cf.DietSparse_Af2Hto8H',\n",
    "                ],\n",
    "        },\n",
    "    },\n",
    "    # --------------------------------\n",
    "}\n",
    "\n",
    "TriggerCaseBaseName_to_TriggerCaseBaseArgs[TriggerCaseBaseName] = TriggerCaseBaseArgs\n",
    "pprint(TriggerCaseBaseArgs, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.check import update_and_assert_CaseInfo\n",
    "from recfldtkn.check import retrive_pipeline_info\n",
    "PIPELINE_INFO = retrive_pipeline_info(SPACE)\n",
    "\n",
    "\n",
    "CaseSettingInfo = update_and_assert_CaseInfo(\n",
    "                                TriggerCaseBaseName,\n",
    "                                TriggerCaseBaseArgs,\n",
    "                                Case_Args_Settings,\n",
    "                                Case_Proc_Config, \n",
    "                                PIPELINE_INFO, \n",
    "                                )\n",
    "\n",
    "HumanRecordRecfeat_Args = CaseSettingInfo['HumanRecordRecfeat_Args']\n",
    "record_base = Record_Base(CohortName_list, \n",
    "                            HumanRecordRecfeat_Args,\n",
    "                            CohortName_to_OneCohortArgs,\n",
    "                            SPACE = SPACE, \n",
    "                            Inference_Entry = Inference_Entry,\n",
    "                            Record_Proc_Config = Record_Proc_Config,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TriggerCaseBaseName_to_CohortNameList = {\n",
    "    TriggerCaseBaseName: CohortName_list,\n",
    "}\n",
    "\n",
    "TriggerCaseBaseName_to_CohortNameList\n",
    "\n",
    "case_base = Case_Base(\n",
    "    record_base = record_base, \n",
    "    TriggerCaseBaseName_to_CohortNameList = TriggerCaseBaseName_to_CohortNameList, \n",
    "    TriggerCaseBaseName_to_TriggerCaseBaseArgs = TriggerCaseBaseName_to_TriggerCaseBaseArgs,\n",
    "    Case_Proc_Config = Case_Proc_Config,\n",
    "    Case_Args_Settings = Case_Args_Settings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CaseSetNameToCaseset = case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset[TriggerCaseBaseName]\n",
    "CaseSetNameToCaseset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, caseset in CaseSetNameToCaseset.items(): pass \n",
    "caseset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseset.ds_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = caseset.df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[CF for CF in case_base.TriggerCaseBaseName_to_CFtoCFvocab[TriggerCaseBaseName]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.base import apply_multiple_conditions\n",
    "import numpy as np \n",
    "\n",
    "def filter_data(Data, rules):\n",
    "    special_column = 'selected'\n",
    "    df_case = Data['df_case']\n",
    "    ds_case = Data['ds_case']\n",
    "\n",
    "    result = apply_multiple_conditions(df_case, rules)\n",
    "    df_case[special_column] = result\n",
    "    ds_case = ds_case.add_column(special_column, df_case[special_column].values)\n",
    "    # print(df_case.shape)\n",
    "\n",
    "    df_case_filter = df_case[df_case[special_column]].reset_index(drop=True)    \n",
    "    # print(df_case_filter.shape)\n",
    "\n",
    "    filter_array = np.array(ds_case[special_column])\n",
    "    indices = np.where(filter_array == 1)[0]\n",
    "    ds_case_filter = ds_case.select(indices)\n",
    "    # print(len(ds_case_filter))\n",
    "\n",
    "    return {'df_case': df_case_filter, 'ds_case': ds_case_filter}\n",
    "\n",
    "# Example usage\n",
    "rules = [\n",
    "    ['co.Bf24H_Food_recnum:recnum', '>=', 1],\n",
    "    # ['co.Bf24H_Carb_recnum:recnum', '>=', 1],\n",
    "]\n",
    "\n",
    "# caseset\n",
    "Data = {'df_case': caseset.df_case, 'ds_case': caseset.ds_case}\n",
    "print(Data['df_case'].shape)\n",
    "Data = filter_data(Data, rules)\n",
    "print(Data['df_case'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CF_to_CFvocab = case_base.TriggerCaseBaseName_to_CFtoCFvocab[TriggerCaseBaseName]\n",
    "print([i for i in CF_to_CFvocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: EntryFn - Input_Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "            # 'cf.TimeSparse_Bf24H', \n",
    "            # 'cf.TimeSparse_Af2H',\n",
    "            # 'cf.DietSparse_Bf24H',\n",
    "            # 'cf.DietSparse_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        # 'TimeField':   'Time',\n",
    "        # 'EventFields': [\n",
    "        #     'Diet',\n",
    "        # ],\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "}\n",
    "\n",
    "EntryInputMethod = OneEntryArgs['Input_Part']['EntryInputMethod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InputCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import datasets\n",
    "import inspect\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import itertools\n",
    "\n",
    "## %%%%%%%%%%%%%%%%%%%%% user functions\n",
    "def get_INPUT_CFs(OneEntryArgs):\n",
    "    Input_Part = OneEntryArgs['Input_Part']\n",
    "    CF_list = Input_Part['CF_list']\n",
    "    ############################ # INPUT_CFs\n",
    "    assert type(CF_list) == list, f'InputCFs must be a list, but got {type(CF_list)}'\n",
    "    # INPUT_CFs = sorted(InputCFs_Args)\n",
    "    INPUT_CFs = CF_list\n",
    "\n",
    "    InferenceMode = Input_Part['InferenceMode'] \n",
    "    BeforePeriods = Input_Part['BeforePeriods']\n",
    "    TargetField = Input_Part['TargetField']\n",
    "    if InferenceMode == 'NoFutureEvent':\n",
    "        INPUT_CFs = [i for i in INPUT_CFs if any([j in i for j in BeforePeriods])]\n",
    "    elif InferenceMode == 'WithFutureEvent':\n",
    "        INPUT_CFs = [i for i in INPUT_CFs if any([j in i for j in BeforePeriods]) or TargetField not in i]\n",
    "\n",
    "    ############################\n",
    "    return INPUT_CFs\n",
    "\n",
    "get_INPUT_CFs.fn_string = inspect.getsource(get_INPUT_CFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EntryInputMethod = OneEntryArgs['Input_Part']['EntryInputMethod']\n",
    "InputCFs = get_INPUT_CFs(OneEntryArgs)\n",
    "InputCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_case = Data['ds_case']\n",
    "ds_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ds_case.shuffle(seed=42)[:64] # .select(range(5))  \n",
    "# examples = ds_case[:4] \n",
    "pprint(examples, sort_dicts=False, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Part = OneEntryArgs['Input_Part']\n",
    "Input_Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputCFs = Input_Part['CF_list']\n",
    "InputCFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TargetCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetField = Input_Part['TargetField']\n",
    "TargetField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetCFs = [i for i in InputCFs if TargetField in i]\n",
    "TargetCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "\n",
    "s = datetime.now()\n",
    "examples_tfm = {}\n",
    "\n",
    "############################################################\n",
    "# # 0:00:00.002059\n",
    "## method 1:\n",
    "# df = pd.DataFrame({cf: examples[cf + '--input_ids'] for cf in TargetCFs})\n",
    "# df['input_ids'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "# examples_tfm['input_ids'] = torch.LongTensor(np.array(df['input_ids'].to_list())) # ().copy()\n",
    "\n",
    "\n",
    "############################################################\n",
    "# # 0:00:00.000868\n",
    "# method 2: \n",
    "# Step 1: Directly access columns as numpy arrays\n",
    "target_arrays = [np.array(examples[f\"{cf}--input_ids\"]) for cf in TargetCFs]\n",
    "# Step 2: Concatenate along columns (axis=1) to combine features\n",
    "# Assuming each array has shape (batch_size, seq_len)\n",
    "stacked_ids = np.concatenate(target_arrays, axis=1)\n",
    "examples_tfm['input_ids'] = torch.LongTensor(stacked_ids)\n",
    "# examples_tfm['input_ids'] = stacked_ids # torch.LongTensor()\n",
    "\n",
    "\n",
    "e = datetime.now()\n",
    "print(f'TargetCFs: {e-s}')\n",
    "examples_tfm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the Emptiness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_empty_values(values):\n",
    "    if len(values) == 1 and len(values[0]) == 1 and int(values[0][0]) == 0:\n",
    "        EmptyFlag = True\n",
    "    else:\n",
    "        EmptyFlag = False\n",
    "    return EmptyFlag\n",
    "detect_empty_values.fn_string = inspect.getsource(detect_empty_values)\n",
    "\n",
    "\n",
    "def update_emptiness_of_examples(examples, CF):\n",
    "    # make sure your CF is an EventCF, which means your have steps. \n",
    "    batch_to_values = examples[CF + '--input_ids']\n",
    "    batch_to_empty = [detect_empty_values(values) for values in batch_to_values]\n",
    "    examples_updated = {}\n",
    "    for items in ['input_ids', 'input_wgts', 'timestep']:\n",
    "        if f'{CF}--{items}' not in examples: continue \n",
    "        batch_to_values = examples[CF + '--' + items]\n",
    "        batch_to_values_updated = []\n",
    "        empty_value = []\n",
    "        for dp_idx, empty in enumerate(batch_to_empty):\n",
    "            if empty:\n",
    "                batch_to_values_updated.append(empty_value)\n",
    "            else:\n",
    "                batch_to_values_updated.append(batch_to_values[dp_idx])\n",
    "        examples_updated[CF + '--' + items] = batch_to_values_updated\n",
    "    return examples_updated\n",
    "update_emptiness_of_examples.fn_string = inspect.getsource(update_emptiness_of_examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfm_fn_AIInputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab):\n",
    "    \n",
    "    # s1 = datetime.now()\n",
    "    Input_Part = OneEntryArgs['Input_Part']\n",
    "    InputCFs = get_INPUT_CFs(OneEntryArgs)\n",
    "    # e1 = datetime.now()\n",
    "    # print(f'get_INPUT_CFs: {e1-s1}')\n",
    "\n",
    "    examples_tfm = {}\n",
    "    # s2 = datetime.now()\n",
    "    # ------------------------------------------------------------ # \n",
    "    TargetField = Input_Part['TargetField']\n",
    "    TargetCFs = [i for i in InputCFs if TargetField in i]\n",
    "    \n",
    "    # df = pd.DataFrame({cf: examples[cf + '--input_ids'] for cf in TargetCFs})\n",
    "    # df['input_ids'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "    # examples_tfm['input_ids'] = torch.LongTensor(np.array(df['input_ids'].to_list())) # ().copy()\n",
    "    \n",
    "    target_arrays = [np.array(examples[f\"{cf}--input_ids\"]) for cf in TargetCFs]\n",
    "    stacked_ids = np.concatenate(target_arrays, axis=1) # # Assuming each array has shape (batch_size, seq_len)\n",
    "    examples_tfm['input_ids'] = torch.LongTensor(stacked_ids)\n",
    "\n",
    "    # e2 = datetime.now()\n",
    "    # print(f'TargetField: {e2-s2}')\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------ # \n",
    "    # already ordered\n",
    "    # s3 = datetime.now()\n",
    "    EventFields = Input_Part.get('EventFields', [])\n",
    "    if len(EventFields) > 0:\n",
    "        TimeField = Input_Part.get('TimeField', None)\n",
    "        if TimeField is not None:\n",
    "            EventCFs = [i for i in InputCFs if TargetField not in i and TimeField not in i]\n",
    "        else:\n",
    "            EventCFs = [i for i in InputCFs if TargetField not in i]\n",
    "    else:\n",
    "        EventCFs = []\n",
    "    # e3 = datetime.now()\n",
    "    # print(f'Get different Field Information: {e3-s3}')\n",
    "\n",
    "    # s4 = datetime.now()\n",
    "    # update emptiness of examples\n",
    "    for EventCF in EventCFs:\n",
    "        examples_updated = update_emptiness_of_examples(examples, EventCF)\n",
    "        for k, v in examples_updated.items(): examples[k] = v\n",
    "    # e4 = datetime.now()\n",
    "    # print(f'update_emptiness_of_examples: {e4-s4}')\n",
    "\n",
    "   \n",
    "    # Multi EventCFs\n",
    "    timestep_info = None\n",
    "    for OneEvent in EventFields:\n",
    "        # s5 = datetime.now()\n",
    "        OneEventCFs = [i for i in InputCFs if OneEvent in i]\n",
    "        \n",
    "        ############################################################\n",
    "        example_event_info = {}\n",
    "        for seqtype in ['input_ids', 'input_wgts', 'timestep']:\n",
    "            columns_data = [examples[f\"{cf}--{seqtype}\"] for cf in OneEventCFs]\n",
    "            values = []\n",
    "            for sample_items in zip(*columns_data):\n",
    "                combined = list(itertools.chain(*sample_items))\n",
    "                values.append(combined)\n",
    "            example_event_info[seqtype] = values\n",
    "        ############################################################\n",
    "\n",
    "        # Precompute timestep info once per Event type\n",
    "        if timestep_info is None: timestep_info = get_timestep_info(examples, OneEventCFs)\n",
    "\n",
    "        names_orig = [i for i in example_event_info]\n",
    "        event_info_final = {name: [] for name in ['input_ids', 'input_wgts', 'timestep_orig_ids', 'event_indicators']}\n",
    "        max_timesteps = len(timestep_info['timestep_orig_ids'])\n",
    "        max_features = 0\n",
    "        for items_sample in zip(*example_event_info.values()):\n",
    "            single_data_point = dict(zip(names_orig, items_sample))\n",
    "            # s1 = datetime.now()\n",
    "            updated_data_point = update_seqtype_base_on_timestep(single_data_point, timestep_info)\n",
    "            # e1 = datetime.now()\n",
    "            # print('update_seqtype_base_on_timestep: ', e1-s1)\n",
    "            for name, value in updated_data_point.items():\n",
    "                # print(name, len(value))\n",
    "                if name == 'input_ids': max_features = max(max_features, max(len(i) for i in value))\n",
    "                event_info_final[name].append(value)\n",
    "\n",
    "\n",
    "        for seqtype in ['input_ids', 'input_wgts']:\n",
    "            values = event_info_final[seqtype]\n",
    "            values_pad = vectorized_pad(values, max_timesteps, max_features, pad_value=0)\n",
    "            event_info_final[seqtype] = values_pad\n",
    "\n",
    "        for seqtype in ['timestep_orig_ids', 'event_indicators']:\n",
    "            values = event_info_final[seqtype]\n",
    "            values_pad = np.array(values) \n",
    "            event_info_final[seqtype] = values_pad\n",
    "\n",
    "        for k, v in event_info_final.items():\n",
    "            if '_wgt' in k:\n",
    "                event_info_final[k] = torch.FloatTensor(v)\n",
    "            else:\n",
    "                event_info_final[k] = torch.LongTensor(v)\n",
    "            examples_tfm[OneEvent + '--' + k] = event_info_final[k]\n",
    "    \n",
    "        # e5 = datetime.now()\n",
    "        # print(f'Multi EventCFs -- {OneEvent}: {e5-s5}')\n",
    "\n",
    "\n",
    "    # s6 = datetime.now()\n",
    "    # ------------------------------------------------------------ # \n",
    "    TimeField = Input_Part.get('TimeField', None)\n",
    "    # TimeField\n",
    "    if TimeField is not None:\n",
    "        TimeCFs = [i for i in InputCFs if TimeField in i]\n",
    "        CFvocab = CF_to_CFvocab[TimeCFs[0]]\n",
    "        if timestep_info is None: timestep_info = get_timestep_info(examples, TimeCFs)\n",
    "\n",
    "        time_info_final = get_timestepinfo_array(examples, timestep_info, CFvocab)\n",
    "        for k, v in time_info_final.items():\n",
    "            if '_wgt' in k:\n",
    "                time_info_final[k] = torch.FloatTensor(v)\n",
    "            else:\n",
    "                time_info_final[k] = torch.LongTensor(v)\n",
    "\n",
    "            examples_tfm[TimeField + '--' + k] = time_info_final[k]\n",
    "    # e6 = datetime.now()\n",
    "    # print(f'TimeField: {e6-s6}')\n",
    "\n",
    "    return examples_tfm\n",
    "\n",
    "\n",
    "tfm_fn_AIInputData.fn_string = inspect.getsource(tfm_fn_AIInputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n==============================================\\n')\n",
    "from datetime import datetime\n",
    "s = datetime.now()\n",
    "examples_tfm = tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "e = datetime.now()\n",
    "print(f'tfm_fn_AIInputData_new: {e-s}')\n",
    "\n",
    "\n",
    "# old version\n",
    "# get_INPUT_CFs: 0:00:00.000003\n",
    "# TargetField: 0:00:00.001757\n",
    "# EventFields: 0:00:00.000003\n",
    "# update_emptiness_of_examples: 0:00:00.000056\n",
    "# Multi EventCFs -- Diet: 0:00:00.470472\n",
    "# TimeField: 0:00:00.205376\n",
    "# tfm_fn_AIInputData: 0:00:00.678363\n",
    "\n",
    "\n",
    "# Diet and Time\n",
    "# tfm_fn_AIInputData_new: 0:00:00.047536 \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in examples_tfm.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entry_fn_AIInputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_fn_AIInputData(Data, \n",
    "                         CF_to_CFvocab, \n",
    "                         OneEntryArgs,\n",
    "                         tfm_fn_AIInputData = None):\n",
    "    \n",
    "    # Input feaures. \n",
    "    # INPUT_CFs = get_INPUT_CFs(OneEntryArgs)\n",
    "    # print(INPUT_CFs)\n",
    "    transform_fn = lambda examples: tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "\n",
    "    # ds_case \n",
    "    ds_case = Data['ds_case']\n",
    "    if type(ds_case) == pd.DataFrame:\n",
    "        ds_case = datasets.Dataset.from_pandas(ds_case) \n",
    "\n",
    "    use_map = OneEntryArgs.get('use_map', False)\n",
    "    num_proc = OneEntryArgs.get('num_proc', 4)\n",
    "    if use_map == False:\n",
    "        ds_case.set_transform(transform_fn)\n",
    "    else:\n",
    "        ds_case = ds_case.map(transform_fn, batched = True, num_proc = num_proc)\n",
    "    ds_tfm = ds_case\n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    return Data\n",
    "\n",
    "tfm_fn_AIInputData.fn_string = inspect.getsource(tfm_fn_AIInputData)\n",
    "entry_fn_AIInputData.fn_string = inspect.getsource(entry_fn_AIInputData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = entry_fn_AIInputData(Data, \n",
    "                            CF_to_CFvocab, \n",
    "                            OneEntryArgs,\n",
    "                            tfm_fn_AIInputData)\n",
    "\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_tfm[:4]\n",
    "# batch\n",
    "\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create DataLoader with your actual training parameters\n",
    "loader = DataLoader(\n",
    "    dataset=ds_tfm,  # Your dataset with set_transform\n",
    "    batch_size=32,            # Use your real batch size\n",
    "    num_workers=4,            # Match your training setup\n",
    "    pin_memory=True,          # Same as training config\n",
    "    shuffle=False             # Disable for consistent measurement\n",
    ")\n",
    "\n",
    "# 2. Warm-up run (initial batches are slower due to setup)\n",
    "print(\"Warming up...\")\n",
    "for _ in loader:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# 3. Timed measurement\n",
    "num_batches = len(loader)\n",
    "print(f\"Testing with {num_batches} batches...\")\n",
    "\n",
    "start_time = time.perf_counter()  # More precise timer\n",
    "for _ in loader:\n",
    "    pass\n",
    "total_time = time.perf_counter() - start_time\n",
    "\n",
    "# 4. Calculate metrics\n",
    "throughput = num_batches / total_time\n",
    "samples_per_sec = len(ds_tfm) / total_time\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"- Batches/s: {throughput:.1f}\")\n",
    "print(f\"- Samples/s: {samples_per_sec:.1f}\")\n",
    "print(f\"- Batch time: {1000*total_time/num_batches:.1f}ms\")\n",
    "print(f\"- Total time: {total_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: EntryFn - Output_Part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TaskType = 'MLUniLabel'\n",
    "SeriesName  = 'Bf24.Af2H'\n",
    "OneTaskName = 'cgm_lhm_bf24h_af2h_5min'\n",
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_MultiTknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "            # 'cf.TimeSparse_Bf24H', \n",
    "            # 'cf.TimeSparse_Af2H',\n",
    "            # 'cf.DietSparse_Bf24H',\n",
    "            # 'cf.DietSparse_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        # 'TimeField':   'Time',\n",
    "        # 'EventFields': [\n",
    "        #     'Diet',\n",
    "        # ],\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # 'WithFutureEvent' #  # 'NoFutureEvent', 'WithFutureEvent', \n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'NTP',\n",
    "    },\n",
    "\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "        'Tagging': [],\n",
    "        'Filtering': [], \n",
    "    },\n",
    "}\n",
    "\n",
    "# Data = {'df_case': caseset.df_case, 'ds_case': caseset.ds_case}\n",
    "\n",
    "EntryOutputMethod = OneEntryArgs['Output_Part']['EntryOutputMethod']\n",
    "CF_to_CFvocab = case_base.TriggerCaseBaseName_to_CFtoCFvocab[TriggerCaseBaseName]\n",
    "print([i for i in CF_to_CFvocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%%%%%%%%%%%%%%%%%%%%\n",
    "# UniLabel\n",
    "import inspect \n",
    "import numpy as np \n",
    "# from recfldtkn.loadtools import convert_variables_to_pystirng\n",
    "\n",
    "def get_OUTPUT_CFs(OneEntryArgs):\n",
    "    if 'Output_Part' not in OneEntryArgs:\n",
    "        return []\n",
    "    else:\n",
    "        return OneEntryArgs['Output_Part'].get('CF_list', [])\n",
    "get_OUTPUT_CFs.fn_string = inspect.getsource(get_OUTPUT_CFs)\n",
    "\n",
    "\n",
    "def entry_fn_AITaskData(Data, \n",
    "                        CF_to_CFvocab, \n",
    "                        OneEntryArgs,\n",
    "                        tfm_fn_AIInputData = None,\n",
    "                        entry_fn_AIInputData = None,\n",
    "                        ):\n",
    "\n",
    "    # InputCFs = OneEntryArgs['Input_FullArgs']['INPUT_CFs_Args']['InputCFs']\n",
    "\n",
    "\n",
    "    def transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab):\n",
    "        examples_tfm = tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "        # examples_tfm['labels'] = torch.LongTensor([[i] for i in examples['Labeling']])\n",
    "        examples_tfm['labels'] = examples_tfm['input_ids'].clone() \n",
    "        return examples_tfm\n",
    "    \n",
    "    transform_fn = lambda examples: transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab)\n",
    "    ds_case = Data['ds_case']\n",
    "\n",
    "    if type(ds_case) == pd.DataFrame:\n",
    "        ds_case = datasets.Dataset.from_pandas(ds_case)\n",
    "        \n",
    "    # ds_case.set_transform(transform_fn)\n",
    "    use_map = OneEntryArgs.get('use_map', False)\n",
    "    num_proc = OneEntryArgs.get('num_proc', 4)\n",
    "    if use_map == False:\n",
    "        ds_case.set_transform(transform_fn)\n",
    "    else:\n",
    "        ds_case = ds_case.map(transform_fn, batched = True, num_proc = num_proc)\n",
    "\n",
    "    ds_tfm = ds_case\n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    \n",
    "    return Data\n",
    "\n",
    "entry_fn_AITaskData.fn_string = inspect.getsource(entry_fn_AITaskData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = entry_fn_AITaskData(Data, \n",
    "                           CF_to_CFvocab, \n",
    "                           OneEntryArgs,\n",
    "                           tfm_fn_AIInputData,\n",
    "                           entry_fn_AIInputData)\n",
    "\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_tfm[:4]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from recfldtkn.base import Base\n",
    "# from recfldtkn.aidata_base.entry import AIDATA_ENTRYOUTPUT_PATH\n",
    "\n",
    "# prefix = [\n",
    "#     'import torch',\n",
    "#     'import pandas as pd', \n",
    "#     'import numpy as np', \n",
    "#     'import datasets',\n",
    "#     ]\n",
    "# fn_variables = [\n",
    "#     get_OUTPUT_CFs,\n",
    "#     entry_fn_AITaskData,\n",
    "# ]\n",
    "# pycode = Base.convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "# pypath = os.path.join(SPACE['CODE_FN'], AIDATA_ENTRYOUTPUT_PATH, f'{EntryOutputMethod}.py')\n",
    "# print(pypath)\n",
    "# if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "# with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create DataLoader with your actual training parameters\n",
    "loader = DataLoader(\n",
    "    dataset=ds_tfm,  # Your dataset with set_transform\n",
    "    batch_size=32,            # Use your real batch size\n",
    "    num_workers=4,            # Match your training setup\n",
    "    pin_memory=True,          # Same as training config\n",
    "    shuffle=False             # Disable for consistent measurement\n",
    ")\n",
    "\n",
    "# 2. Warm-up run (initial batches are slower due to setup)\n",
    "print(\"Warming up...\")\n",
    "for _ in loader:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# 3. Timed measurement\n",
    "num_batches = len(loader)\n",
    "print(f\"Testing with {num_batches} batches...\")\n",
    "\n",
    "start_time = time.perf_counter()  # More precise timer\n",
    "for _ in loader:\n",
    "    pass\n",
    "total_time = time.perf_counter() - start_time\n",
    "\n",
    "# 4. Calculate metrics\n",
    "throughput = num_batches / total_time\n",
    "samples_per_sec = len(ds_tfm) / total_time\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"- Batches/s: {throughput:.1f}\")\n",
    "print(f\"- Samples/s: {samples_per_sec:.1f}\")\n",
    "print(f\"- Batch time: {1000*total_time/num_batches:.1f}ms\")\n",
    "print(f\"- Total time: {total_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}