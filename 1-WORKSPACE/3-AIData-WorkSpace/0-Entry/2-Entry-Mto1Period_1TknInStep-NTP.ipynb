{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. AIData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oneday: 288, 24pd. 1/12\n",
    "from datasets import load_from_disk\n",
    "\n",
    "AIDataName = 'CGM_32h_24pd_WellDoc_v2' # v2 6 cohorts. \n",
    "path = os.path.join(SPACE['DATA_AIDATA'], AIDataName)\n",
    "print(path)\n",
    "dataset = load_from_disk(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = {\n",
    "    'ds_case': dataset,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dataset.info.__dict__['config_name']# .features['cf'].feature.vocab\n",
    "print([i for i in config])\n",
    "CF_to_CFvocab = config['CF_to_CFvocab']\n",
    "print([i for i in CF_to_CFvocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: EntryFn - Input_Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_1TknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # True, # True, # False, # True, \n",
    "    }, \n",
    "}\n",
    "\n",
    "EntryInputMethod = OneEntryArgs['Input_Part']['EntryInputMethod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import datasets\n",
    "import inspect\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "## %%%%%%%%%%%%%%%%%%%%% user functions\n",
    "def get_INPUT_CFs(OneEntryArgs):\n",
    "    Input_Part = OneEntryArgs['Input_Part']\n",
    "    CF_list = Input_Part['CF_list']\n",
    "    ############################ # INPUT_CFs\n",
    "    assert type(CF_list) == list, f'InputCFs must be a list, but got {type(CF_list)}'\n",
    "    # INPUT_CFs = sorted(InputCFs_Args)\n",
    "    INPUT_CFs = CF_list\n",
    "\n",
    "    InferenceMode = Input_Part['InferenceMode'] \n",
    "    BeforePeriods = Input_Part['BeforePeriods']\n",
    "    # TargetField = Input_Part['TargetField']\n",
    "    if InferenceMode == True:\n",
    "        INPUT_CFs = [i for i in INPUT_CFs if any([j in i for j in BeforePeriods])]\n",
    "\n",
    "    ############################\n",
    "    return INPUT_CFs\n",
    "\n",
    "\n",
    "def tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab):\n",
    "    INPUT_CFs = get_INPUT_CFs(OneEntryArgs)\n",
    "    examples_tfm = {}\n",
    "    df = pd.DataFrame({cf: examples[cf + '--input_ids'] for cf in INPUT_CFs})\n",
    "    df['input_ids'] = df.apply(lambda x: list(itertools.chain(*x.values)), axis=1)\n",
    "    examples_tfm['input_ids'] = torch.LongTensor(np.array(df['input_ids'].to_list())) # ().copy()\n",
    "    # move this part to the TaskPart. \n",
    "    # examples_tfm['labels'] = torch.LongTensor(np.array(df['input_ids'].to_list().copy()))\n",
    "    return examples_tfm\n",
    "\n",
    "\n",
    "def entry_fn_AIInputData(Data, \n",
    "                         CF_to_CFvocab, \n",
    "                         OneEntryArgs,\n",
    "                         tfm_fn_AIInputData = None):\n",
    "    \n",
    "    # Input feaures. \n",
    "    # INPUT_CFs = get_INPUT_CFs(OneEntryArgs)\n",
    "    # print(INPUT_CFs)\n",
    "    transform_fn = lambda examples: tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "\n",
    "    # ds_case \n",
    "    ds_case = Data['ds_case']\n",
    "    if type(ds_case) == pd.DataFrame:\n",
    "        ds_case = datasets.Dataset.from_pandas(ds_case) \n",
    "    ds_case.set_transform(transform_fn)\n",
    "    ds_tfm = ds_case\n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    return Data\n",
    "\n",
    "\n",
    "get_INPUT_CFs.fn_string = inspect.getsource(get_INPUT_CFs)\n",
    "tfm_fn_AIInputData.fn_string = inspect.getsource(tfm_fn_AIInputData)\n",
    "entry_fn_AIInputData.fn_string = inspect.getsource(entry_fn_AIInputData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = entry_fn_AIInputData(Data, \n",
    "                            CF_to_CFvocab, \n",
    "                            OneEntryArgs,\n",
    "                            tfm_fn_AIInputData)\n",
    "\n",
    "\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_tfm[:4]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Save Entry Fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.entry import AIDATA_ENTRYINPUT_PATH\n",
    "from recfldtkn.base import Base\n",
    "\n",
    "pypath = os.path.join(SPACE['CODE_FN'],  AIDATA_ENTRYINPUT_PATH, f'{EntryInputMethod}.py')\n",
    "# print(pypath) \n",
    "\n",
    "prefix = [\n",
    "    'import itertools',\n",
    "    'import pandas as pd', \n",
    "    'import numpy as np', \n",
    "    'import datasets',\n",
    "    'import torch',\n",
    "    'import datasets',\n",
    "    ]\n",
    "\n",
    "fn_variables = [\n",
    "    get_INPUT_CFs,\n",
    "    tfm_fn_AIInputData,\n",
    "    entry_fn_AIInputData,\n",
    "]\n",
    "\n",
    "pycode = Base.convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "\n",
    "print(pypath)\n",
    "if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: EntryFn - Output_Part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TaskType = 'MLUniLabel'\n",
    "SeriesName  = 'Bf24.Af2H'\n",
    "\n",
    "OneTaskName = 'cgm_bf24h_af2h_5min'\n",
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'Mto1Period_1TknInStep',\n",
    "        'CF_list': [\n",
    "            'cf.TargetCGM_Bf24H',\n",
    "            'cf.TargetCGM_Af2H',\n",
    "        ],\n",
    "        'TargetField': 'TargetCGM',\n",
    "        'BeforePeriods': ['Bf24H'],\n",
    "        'AfterPeriods': ['Af2H'],\n",
    "        'InferenceMode': False, # True, # True, # False, # True, \n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'NTP',\n",
    "        'set_transform': True,\n",
    "    },\n",
    "\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "        'Tagging': [],\n",
    "        'Filtering': [], \n",
    "    },\n",
    "}\n",
    "\n",
    "# Data = {'df_case': caseset.df_case, 'ds_case': caseset.ds_case}\n",
    "\n",
    "EntryOutputMethod = OneEntryArgs['Output_Part']['EntryOutputMethod']\n",
    "print([i for i in CF_to_CFvocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%%%%%%%%%%%%%%%%%%%%\n",
    "# UniLabel\n",
    "import inspect \n",
    "import numpy as np \n",
    "# from recfldtkn.loadtools import convert_variables_to_pystirng\n",
    "\n",
    "\n",
    "def get_OUTPUT_CFs(OneEntryArgs):\n",
    "    if 'Output_Part' not in OneEntryArgs:\n",
    "        return []\n",
    "    else:\n",
    "        return OneEntryArgs['Output_Part'].get('CF_list', [])\n",
    "get_OUTPUT_CFs.fn_string = inspect.getsource(get_OUTPUT_CFs)\n",
    "\n",
    "\n",
    "def entry_fn_AITaskData(Data, \n",
    "                        CF_to_CFvocab, \n",
    "                        OneEntryArgs,\n",
    "                        tfm_fn_AIInputData = None,\n",
    "                        entry_fn_AIInputData = None,\n",
    "                        ):\n",
    "\n",
    "    # InputCFs = OneEntryArgs['Input_FullArgs']['INPUT_CFs_Args']['InputCFs']\n",
    "\n",
    "\n",
    "    def transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab):\n",
    "        examples_tfm = tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "        # examples_tfm['labels'] = torch.LongTensor([[i] for i in examples['Labeling']])\n",
    "        examples_tfm['labels'] = examples_tfm['input_ids'].clone() \n",
    "        return examples_tfm\n",
    "    \n",
    "    transform_fn = lambda examples: transform_fn_output(examples, tfm_fn_AIInputData, OneEntryArgs, CF_to_CFvocab)\n",
    "    ds_case = Data['ds_case']\n",
    "\n",
    "    if type(ds_case) == pd.DataFrame:\n",
    "        ds_case = datasets.Dataset.from_pandas(ds_case)\n",
    "        \n",
    "    ####### You can either set transform, or map it. \n",
    "    if OneEntryArgs['Output_Part']['set_transform'] == True:\n",
    "        ds_case.set_transform(transform_fn)\n",
    "    else:\n",
    "        ds_case = ds_case.map(transform_fn)\n",
    "    ds_tfm = ds_case\n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    return Data\n",
    "\n",
    "entry_fn_AITaskData.fn_string = inspect.getsource(entry_fn_AITaskData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = entry_fn_AITaskData(Data, \n",
    "                           CF_to_CFvocab, \n",
    "                           OneEntryArgs,\n",
    "                           tfm_fn_AIInputData,\n",
    "                           entry_fn_AIInputData)\n",
    "\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_tfm[:4]\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.base import Base\n",
    "from recfldtkn.aidata_base.entry import AIDATA_ENTRYOUTPUT_PATH\n",
    "\n",
    "prefix = [\n",
    "    'import torch',\n",
    "    'import pandas as pd', \n",
    "    'import numpy as np', \n",
    "    'import datasets',\n",
    "    ]\n",
    "fn_variables = [\n",
    "    get_OUTPUT_CFs,\n",
    "    entry_fn_AITaskData,\n",
    "]\n",
    "pycode = Base.convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "pypath = os.path.join(SPACE['CODE_FN'], AIDATA_ENTRYOUTPUT_PATH, f'{EntryOutputMethod}.py')\n",
    "print(pypath)\n",
    "if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}