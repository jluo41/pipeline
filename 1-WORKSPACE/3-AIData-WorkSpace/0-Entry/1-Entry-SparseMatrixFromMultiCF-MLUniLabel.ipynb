{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd \n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "KEY = 'WorkSpace'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0] + KEY\n",
    "# print(WORKSPACE_PATH)\n",
    "os.chdir(WORKSPACE_PATH)\n",
    "import sys\n",
    "from proj_space import SPACE\n",
    "sys.path.append(SPACE['CODE_FN'])\n",
    "SPACE['WORKSPACE_PATH'] = WORKSPACE_PATH\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Record and Case Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_case.GROUP import GROUP_TO_GROUPMethodArgs\n",
    "from config.config_case.CF import CF_to_CFArgs\n",
    "from config.config_case.CKPD import Ckpd_to_CkpdObsConfig\n",
    "from config.config_case.TagRec import TagRec_to_TagRecArgs\n",
    "from config.config_case.TagCF import TagCF_to_TagCFArgs \n",
    "from config.config_case.Flt import FltName_to_FltArgs\n",
    "from config.config_case.CASE import TriggerCaseBaseName_to_TriggerCaseBaseArgs\n",
    "\n",
    "from config.config_record.Cohort import CohortName_to_OneCohortArgs\n",
    "from config.config_case.CKPD import Ckpd_to_CkpdObsConfig\n",
    "\n",
    "from recfldtkn.record_base import Record_Base\n",
    "from recfldtkn.case_base.case_base import Case_Base\n",
    "\n",
    "CohortNames = [i for i in CohortName_to_OneCohortArgs.keys()]\n",
    "print(CohortNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "Inference_Entry = None # this is not inference mode\n",
    "Case_Args_Settings = {\n",
    "    'Ckpd_to_CkpdObsConfig': Ckpd_to_CkpdObsConfig,\n",
    "    'CF_to_CFArgs': CF_to_CFArgs,\n",
    "    'TagCF_to_TagCFArgs': TagCF_to_TagCFArgs,\n",
    "    'TagRec_to_TagRecArgs': TagRec_to_TagRecArgs,\n",
    "    'FltName_to_FltArgs': FltName_to_FltArgs,\n",
    "    'GROUP_TO_GROUPMethodArgs': GROUP_TO_GROUPMethodArgs,\n",
    "}\n",
    "\n",
    "Record_Proc_Config = {\n",
    "    'save_data': True, \n",
    "    'load_data':True, \n",
    "    'via_method': 'ds',\n",
    "}\n",
    "\n",
    "Case_Proc_Config = {\n",
    "    'max_trigger_case_num': None, \n",
    "    'use_task_cache': False, \n",
    "    'caseset_chunk_size': 10000, # 200k for CGM, 50k for others.\n",
    "    'save_data': True, \n",
    "    'load_data': True, \n",
    "    'load_casecollection': True,\n",
    "    'via_method': 'ds',\n",
    "    'n_cpus': 4, \n",
    "    'batch_size': 1000,  \n",
    "}\n",
    "###################################  \n",
    "\n",
    "CohortName_list = [ \n",
    "    'WellDoc2023CVSDeRx',\n",
    "]\n",
    "\n",
    "TriggerCaseBaseName = 'WeightEntry-FutureWeightAndMultiHistoricalEgm'\n",
    "TriggerCaseBaseArgs = {\n",
    "    'Trigger': {\n",
    "        'TriggerName': 'WeightEntry', \n",
    "        'TagRec': [\n",
    "            'TagRec.PDemoFromP',\n",
    "        ],\n",
    "        'Filter': 'FltBasicDemo',\n",
    "        'Group': 'GrpGenderDisease', # <--- get CaseSetName_to_CaseSet \n",
    "        'ObsTask': {\n",
    "            'TagCF_list': [\n",
    "                'TagCF.FutureWeightInfo', \n",
    "            ],\n",
    "            'CF_list':  [\n",
    "                'cf.PDemo',\n",
    "                'cf.Bf1mRecNum',\n",
    "                'cf.Bf24hCGMFeat',\n",
    "                'cf.Bf24hMedalFeat',\n",
    "                'cf.Bf1mMedalFeat',\n",
    "                'cf.Bf2mMedalFeat',\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "}\n",
    "TriggerCaseBaseName_to_TriggerCaseBaseArgs[TriggerCaseBaseName] = TriggerCaseBaseArgs\n",
    "pprint(TriggerCaseBaseArgs, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.check import update_and_assert_CaseInfo\n",
    "from recfldtkn.check import retrive_pipeline_info\n",
    "PIPELINE_INFO = retrive_pipeline_info(SPACE)\n",
    "\n",
    "\n",
    "CaseSettingInfo = update_and_assert_CaseInfo(\n",
    "                                TriggerCaseBaseName,\n",
    "                                TriggerCaseBaseArgs,\n",
    "                                Case_Args_Settings,\n",
    "                                Case_Proc_Config, \n",
    "                                PIPELINE_INFO, \n",
    "                                )\n",
    "\n",
    "HumanRecordRecfeat_Args = CaseSettingInfo['HumanRecordRecfeat_Args']\n",
    "record_base = Record_Base(CohortName_list, \n",
    "                            HumanRecordRecfeat_Args,\n",
    "                            CohortName_to_OneCohortArgs,\n",
    "                            SPACE = SPACE, \n",
    "                            Inference_Entry = Inference_Entry,\n",
    "                            Record_Proc_Config = Record_Proc_Config,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TriggerCaseBaseName_to_CohortNameList = {\n",
    "    TriggerCaseBaseName: CohortName_list,\n",
    "}\n",
    "\n",
    "TriggerCaseBaseName_to_CohortNameList\n",
    "\n",
    "case_base = Case_Base(\n",
    "    record_base = record_base, \n",
    "    TriggerCaseBaseName_to_CohortNameList = TriggerCaseBaseName_to_CohortNameList, \n",
    "    TriggerCaseBaseName_to_TriggerCaseBaseArgs = TriggerCaseBaseName_to_TriggerCaseBaseArgs,\n",
    "    Case_Proc_Config = Case_Proc_Config,\n",
    "    Case_Args_Settings = Case_Args_Settings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CaseSetNameToCaseset = case_base.TriggerCaseBaseName_to_CaseSetNameToCaseset[TriggerCaseBaseName]\n",
    "CaseSetNameToCaseset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, caseset in CaseSetNameToCaseset.items(): break \n",
    "\n",
    "caseset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseset.ds_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[CF for CF in case_base.TriggerCaseBaseName_to_CFtoCFvocab[TriggerCaseBaseName]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: EntryFn - Input_Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'SparseMatrixFromMultiCF',\n",
    "        'CF_list': [\n",
    "            'cf.PDemo',\n",
    "            'cf.Bf1mRecNum',\n",
    "            'cf.Bf24hCGMFeat',\n",
    "            'cf.Bf24hMedalFeat',\n",
    "            'cf.Bf1mMedalFeat',\n",
    "            'cf.Bf2mMedalFeat',\n",
    "        ],\n",
    "        # 'BeforePeriods': ['Bf24H'],\n",
    "        # 'AfterPeriods': ['Af2H'],\n",
    "        # 'InferenceMode': False, \n",
    "    }, \n",
    "}\n",
    "\n",
    "EntryInputMethod = OneEntryArgs['Input_Part']['EntryInputMethod']\n",
    "\n",
    "# caseset\n",
    "Data = {'df_case': caseset.df_case, 'ds_case': caseset.ds_case}\n",
    "\n",
    "CF_to_CFvocab = case_base.TriggerCaseBaseName_to_CFtoCFvocab[TriggerCaseBaseName]\n",
    "print([i for i in CF_to_CFvocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import itertools\n",
    "\n",
    "\n",
    "## %%%%%%%%%%%%%%%%%%%%% user functions\n",
    "def tfm_fn_AIInputData(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "def get_INPUT_CFs(OneEntryArgs):\n",
    "    Input_Part = OneEntryArgs['Input_Part']\n",
    "    CF_list = Input_Part['CF_list']\n",
    "    ############################ # INPUT_CFs\n",
    "    # assert type(InputCFs_Args) == list, f'InputCFs_Args must be a list, but got {type(InputCFs_Args)}'\n",
    "    INPUT_CFs = sorted(CF_list) # why sorted here?\n",
    "    ############################\n",
    "    return INPUT_CFs\n",
    "    \n",
    "\n",
    "def entry_fn_AIInputData(Data, \n",
    "                         CF_to_CFvocab, \n",
    "                         OneEntryArgs,\n",
    "                         tfm_fn_AIInputData = None):\n",
    "\n",
    "    ds_case = Data['ds_case']\n",
    "    # Input feaures. \n",
    "    \n",
    "    INPUT_CFs = get_INPUT_CFs(OneEntryArgs)\n",
    "    # print('\\n\\n\\n\\n ---------- INPUT_CFs\" {} --------- \\n\\n\\n\\n'.format(INPUT_CFs))\n",
    "    \n",
    "    \n",
    "    accumulated_matrices = []  # Initialize a list to accumulate the sparse matrices\n",
    "    for INPUT_CF in INPUT_CFs:\n",
    "        CF_vocab = CF_to_CFvocab[INPUT_CF]\n",
    "        \n",
    "        tid2tkn = CF_vocab['input_ids']['tid2tkn']\n",
    "        num_features = len(tid2tkn)\n",
    "\n",
    "        # tid2tkn_filter = EntryArgs.get('tid2tkn_filter', None)\n",
    "        input_ids_name  = f'{INPUT_CF}--input_ids'\n",
    "        input_wgts_name = f'{INPUT_CF}--input_wgts'\n",
    "\n",
    "        col_indices = list(itertools.chain(*[          tid  for i,   tid in enumerate(ds_case[input_ids_name])]))\n",
    "        row_indices = list(itertools.chain(*[[i] * len(tid) for i,   tid in enumerate(ds_case[input_ids_name])]))\n",
    "        data        = list(itertools.chain(*[          wgt  for tid, wgt in zip(ds_case[input_ids_name], ds_case[input_wgts_name])]))\n",
    "        \n",
    "        sparse_matrix_value = (data, (row_indices, col_indices))\n",
    "        shape = (len(ds_case), num_features)\n",
    "        X = csr_matrix(sparse_matrix_value, shape=shape)\n",
    "        \n",
    "        # Inside your loop, after creating each X, append it to the list:\n",
    "        accumulated_matrices.append(X)\n",
    "\n",
    "    # After the loop, concatenate all sparse matrices horizontally\n",
    "    X = hstack(accumulated_matrices, format='csr')\n",
    "\n",
    "    ds_tfm = {'X': X}\n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    return Data\n",
    "\n",
    "\n",
    "get_INPUT_CFs.fn_string = inspect.getsource(get_INPUT_CFs)\n",
    "tfm_fn_AIInputData.fn_string = inspect.getsource(tfm_fn_AIInputData)\n",
    "entry_fn_AIInputData.fn_string = inspect.getsource(entry_fn_AIInputData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = entry_fn_AIInputData(Data, \n",
    "                            CF_to_CFvocab, \n",
    "                            OneEntryArgs,\n",
    "                            tfm_fn_AIInputData)\n",
    "\n",
    "\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Save Entry Fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.entry import AIDATA_ENTRYINPUT_PATH\n",
    "from recfldtkn.base import Base\n",
    "\n",
    "pypath = os.path.join(SPACE['CODE_FN'],  AIDATA_ENTRYINPUT_PATH, f'{EntryInputMethod}.py')\n",
    "print(pypath) \n",
    "\n",
    "prefix = [\n",
    "    'import itertools',\n",
    "    'import pandas as pd', \n",
    "    'import numpy as np', \n",
    "    'import datasets',\n",
    "    'from scipy.sparse import csr_matrix, hstack',\n",
    "    ]\n",
    "\n",
    "fn_variables = [\n",
    "    get_INPUT_CFs,\n",
    "    tfm_fn_AIInputData,\n",
    "    entry_fn_AIInputData,\n",
    "]\n",
    "\n",
    "pycode = Base.convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "\n",
    "# print(pypath)\n",
    "if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: EntryFn - Output_Part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TaskType = 'MLUniLabel'\n",
    "SeriesName  = 'weightpred.Af1M'\n",
    "\n",
    "OneTaskName = 'WeightPred.Af1M.WeightLossPctLarge2'\n",
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': 'SparseMatrixFromMultiCF',\n",
    "        'CF_list': [\n",
    "            'cf.PDemo',\n",
    "            'cf.Bf1mRecNum',\n",
    "            'cf.Bf24hCGMFeat',\n",
    "            'cf.Bf24hMedalFeat',\n",
    "            'cf.Bf1mMedalFeat',\n",
    "            'cf.Bf2mMedalFeat',\n",
    "        ],\n",
    "    }, \n",
    "\n",
    "    # ----------------- Output Part -----------------\n",
    "    'Output_Part': {\n",
    "        'EntryOutputMethod': 'MLUniLabel',\n",
    "        'TagCF_list': [\n",
    "            'TagCF.FutureWeightInfo', \n",
    "        ], \n",
    "        'Labeling': ('co.Weight_Af1Minfo:weight_loss_pct', '>', 0.02), \n",
    "    },\n",
    "\n",
    "\n",
    "    # ----------------- Task Part -----------------\n",
    "    'Task_Part': {\n",
    "        'Tagging': [],\n",
    "        'Filtering': [\n",
    "            ('co.Weight_Af1Minfo:no_future_weight', '!=', 1),\n",
    "        ], \n",
    "    },\n",
    "}\n",
    "\n",
    "# EntryInputMethod = OneEntryArgs['EntryInputMethod']\n",
    "EntryOutputMethod = OneEntryArgs['Output_Part']['EntryOutputMethod']\n",
    "# caseset\n",
    "Data = {'df_case': caseset.df_case, 'ds_case': caseset.ds_case}\n",
    "\n",
    "CF_to_CFvocab = case_base.TriggerCaseBaseName_to_CFtoCFvocab[TriggerCaseBaseName]\n",
    "print([i for i in CF_to_CFvocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%%%%%%%%%%%%%%%%%%%%\n",
    "# UniLabel\n",
    "import inspect \n",
    "import numpy as np \n",
    "# from recfldtkn.loadtools import convert_variables_to_pystirng\n",
    "\n",
    "\n",
    "def get_OUTPUT_CFs(OneEntryArgs):\n",
    "    if 'Output_Part' not in OneEntryArgs:\n",
    "        return []\n",
    "    else:\n",
    "        return OneEntryArgs['Output_Part'].get('CF_list', [])\n",
    "get_OUTPUT_CFs.fn_string = inspect.getsource(get_OUTPUT_CFs)\n",
    "\n",
    "\n",
    "def entry_fn_AITaskData(Data, \n",
    "                        CF_to_CFvocab, \n",
    "                        OneEntryArgs,\n",
    "                        tfm_fn_AIInputData = None,\n",
    "                        entry_fn_AIInputData = None,\n",
    "                        ):\n",
    "\n",
    "    Data = entry_fn_AIInputData(Data, CF_to_CFvocab, OneEntryArgs, tfm_fn_AIInputData) \n",
    "    \n",
    "    \n",
    "    Output_Part = OneEntryArgs['Output_Part']\n",
    "    Labeling = Output_Part['Labeling']\n",
    "    # assert type(Labeling) == tuple, f'Labeling must be a tuple, but got {type(Labeling)}'\n",
    "    assert len(Labeling) == 3, f'Labeling must have 3 elements, but got {len(Labeling)}'\n",
    "    label_name, label_op, label_value = Labeling\n",
    "    df_case = Data['df_case']\n",
    "    \n",
    "    if label_op == '>':\n",
    "        Y = df_case[label_name] > label_value\n",
    "    elif label_op == '<':\n",
    "        Y = df_case[label_name] < label_value\n",
    "    elif label_op == '==':\n",
    "        Y = df_case[label_name] == label_value\n",
    "    elif label_op == 'in':\n",
    "        Y = df_case[label_name].isin(label_value)\n",
    "    else:\n",
    "        raise ValueError(f'Invalid label_op: {label_op}')\n",
    "    \n",
    "    Y = Y.astype(int).values\n",
    "    ds_tfm = Data['ds_tfm']\n",
    "    ds_tfm['Y'] = Y\n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    return Data\n",
    "\n",
    "entry_fn_AITaskData.fn_string = inspect.getsource(entry_fn_AITaskData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = entry_fn_AITaskData(Data, \n",
    "                           CF_to_CFvocab, \n",
    "                           OneEntryArgs,\n",
    "                           tfm_fn_AIInputData,\n",
    "                           entry_fn_AIInputData)\n",
    "\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tfm['Y'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.base import Base\n",
    "from recfldtkn.aidata_base.entry import AIDATA_ENTRYOUTPUT_PATH\n",
    "\n",
    "prefix = [\n",
    "    'import torch',\n",
    "    'import pandas as pd', \n",
    "    'import numpy as np', \n",
    "    'import datasets'\n",
    "    ]\n",
    "fn_variables = [\n",
    "    get_OUTPUT_CFs,\n",
    "    entry_fn_AITaskData,\n",
    "]\n",
    "pycode = Base.convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "pypath = os.path.join(SPACE['CODE_FN'], AIDATA_ENTRYOUTPUT_PATH, f'{EntryOutputMethod}.py')\n",
    "print(pypath)\n",
    "if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}