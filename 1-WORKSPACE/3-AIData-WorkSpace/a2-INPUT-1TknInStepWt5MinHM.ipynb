{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import logging\n",
    "import pandas as pd\n",
    "from pprint import pprint \n",
    "from IPython.display import display, HTML\n",
    "\n",
    "KEY = '1-WORKSPACE'\n",
    "WORKSPACE_PATH = os.getcwd().split(KEY)[0]\n",
    "print(WORKSPACE_PATH); os.chdir(WORKSPACE_PATH)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='[%(levelname)s:%(asctime)s:(%(filename)s@%(lineno)d %(name)s)]: %(message)s')\n",
    "\n",
    "SPACE = {\n",
    "    'DATA_RAW': f'_Data/0-Data_Raw',\n",
    "    'DATA_RFT': f'_Data/1-Data_RFT',\n",
    "    'DATA_CASE': f'_Data/2-Data_CASE',\n",
    "    'DATA_AIDATA': f'_Data/3-Data_AIDATA',\n",
    "    'DATA_EXTERNAL': f'code/external',\n",
    "    'CODE_FN': f'code/pipeline', \n",
    "}\n",
    "assert os.path.exists(SPACE['CODE_FN']), f'{SPACE[\"CODE_FN\"]} not found'\n",
    "\n",
    "print(SPACE['CODE_FN'])\n",
    "sys.path.append(SPACE['CODE_FN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.entry import EntryAIData_Builder\n",
    "import datasets\n",
    "\n",
    "OneAIDataName = 'DietEventBench'\n",
    "CF_DataName = 'DietEvent-CGM5MinEntry-1ea9d787eef20fb7'\n",
    "CohortName_list = ['WellDoc2022CGM']\n",
    "CF_DataName_list = [f'{i}/{CF_DataName}' for i in CohortName_list]\n",
    "\n",
    "\n",
    "entry = EntryAIData_Builder(SPACE = SPACE)\n",
    "\n",
    "dataset = entry.merge_one_cf_dataset(CF_DataName_list)\n",
    "data_config = dataset.info.config_name \n",
    "print('total', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFName = 'HM5MinStep'\n",
    "\n",
    "interval_delta = pd.Timedelta(minutes=5)\n",
    "idx2tkn = [\n",
    "    pd.Timestamp('2022-01-01 00:00:00') + interval_delta * i for i in range(24 * 12)\n",
    "]\n",
    "idx2tkn = [f'{i.hour:02d}:{i.minute:02d}' for i in idx2tkn]\n",
    "tkn2idx = {tkn: idx for idx, tkn in enumerate(idx2tkn)}\n",
    "CF_to_CFvocab = data_config['CF_to_CFvocab']\n",
    "CF_to_CFvocab[CFName] = {'idx2tkn': idx2tkn, 'tkn2idx': tkn2idx, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CF_to_CFvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### should be a split here #######\n",
    "Data = {'ds_case': dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT: Mto1Period_1TknInStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneEntryArgs = {\n",
    "    # ----------------- Input Part -----------------\n",
    "    'Input_Part': {\n",
    "        'EntryInputMethod': '1TknInStepWt5MinHM',\n",
    "        'CF_list': [\n",
    "            'CGMValueBf24h',\n",
    "            # 'CGMValueAf2h',\n",
    "        ],\n",
    "        'BeforePeriods': ['Bf24h'],\n",
    "        # 'AfterPeriods': ['Af2h'],\n",
    "        'TimeIndex': True, \n",
    "        'InferenceMode': False, # True, # True, # False, # True, \n",
    "        'TargetField': 'CGMValue',\n",
    "        'TargetRange': [40, 400],\n",
    "        # 'HM': None, \n",
    "        'HM': {'start': -24, 'unit': 'h', 'interval': '5m'},\n",
    "    }, \n",
    "}\n",
    "\n",
    "EntryInputMethod = OneEntryArgs['Input_Part']['EntryInputMethod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "import inspect\n",
    "\n",
    "\n",
    "## %%%%%%%%%%%%%%%%%%%%% user functions\n",
    "def get_INPUT_CFs(OneEntryArgs):\n",
    "    Input_Part = OneEntryArgs['Input_Part']\n",
    "    CF_list = Input_Part['CF_list']\n",
    "    ############################ # INPUT_CFs\n",
    "    assert type(CF_list) == list, f'InputCFs must be a list, but got {type(CF_list)}'\n",
    "    # INPUT_CFs = sorted(InputCFs_Args)\n",
    "    INPUT_CFs = CF_list\n",
    "\n",
    "    InferenceMode = Input_Part['InferenceMode'] \n",
    "    BeforePeriods = Input_Part['BeforePeriods']\n",
    "    # TargetField = Input_Part['TargetField']\n",
    "    if InferenceMode == True:\n",
    "        INPUT_CFs = [i for i in INPUT_CFs if any([j in i for j in BeforePeriods])]\n",
    "\n",
    "    ############################\n",
    "    return INPUT_CFs\n",
    "\n",
    "get_INPUT_CFs.fn_string = inspect.getsource(get_INPUT_CFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import torch \n",
    "import numpy as np \n",
    "\n",
    "## %%%%%%%%%%%%%%%%%%%%% user functions\n",
    "import itertools\n",
    "\n",
    "def tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab):\n",
    "    # 1. grab your input CF names and the target\u2010range bounds\n",
    "    INPUT_CFs    = get_INPUT_CFs(OneEntryArgs)                           # e.g. ['CGMValueBf24h', \u2026]\n",
    "    low, high    = OneEntryArgs['Input_Part']['TargetRange']             # e.g. [40, 400]\n",
    "\n",
    "    # 2. pull out the raw \"--tid\" lists for each CF\n",
    "    #    examples[f\"{cf}--tid\"] is assumed to be a list of lists (len = batch size)\n",
    "    tid_lists = [examples[f\"{cf}--tid\"] for cf in INPUT_CFs]\n",
    "\n",
    "    # 3. for each example in the batch, clamp each sequence to [low,high] and flatten\n",
    "    #    we do this all in Python lists + numpy.clip, which is far faster than DataFrame/apply\n",
    "    flat_seqs = []\n",
    "    for per_cf_seqs in zip(*tid_lists):\n",
    "        # per_cf_seqs is a tuple like (seq_cf1, seq_cf2, \u2026) for one example\n",
    "        clamped = []\n",
    "        for seq in per_cf_seqs:\n",
    "            # numpy.clip can work on any sequence type\n",
    "            arr = np.clip(seq, low, high)\n",
    "            clamped.extend(arr.tolist())\n",
    "        flat_seqs.append(clamped)\n",
    "\n",
    "    # 4. stack into one LongTensor [batch_size, total_seq_length]\n",
    "    input_ids = torch.tensor(flat_seqs, dtype=torch.long)\n",
    "\n",
    "    # length_each_cf = [len(i) for i in tid_lists[0]]\n",
    "    now_list = examples['ObsDT']\n",
    "    HM_seq_list = []\n",
    "    HM_args = OneEntryArgs['Input_Part'].get('HM', None)\n",
    "\n",
    "\n",
    "    CFName = 'HM5MinStep'\n",
    "\n",
    "    # columns_tid = [i for i in examples if '--tid' in i and CFName in i]\n",
    "    \n",
    "    tkn2idx = CF_to_CFvocab[CFName]['tkn2idx']\n",
    "    if HM_args is not None:\n",
    "        HM_start = HM_args['start']\n",
    "        HM_unit = HM_args['unit']\n",
    "        HM_interval = HM_args['interval']\n",
    "        if HM_interval == '5m':\n",
    "            interval_delta = pd.Timedelta(minutes=5)\n",
    "        else:\n",
    "            raise ValueError(f\"Not implemented interval: {HM_interval}\")\n",
    "        \n",
    "        for now in now_list:\n",
    "            # HM_now = f'{now.hour}:{now.minute}'\n",
    "            HM_start_dt = now + pd.Timedelta(value=HM_start, unit=HM_unit)\n",
    "\n",
    "            length = len(input_ids[0])\n",
    "\n",
    "\n",
    "            # HM_end = now + pd.Timedelta(hours=HM_end)\n",
    "            # HM_now = f'{now.hour}:{now.minute}'\n",
    "            \n",
    "            HM_seq = [HM_start_dt + i * interval_delta for i in range(length)]\n",
    "            HM_seq = [tkn2idx[f'{i.hour:02d}:{i.minute:02d}'] for i in HM_seq]\n",
    "            HM_seq_list.append(HM_seq)\n",
    "        \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'hm_ids': torch.tensor(HM_seq_list, dtype=torch.long),\n",
    "        # you could also add labels here, e.g.\n",
    "        # 'labels': input_ids.clone()\n",
    "    }\n",
    "\n",
    "tfm_fn_AIInputData.fn_string = inspect.getsource(tfm_fn_AIInputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = dataset[:4]\n",
    "\n",
    "\n",
    "CF_to_CFvocab = data_config['CF_to_CFvocab']\n",
    "examples_tfm = tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "examples_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import itertools\n",
    "\n",
    "def entry_fn_AIInputData(Data, \n",
    "                         CF_to_CFvocab, \n",
    "                         OneEntryArgs,\n",
    "                         tfm_fn_AIInputData = None):\n",
    "    \n",
    "    # Input feaures. \n",
    "    # INPUT_CFs = get_INPUT_CFs(OneEntryArgs)\n",
    "    # print(INPUT_CFs)\n",
    "    transform_fn = lambda examples: tfm_fn_AIInputData(examples, OneEntryArgs, CF_to_CFvocab)\n",
    "    # ds_case \n",
    "    ds_case = Data['ds_case']\n",
    "    if type(ds_case) == pd.DataFrame:\n",
    "        ds_case = datasets.Dataset.from_pandas(ds_case) \n",
    "    ds_case.set_transform(transform_fn)\n",
    "    ds_tfm = ds_case\n",
    "    Data['ds_tfm'] = ds_tfm\n",
    "    return Data\n",
    "\n",
    "entry_fn_AIInputData.fn_string = inspect.getsource(entry_fn_AIInputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# Data = {'ds_case': dataset_all}\n",
    "\n",
    "print([i for i in Data])\n",
    "\n",
    "\n",
    "CF_to_CFvocab = data_config['CF_to_CFvocab']\n",
    "Data = entry_fn_AIInputData(Data, \n",
    "                            CF_to_CFvocab, \n",
    "                            OneEntryArgs,\n",
    "                            tfm_fn_AIInputData)\n",
    "ds_tfm = Data['ds_tfm']\n",
    "ds_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_tfm[:4]\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Entry Fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recfldtkn.aidata_base.entry import AIDATA_ENTRYINPUT_PATH\n",
    "from recfldtkn.base import Base\n",
    "\n",
    "pypath = os.path.join(SPACE['CODE_FN'],  AIDATA_ENTRYINPUT_PATH, f'{EntryInputMethod}.py')\n",
    "# print(pypath) \n",
    "\n",
    "prefix = [\n",
    "    'import itertools',\n",
    "    'import pandas as pd', \n",
    "    'import numpy as np', \n",
    "    'import datasets',\n",
    "    'import torch',\n",
    "    'import datasets',\n",
    "    ]\n",
    "\n",
    "fn_variables = [\n",
    "    get_INPUT_CFs,\n",
    "    tfm_fn_AIInputData,\n",
    "    entry_fn_AIInputData,\n",
    "]\n",
    "\n",
    "pycode = Base.convert_variables_to_pystirng(fn_variables = fn_variables, prefix = prefix)\n",
    "\n",
    "print(pypath)\n",
    "if not os.path.exists(os.path.dirname(pypath)): os.makedirs(os.path.dirname(pypath))\n",
    "with open(pypath, 'w') as file: file.write(pycode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}